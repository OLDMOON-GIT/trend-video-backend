"""
ë¹„ë””ì˜¤ ë³‘í•© ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°í•˜ê³ , ì„ íƒì ìœ¼ë¡œ TTS ë‚˜ë ˆì´ì…˜ê³¼ ìë§‰ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
"""
import sys
import asyncio
import json
from pathlib import Path
from typing import List
import subprocess
import logging
import re

# ì›Œí„°ë§ˆí¬ ì œê±° ê¸°ëŠ¥
try:
    import cv2
    import numpy as np
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    logging.warning("âš ï¸ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì›Œí„°ë§ˆí¬ ì œê±° ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì • (stderr ì—ëŸ¬ ë°©ì§€)
import sys
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    stream=sys.stdout,  # stderr ëŒ€ì‹  stdout ì‚¬ìš©
    force=True
)
logger = logging.getLogger(__name__)


def detect_watermark_region(frame, threshold=200):
    """í”„ë ˆì„ì—ì„œ ì›Œí„°ë§ˆí¬ ì˜ì—­ ê°ì§€"""
    if not OPENCV_AVAILABLE:
        return []

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)

    kernel = np.ones((5, 5), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    watermark_regions = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        area = w * h
        frame_area = frame.shape[0] * frame.shape[1]
        if 0.005 * frame_area < area < 0.1 * frame_area:
            watermark_regions.append((x, y, w, h))

    return watermark_regions


def inpaint_region(frame, x, y, w, h):
    """íŠ¹ì • ì˜ì—­ì„ ì£¼ë³€ í”½ì…€ë¡œ ì±„ìš°ê¸° (inpainting)"""
    if not OPENCV_AVAILABLE:
        return frame

    mask = np.zeros(frame.shape[:2], dtype=np.uint8)
    padding = 5
    x1 = max(0, x - padding)
    y1 = max(0, y - padding)
    x2 = min(frame.shape[1], x + w + padding)
    y2 = min(frame.shape[0], y + h + padding)

    mask[y1:y2, x1:x2] = 255
    result = cv2.inpaint(frame, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    return result


def remove_watermark_from_video(input_path: Path, output_path: Path, threshold: int = 150) -> Path:
    """
    ë¹„ë””ì˜¤ì—ì„œ ì›Œí„°ë§ˆí¬ ì œê±° - ì›Œí„°ë§ˆí¬ ì œê±°ëŠ” ê±´ë„ˆë›°ê³  ì›ë³¸ ë³µì‚¬
    (í˜„ì¬ëŠ” ì›Œí„°ë§ˆí¬ ì œê±° ê¸°ëŠ¥ ë¹„í™œì„±í™”)
    """
    logger.info(f"â­ï¸ ì›Œí„°ë§ˆí¬ ì œê±° ê±´ë„ˆë›°ê¸°: {input_path.name}")
    logger.info(f"   (ì›Œí„°ë§ˆí¬ ì œê±° ê¸°ëŠ¥ì€ í˜„ì¬ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤)")

    # ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬
    import shutil
    shutil.copy(input_path, output_path)
    return output_path


def get_ffmpeg_path():
    """FFmpeg ê²½ë¡œ í™•ì¸"""
    try:
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
        if result.returncode == 0:
            return 'ffmpeg'
    except FileNotFoundError:
        pass

    # imageio-ffmpeg ì‹œë„
    try:
        import imageio_ffmpeg
        return imageio_ffmpeg.get_ffmpeg_exe()
    except ImportError:
        pass

    return None


def concatenate_videos(video_paths: List[Path], output_path: Path) -> Path:
    """
    FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ë³‘í•© (filter_complex ë°©ì‹)
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found. Install FFmpeg or imageio-ffmpeg.")

    logger.info(f"ğŸ“¹ {len(video_paths)}ê°œ ë¹„ë””ì˜¤ ë³‘í•© ì¤‘...")
    logger.info(f"   ë¹„ë””ì˜¤ ëª©ë¡:")
    for i, path in enumerate(video_paths, 1):
        logger.info(f"   {i}. {path.name}")

    # filter_complex ë°©ì‹ìœ¼ë¡œ ë³‘í•© (íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ì œ í•´ê²°)
    # ì…ë ¥ íŒŒì¼ë“¤
    input_args = []
    for path in video_paths:
        input_args.extend(['-i', str(path)])

    # filter_complex ë¬¸ìì—´ ìƒì„±
    # [0:v][0:a][1:v][1:a]...[n:v][n:a]concat=n=N:v=1:a=1[outv][outa]
    filter_parts = []
    for i in range(len(video_paths)):
        filter_parts.append(f"[{i}:v][{i}:a]")
    filter_str = "".join(filter_parts) + f"concat=n={len(video_paths)}:v=1:a=1[outv][outa]"

    logger.info(f"ğŸ¬ FFmpeg filter_complex ëª…ë ¹ ì‹¤í–‰ ì¤‘...")

    cmd = [
        ffmpeg,
        '-y',  # ë®ì–´ì“°ê¸°
        *input_args,  # ì…ë ¥ íŒŒì¼ë“¤
        '-filter_complex', filter_str,
        '-map', '[outv]',
        '-map', '[outa]',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '18',  # ê³ í’ˆì§ˆ
        '-c:a', 'aac',
        '-b:a', '192k',
        str(output_path)
    ]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        timeout=600
    )

    if result.returncode != 0:
        logger.error(f"âŒ FFmpeg stderr: {result.stderr}")
        raise RuntimeError(f"FFmpeg ì‹¤íŒ¨:\n{result.stderr}")

    logger.info(f"âœ… ë¹„ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_path.name}")

    if not output_path.exists():
        raise RuntimeError(f"ì¶œë ¥ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_path}")

    return output_path


def align_videos_to_scenes(video_paths: list, scenes: list, whisper_segments: list, output_path: Path) -> Path:
    """
    scenes ë°°ì—´ì— ë§ì¶° ë¹„ë””ì˜¤ë¥¼ ë°°ì¹˜ (ì›ë³¸ ëŒ€ë³¸ êµ¬ì¡° ì‚¬ìš©)

    Args:
        video_paths: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        scenes: scenes ë°°ì—´ (ê° sceneì€ narration, duration í¬í•¨)
        whisper_segments: Whisper ì„¸ê·¸ë¨¼íŠ¸ (ì „ì²´ íƒ€ì„ìŠ¤íƒ¬í”„)
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found. Install FFmpeg or imageio-ffmpeg.")

    logger.info(f"\nğŸ¬ scenes ë°°ì—´ì— ë§ì¶° ë¹„ë””ì˜¤ ë°°ì¹˜ ì¤‘...")
    logger.info(f"   scenes: {len(scenes)}ê°œ")
    logger.info(f"   ë¹„ë””ì˜¤: {len(video_paths)}ê°œ")

    # scenesì™€ ë¹„ë””ì˜¤ ë§¤ì¹­
    video_segments = []
    current_time = 0.0

    for i, scene in enumerate(scenes):
        # ë¹„ë””ì˜¤ ì„ íƒ (ìˆœì°¨ì ìœ¼ë¡œ, ë§ˆì§€ë§‰ ë¹„ë””ì˜¤ ë°˜ë³µ)
        video_idx = min(i, len(video_paths) - 1)
        video_path = video_paths[video_idx]

        # sceneì˜ duration ì‚¬ìš© (Whisper ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì‹¤ì œ ê¸¸ì´ ê³„ì‚°)
        scene_narration = scene.get('narration', '')
        scene_duration = scene.get('duration', 0)

        # Whisper ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì´ sceneì— í•´ë‹¹í•˜ëŠ” êµ¬ê°„ ì°¾ê¸°
        scene_start = current_time
        scene_end = scene_start

        # sceneì˜ narrationê³¼ ë§¤ì¹­ë˜ëŠ” Whisper ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
        for seg in whisper_segments:
            if seg['start'] >= current_time:
                if scene_end == scene_start:
                    scene_end = seg['end']
                else:
                    scene_end = seg['end']

                # scene_narrationì´ seg['text']ì— í¬í•¨ë˜ê±°ë‚˜ ìœ ì‚¬í•˜ë©´ ê³„ì†
                # ê°„ë‹¨í•˜ê²Œ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
                if scene_duration > 0 and (scene_end - scene_start) >= scene_duration * 0.9:
                    break

        # scene_endê°€ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì•˜ìœ¼ë©´ duration ì‚¬ìš©
        if scene_end == scene_start and scene_duration > 0:
            scene_end = scene_start + scene_duration

        duration = scene_end - scene_start
        current_time = scene_end

        video_segments.append({
            'video_path': video_path,
            'duration': duration,
            'scene_text': scene_narration[:30]
        })

        logger.info(f"   ì”¬ {i+1}: {duration:.2f}ì´ˆ â†’ {video_path.name}")

    # FFmpeg filter_complexë¡œ ê° ë¹„ë””ì˜¤ë¥¼ trimí•˜ê³  concat
    input_args = []
    trim_filters = []
    concat_inputs = []

    for i, vs in enumerate(video_segments):
        input_args.extend(['-i', str(vs['video_path'])])
        trim_filters.append(f"[{i}:v]trim=duration={vs['duration']},setpts=PTS-STARTPTS[v{i}]")
        trim_filters.append(f"[{i}:a]atrim=duration={vs['duration']},asetpts=PTS-STARTPTS[a{i}]")
        concat_inputs.append(f"[v{i}][a{i}]")

    trim_filter_str = ";".join(trim_filters)
    concat_input_str = "".join(concat_inputs)
    concat_filter = f"{concat_input_str}concat=n={len(video_segments)}:v=1:a=1[outv][outa]"
    filter_complex = f"{trim_filter_str};{concat_filter}"

    logger.info(f"ğŸ¬ FFmpeg filter_complex ì‹¤í–‰ ì¤‘...")

    cmd = [
        ffmpeg,
        '-y',
        *input_args,
        '-filter_complex', filter_complex,
        '-map', '[outv]',
        '-map', '[outa]',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '23',
        '-c:a', 'aac',
        '-b:a', '192k',
        str(output_path)
    ]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        timeout=600
    )

    if result.returncode != 0:
        logger.error(f"âŒ FFmpeg stderr: {result.stderr}")
        raise RuntimeError(f"FFmpeg ì‹¤íŒ¨:\n{result.stderr}")

    logger.info(f"âœ… scenes ê¸°ë°˜ ë¹„ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_path.name}")

    if not output_path.exists():
        raise RuntimeError(f"ì¶œë ¥ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_path}")

    return output_path


def align_videos_to_segments(video_paths: list, segments: list, output_path: Path) -> Path:
    """
    ë‚˜ë ˆì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì— ë§ì¶° ë¹„ë””ì˜¤ë¥¼ ë°°ì¹˜

    Args:
        video_paths: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        segments: Whisper ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ (ê° ì„¸ê·¸ë¨¼íŠ¸ëŠ” start, end, text í¬í•¨)
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found. Install FFmpeg or imageio-ffmpeg.")

    logger.info(f"\nğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì— ë§ì¶° ë¹„ë””ì˜¤ ë°°ì¹˜ ì¤‘...")
    logger.info(f"   ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ")
    logger.info(f"   ë¹„ë””ì˜¤: {len(video_paths)}ê°œ")

    # ì„¸ê·¸ë¨¼íŠ¸ì™€ ë¹„ë””ì˜¤ ë§¤ì¹­ (ìˆœí™˜ ì—†ìŒ, ë§ˆì§€ë§‰ ë¹„ë””ì˜¤ ìœ ì§€)
    video_segments = []
    for i, seg in enumerate(segments):
        # ë¹„ë””ì˜¤ ê°œìˆ˜ë¥¼ ë„˜ì–´ê°€ë©´ ë§ˆì§€ë§‰ ë¹„ë””ì˜¤ ê³„ì† ì‚¬ìš©
        video_idx = min(i, len(video_paths) - 1)
        video_path = video_paths[video_idx]
        duration = seg['end'] - seg['start']

        video_segments.append({
            'video_path': video_path,
            'duration': duration,
            'segment_text': seg['text'][:30]  # ë¡œê·¸ìš©
        })

        logger.info(f"   ì„¸ê·¸ë¨¼íŠ¸ {i+1}: {duration:.2f}ì´ˆ â†’ {video_path.name}")

    # FFmpeg filter_complexë¡œ ê° ë¹„ë””ì˜¤ë¥¼ trimí•˜ê³  concat
    input_args = []
    trim_filters = []
    concat_inputs = []

    for i, vs in enumerate(video_segments):
        # ê° ë¹„ë””ì˜¤ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ì¶”ê°€ (ì¤‘ë³µ ê°€ëŠ¥)
        input_args.extend(['-i', str(vs['video_path'])])

        # í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ durationì— ë§ì¶° trim
        # trimì€ ì²˜ìŒë¶€í„° durationë§Œí¼ë§Œ ê°€ì ¸ì˜´
        trim_filters.append(f"[{i}:v]trim=duration={vs['duration']},setpts=PTS-STARTPTS[v{i}]")
        trim_filters.append(f"[{i}:a]atrim=duration={vs['duration']},asetpts=PTS-STARTPTS[a{i}]")

        concat_inputs.append(f"[v{i}][a{i}]")

    # filter_complex ë¬¸ìì—´ ì¡°í•©
    trim_filter_str = ";".join(trim_filters)
    concat_input_str = "".join(concat_inputs)
    concat_filter = f"{concat_input_str}concat=n={len(video_segments)}:v=1:a=1[outv][outa]"

    filter_complex = f"{trim_filter_str};{concat_filter}"

    logger.info(f"ğŸ¬ FFmpeg filter_complex ì‹¤í–‰ ì¤‘...")

    cmd = [
        ffmpeg,
        '-y',
        *input_args,
        '-filter_complex', filter_complex,
        '-map', '[outv]',
        '-map', '[outa]',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '23',
        '-c:a', 'aac',
        '-b:a', '192k',
        str(output_path)
    ]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        timeout=600
    )

    if result.returncode != 0:
        logger.error(f"âŒ FFmpeg stderr: {result.stderr}")
        raise RuntimeError(f"FFmpeg ì‹¤íŒ¨:\n{result.stderr}")

    logger.info(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ë¹„ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_path.name}")

    if not output_path.exists():
        raise RuntimeError(f"ì¶œë ¥ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_path}")

    return output_path


def transcribe_audio_with_whisper(audio_path: Path, original_text: str) -> list:
    """
    Whisperë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ ì–»ê³ , í…ìŠ¤íŠ¸ëŠ” ì›ë³¸ ë‚˜ë ˆì´ì…˜ ì‚¬ìš©
    """
    try:
        import whisper
        import re

        logger.info(f"ğŸ§ Whisperë¡œ íƒ€ì´ë° ë¶„ì„ ì¤‘...")

        # Whisper ëª¨ë¸ ë¡œë“œ (base ëª¨ë¸ ì‚¬ìš©)
        model = whisper.load_model("base")

        # ì˜¤ë””ì˜¤ ì¸ì‹ (íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ í•„ìš”)
        result = model.transcribe(
            str(audio_path),
            language="ko",
            verbose=False
        )

        # Whisper ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
        whisper_segments = result["segments"]
        logger.info(f"âœ… Whisper íƒ€ì´ë° ë¶„ì„ ì™„ë£Œ: {len(whisper_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

        # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ]+)', original_text)

        # ë¶„ë¦¬ëœ êµ¬ë‘ì ì„ ì• ë¬¸ì¥ì— ë¶™ì´ê¸°
        original_sentences = []
        for i in range(0, len(sentences)-1, 2):
            if i+1 < len(sentences):
                sentence = (sentences[i] + sentences[i+1]).strip()
                if sentence:
                    original_sentences.append(sentence)

        # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
        if len(sentences) % 2 == 1 and sentences[-1].strip():
            original_sentences.append(sentences[-1].strip())

        if not original_sentences:
            original_sentences = [original_text.strip()]

        logger.info(f"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: {len(original_sentences)}ê°œ ë¬¸ì¥")

        # Whisper íƒ€ì„ìŠ¤íƒ¬í”„ + ì›ë³¸ í…ìŠ¤íŠ¸ ê²°í•©
        subtitle_data = []

        # ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜ì™€ ë¬¸ì¥ ê°œìˆ˜ê°€ ë‹¤ë¥¼ ê²½ìš° ì¡°ì •
        num_segments = min(len(whisper_segments), len(original_sentences))

        if len(whisper_segments) != len(original_sentences):
            logger.warning(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜ ë¶ˆì¼ì¹˜: Whisper {len(whisper_segments)}ê°œ, ì›ë³¸ {len(original_sentences)}ê°œ")
            logger.warning(f"   â†’ {num_segments}ê°œë§Œ ì‚¬ìš©")

        for i in range(num_segments):
            subtitle_data.append({
                "start": whisper_segments[i]["start"],
                "end": whisper_segments[i]["end"],
                "text": original_sentences[i]  # ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©!
            })

        # ë‚¨ì€ ì›ë³¸ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì— ì´ì–´ë¶™ì´ê¸°
        if len(original_sentences) > num_segments:
            remaining = " ".join(original_sentences[num_segments:])
            if subtitle_data:
                subtitle_data[-1]["text"] += " " + remaining
                logger.info(f"ğŸ“ ë‚¨ì€ ë¬¸ì¥ì„ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì— ì¶”ê°€")

        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒ˜í”Œ ì¶œë ¥
        if subtitle_data:
            logger.info(f"ğŸ“Š íƒ€ì„ìŠ¤íƒ¬í”„ + ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 3ê°œ):")
            for i, seg in enumerate(subtitle_data[:3]):
                duration = seg['end'] - seg['start']
                logger.info(f"   {i+1}. {seg['start']:.3f}s ~ {seg['end']:.3f}s ({duration:.3f}ì´ˆ): '{seg['text'][:50]}'")

        return subtitle_data

    except Exception as e:
        logger.warning(f"âš ï¸ Whisper ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.warning(f"   íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        return None


async def generate_tts(text: str, output_path: Path, voice: str = "ko-KR-SunHiNeural"):
    """
    Edge TTSë¡œ ìŒì„± ìƒì„± í›„ Whisperë¡œ ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì–»ê¸°
    Returns: (audio_path, subtitle_data)
    """
    try:
        import edge_tts
    except ImportError:
        raise ImportError("edge-ttsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install edge-tts ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

    logger.info(f"ğŸ™ï¸ TTS ìƒì„± ì¤‘: {voice}")

    # í…ìŠ¤íŠ¸ ì •ë¦¬
    clean_text = text.strip()
    if not clean_text:
        raise ValueError("ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    # Edge TTSë¡œ ìŒì„±ë§Œ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” Whisperì—ì„œ ì–»ìŒ)
    communicate = edge_tts.Communicate(clean_text, voice)

    with open(output_path, "wb") as audio_file:
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_file.write(chunk["data"])

    logger.info(f"âœ… TTS ìƒì„± ì™„ë£Œ: {output_path.name}")

    # Whisperë¡œ ì˜¤ë””ì˜¤ ì¸ì‹í•´ì„œ ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì–»ê¸°
    subtitle_data = transcribe_audio_with_whisper(output_path, clean_text)

    # Whisper ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìë§‰ ì—†ì´ ì§„í–‰)
    if subtitle_data is None:
        subtitle_data = []

    return output_path, subtitle_data


def format_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"


def format_ass_timestamp(seconds: float) -> str:
    """ì´ˆë¥¼ ASS íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (h:mm:ss.cc)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    centisecs = int((seconds % 1) * 100)
    return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"


def create_ass_from_timestamps(subtitle_data: list, output_path: Path, max_chars_per_line: int = 30) -> Path:
    """Whisper ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ì—ì„œ ASS ìë§‰ íŒŒì¼ ìƒì„±

    Args:
        subtitle_data: Whisper ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° (ì´ë¯¸ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ë¨)
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        max_chars_per_line: í•œ ì¤„ ìµœëŒ€ ê¸€ì ìˆ˜ (í˜„ì¬ ë¯¸ì‚¬ìš©)
    """
    if not subtitle_data:
        logger.error("âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨: íƒ€ì„ìŠ¤íƒ¬í”„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None

    # Whisper ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ë¨)
    logger.info(f"ğŸ“ Whisper ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ìë§‰ ìƒì„±: {len(subtitle_data)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    # ìë§‰ ìƒ˜í”Œ ë¡œê·¸ (ë””ë²„ê¹…)
    if subtitle_data:
        logger.info(f"ğŸ“Š ìë§‰ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
        for i, sub in enumerate(subtitle_data[:3]):
            duration = sub['end'] - sub['start']
            logger.info(f"   {i+1}. {sub['start']:.3f}s ~ {sub['end']:.3f}s ({duration:.3f}ì´ˆ): '{sub['text'][:50]}'")

    # ASS íŒŒì¼ ì‘ì„±
    ass_path = output_path.with_suffix('.ass')

    with open(ass_path, 'w', encoding='utf-8') as f:
        # ASS í—¤ë”
        f.write("[Script Info]\n")
        f.write("ScriptType: v4.00+\n")
        f.write("PlayResX: 1920\n")
        f.write("PlayResY: 1080\n")
        f.write("\n")

        # ìŠ¤íƒ€ì¼ ì •ì˜
        f.write("[V4+ Styles]\n")
        f.write("Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n")
        f.write("Style: Default,Pretendard Variable,48,&H00FFFFFF,&H000088EF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,30,30,40,1\n")
        f.write("\n")

        # ì´ë²¤íŠ¸ (ìë§‰)
        f.write("[Events]\n")
        f.write("Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n")

        for sub in subtitle_data:
            start_time = format_ass_timestamp(sub["start"])
            end_time = format_ass_timestamp(sub["end"])
            text = sub["text"]
            f.write(f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\n")

    logger.info(f"âœ… ASS ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path} ({len(subtitle_data)}ê°œ ë¼ì¸)")
    return ass_path


def create_ass_from_text(text: str, duration: float, output_path: Path, max_chars_per_line: int = 22) -> Path:
    """í…ìŠ¤íŠ¸ì—ì„œ ASS ìë§‰ íŒŒì¼ ìƒì„± (ë¡±í¼ ë°©ì‹)"""
    if not text or not text.strip():
        logger.error("âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨: í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None

    # ì œì–´ ëª…ë ¹ì–´ ì œê±° ([ë¬´ìŒ 3ì´ˆ], [ì¹¨ë¬µ] ë“±)
    text = re.sub(r'\[(ë¬´ìŒ|ì¹¨ë¬µ|pause)\s*(\d+(?:\.\d+)?)?ì´ˆ?\]', '', text)

    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text)

    # ë¶„ë¦¬ëœ êµ¬ë‘ì ì„ ì• ë¬¸ì¥ì— ë¶™ì´ê¸°
    combined_sentences = []
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            combined_sentences.append((sentences[i] + sentences[i+1]).strip())

    # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        combined_sentences.append(sentences[-1].strip())

    # ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ
    if not combined_sentences:
        combined_sentences = [text.strip()]

    # ì „ì²´ ê¸€ì ìˆ˜ ê³„ì‚°
    total_text = " ".join(combined_sentences)
    total_chars = len(total_text)
    time_per_char = duration / total_chars if total_chars > 0 else 0

    # ê° ë¬¸ì¥ì„ max_chars_per_lineì ë‹¨ìœ„ë¡œ ë¶„í• 
    subtitles = []
    current_time = 0.0
    MIN_REMAINING_CHARS = 5

    for sentence in combined_sentences:
        words = sentence.split()
        if not words:
            continue

        current_text = ""
        for i, word in enumerate(words):
            next_text = current_text + (" " if current_text else "") + word
            remaining_words = words[i+1:]
            remaining_text = " ".join(remaining_words) if remaining_words else ""

            if len(next_text) > max_chars_per_line and current_text:
                if len(remaining_text) > 0 and len(remaining_text) < MIN_REMAINING_CHARS:
                    current_text = next_text + (" " + remaining_text if remaining_text else "")
                    duration_calc = len(current_text) * time_per_char
                    end_time = current_time + duration_calc
                    subtitles.append({
                        "start": current_time,
                        "end": end_time,
                        "text": current_text.strip()
                    })
                    current_text = ""
                    current_time = end_time
                    break
                else:
                    duration_calc = len(current_text) * time_per_char
                    end_time = current_time + duration_calc
                    subtitles.append({
                        "start": current_time,
                        "end": end_time,
                        "text": current_text.strip()
                    })
                    current_text = word
                    current_time = end_time
            else:
                current_text = next_text

        if current_text:
            duration_calc = len(current_text) * time_per_char
            end_time = current_time + duration_calc
            subtitles.append({
                "start": current_time,
                "end": end_time,
                "text": current_text.strip()
            })
            current_time = end_time

    # ASS íŒŒì¼ ì‘ì„±
    ass_path = output_path.with_suffix('.ass')

    with open(ass_path, 'w', encoding='utf-8') as f:
        # ASS í—¤ë”
        f.write("[Script Info]\n")
        f.write("ScriptType: v4.00+\n")
        f.write("PlayResX: 1920\n")
        f.write("PlayResY: 1080\n\n")

        # ìŠ¤íƒ€ì¼ ì •ì˜ (NanumGothic í°íŠ¸, í°ìƒ‰, ê²€ì€ í…Œë‘ë¦¬)
        f.write("[V4+ Styles]\n")
        f.write("Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n")
        f.write("Style: Default,NanumGothic,96,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,3,2,2,10,10,20,1\n\n")

        # ì´ë²¤íŠ¸ (ìë§‰)
        f.write("[Events]\n")
        f.write("Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n")

        for sub in subtitles:
            start = format_ass_timestamp(sub["start"])
            end = format_ass_timestamp(sub["end"])
            text_escaped = sub['text'].replace('\n', '\\N')
            f.write(f"Dialogue: 0,{start},{end},Default,,0,0,0,,{text_escaped}\n")

    logger.info(f"âœ… ASS ìë§‰ íŒŒì¼ ìƒì„±: {ass_path.name} ({len(subtitles)}ê°œ êµ¬ê°„)")
    return ass_path


def get_video_duration(video_path: Path) -> float:
    """FFprobeë¡œ ë¹„ë””ì˜¤ ê¸¸ì´ í™•ì¸"""
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found.")

    ffprobe_path = ffmpeg.replace('ffmpeg', 'ffprobe')

    try:
        cmd = [
            ffprobe_path,
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(video_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        return float(result.stdout.strip())
    except Exception as e:
        logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return 0.0


def get_audio_duration(audio_path: Path) -> float:
    """FFprobeë¡œ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸"""
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found.")

    ffprobe_path = ffmpeg.replace('ffmpeg', 'ffprobe')

    try:
        cmd = [
            ffprobe_path,
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        return float(result.stdout.strip())
    except Exception as e:
        logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return 0.0


def add_audio_to_video(video_path: Path, audio_path: Path, output_path: Path, subtitle_text: str = None, add_subtitles: bool = False, subtitle_data: list = None) -> Path:
    """
    FFmpegë¡œ ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ (ë° ì„ íƒì ìœ¼ë¡œ ìë§‰) ì¶”ê°€
    TTSê°€ ì§§ì•„ë„ ë¹„ë””ì˜¤ ì „ì²´ ê¸¸ì´ì— ë§ì¶° ë¬´ìŒ ì¶”ê°€
    subtitle_data: TTS íƒ€ì„ìŠ¤íƒ¬í”„ ë°ì´í„° (ìˆìœ¼ë©´ ì •í™•í•œ ë™ê¸°í™”)
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise RuntimeError("FFmpeg not found.")

    logger.info(f"ğŸ”Š ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€ ì¤‘...")

    # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
    video_duration = get_video_duration(video_path)
    audio_duration = get_audio_duration(audio_path)

    logger.info(f"â±ï¸ ë¹„ë””ì˜¤ ê¸¸ì´: {video_duration:.2f}ì´ˆ")
    logger.info(f"â±ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")

    # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ ê¸¸ì´ ë¹„êµí•˜ì—¬ í•„í„° ì¤€ë¹„
    video_filter = None
    audio_filter = None

    if video_duration < audio_duration:
        # ë¹„ë””ì˜¤ê°€ ì§§ìœ¼ë©´: ë§ˆì§€ë§‰ í”„ë ˆì„ì„ freezeí•˜ì—¬ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤
        freeze_duration = audio_duration - video_duration
        video_filter = f"tpad=stop_mode=clone:stop_duration={freeze_duration:.3f}"
        logger.info(f"âš ï¸ ë¹„ë””ì˜¤ê°€ TTSë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ í”„ë ˆì„ì„ {freeze_duration:.2f}ì´ˆ freezeí•©ë‹ˆë‹¤.")
        logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ íŒ¨ë”© í•„í„° ì ìš©: {video_filter}")
    elif audio_duration < video_duration:
        # ì˜¤ë””ì˜¤ê°€ ì§§ìœ¼ë©´: ë¬´ìŒ ì¶”ê°€í•˜ì—¬ ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤
        audio_filter = f"apad=whole_dur={video_duration:.3f}"
        logger.info(f"âš ï¸ TTSê°€ ë¹„ë””ì˜¤ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤. ë¬´ìŒì„ ì¶”ê°€í•˜ì—¬ ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¥ë‹ˆë‹¤.")
        logger.info(f"ğŸ”‡ ì˜¤ë””ì˜¤ íŒ¨ë”© í•„í„° ì ìš©: {audio_filter}")

    # ìë§‰ì´ ìˆëŠ” ê²½ìš°
    if subtitle_text and add_subtitles:
        logger.info(f"ğŸ“ ìë§‰ ì¶”ê°€ ì‹œì‘...")
        logger.info(f"ğŸ“ ìë§‰ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(subtitle_text)}ì")
        logger.info(f"ğŸ“ ìë§‰ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {subtitle_text[:100]}...")

        # ASS ìë§‰ íŒŒì¼ ìƒì„±
        temp_path = video_path.parent / f"{video_path.stem}_temp.srt"

        # íƒ€ì„ìŠ¤íƒ¬í”„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì •í™•í•œ ë™ê¸°í™” ì‚¬ìš©
        if subtitle_data:
            logger.info(f"â±ï¸ TTS íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ìë§‰ ìƒì„± (ì™„ë²½ ë™ê¸°í™”)")
            ass_path = create_ass_from_timestamps(subtitle_data, temp_path)
        else:
            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì •
            logger.info(f"â±ï¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìë§‰ ìƒì„± (TTS ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ì¤€)")
            duration = audio_duration if audio_duration > 0 else get_video_duration(video_path)
            logger.info(f"â±ï¸ ìë§‰ ê¸°ì¤€ ê¸¸ì´: {duration}ì´ˆ")

            if duration == 0:
                logger.warning("âš ï¸ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ê¸¸ì´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ì–´ ìë§‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                subtitle_text = None
                ass_path = None
            else:
                ass_path = create_ass_from_text(subtitle_text, duration, temp_path)

        if subtitle_text:

            if not ass_path or not ass_path.exists():
                logger.error(f"âŒ ASS ìë§‰ íŒŒì¼ ìƒì„± ì‹¤íŒ¨!")
                subtitle_text = None
            else:
                logger.info(f"âœ… ASS ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path}")

                # ASS íŒŒì¼ ë‚´ìš© í™•ì¸ (ë””ë²„ê¹…)
                try:
                    with open(ass_path, 'r', encoding='utf-8') as f:
                        ass_content = f.read()
                        logger.info(f"ğŸ“ ASS íŒŒì¼ ë‚´ìš© ({len(ass_content)}ì):")
                        logger.info(ass_content[:300])
                except Exception as e:
                    logger.warning(f"âš ï¸ ASS íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

                # Windows ê²½ë¡œë¥¼ FFmpeg í˜¸í™˜ ê²½ë¡œë¡œ ë³€í™˜ (ë¡±í¼ ë°©ì‹)
                ass_path_str = str(ass_path).replace('\\', '/').replace(':', '\\\\:')

                # ë¹„ë””ì˜¤ í•„í„° ìƒì„± (tpad + ass ê²°í•©)
                vf_parts = []
                if video_filter:
                    vf_parts.append(video_filter)
                vf_parts.append(f"ass={ass_path_str}")
                vf_combined = ",".join(vf_parts)

                # FFmpeg ëª…ë ¹ì–´ (ASS ìë§‰ í¬í•¨)
                # ë¹„ë””ì˜¤ ê¸¸ì´ë¥¼ TTSì— ë§ì¶”ê³ , ì˜¤ë””ì˜¤ê°€ ì§§ìœ¼ë©´ ë‚˜ë¨¸ì§€ëŠ” ë¬´ìŒ
                # ì£¼ì˜: -vf ì‚¬ìš© ì‹œ ë¹„ë””ì˜¤ ì¬ì¸ì½”ë”© í•„ìš” (ìë§‰ì„ ë¹„ë””ì˜¤ì— ì˜¤ë²„ë ˆì´)
                cmd = [
                    ffmpeg,
                    '-y',
                    '-i', str(video_path),
                    '-i', str(audio_path),
                    '-vf', vf_combined,
                    '-c:v', 'libx264',  # ìë§‰ ì˜¤ë²„ë ˆì´ë¥¼ ìœ„í•´ ì¬ì¸ì½”ë”© í•„ìš”
                    '-preset', 'medium',
                    '-crf', '23',
                    '-c:a', 'aac',
                    '-map', '0:v:0',
                    '-map', '1:a:0',
                ]

                # ì˜¤ë””ì˜¤ í•„í„° ì¶”ê°€ (íŒ¨ë”©ì´ í•„ìš”í•œ ê²½ìš°)
                if audio_filter:
                    cmd.extend(['-af', audio_filter])

                cmd.append(str(output_path))

                logger.info(f"ğŸ¬ FFmpeg ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘...")
                logger.info(f"   ìë§‰ í•„í„°: ass={ass_path_str}")

                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=600
                )

                logger.info(f"ğŸ“¤ FFmpeg ë°˜í™˜ ì½”ë“œ: {result.returncode}")
                if result.stdout:
                    logger.info(f"ğŸ“¤ FFmpeg stdout: {result.stdout[:500]}")
                if result.stderr:
                    logger.info(f"ğŸ“¤ FFmpeg stderr: {result.stderr[:500]}")

                # ASS íŒŒì¼ ì •ë¦¬
                if ass_path.exists():
                    ass_path.unlink()
                    logger.info(f"ğŸ—‘ï¸ ASS ì„ì‹œ íŒŒì¼ ì‚­ì œë¨")

                if result.returncode != 0:
                    logger.error(f"âŒ FFmpeg ìë§‰ ì¶”ê°€ ì‹¤íŒ¨ (ì½”ë“œ: {result.returncode})")
                    logger.error(f"âŒ FFmpeg stderr: {result.stderr}")
                    logger.warning(f"âš ï¸ ìë§‰ ì—†ì´ ì¬ì‹œë„...")
                    subtitle_text = None
                else:
                    logger.info(f"âœ… ìë§‰ ì¶”ê°€ ì„±ê³µ!")

    # ìë§‰ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°
    if not subtitle_text or not add_subtitles:
        cmd = [
            ffmpeg,
            '-y',
            '-i', str(video_path),
            '-i', str(audio_path),
        ]

        # ë¹„ë””ì˜¤ í•„í„°ê°€ ìˆìœ¼ë©´ ì¬ì¸ì½”ë”© í•„ìš”
        if video_filter:
            cmd.extend([
                '-vf', video_filter,
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
            ])
        else:
            cmd.extend(['-c:v', 'copy'])  # ë¹„ë””ì˜¤ëŠ” ë³µì‚¬

        cmd.extend([
            '-c:a', 'aac',   # ì˜¤ë””ì˜¤ëŠ” aacë¡œ ì¸ì½”ë”©
            '-map', '0:v:0',  # ì²« ë²ˆì§¸ ì…ë ¥ì˜ ë¹„ë””ì˜¤
            '-map', '1:a:0',  # ë‘ ë²ˆì§¸ ì…ë ¥ì˜ ì˜¤ë””ì˜¤
        ])

        # ì˜¤ë””ì˜¤ í•„í„° ì¶”ê°€ (íŒ¨ë”©ì´ í•„ìš”í•œ ê²½ìš°)
        if audio_filter:
            cmd.extend(['-af', audio_filter])

        cmd.append(str(output_path))

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=600
        )

    if result.returncode != 0:
        raise RuntimeError(f"ì˜¤ë””ì˜¤ ì¶”ê°€ ì‹¤íŒ¨:\n{result.stderr}")

    logger.info(f"âœ… ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ: {output_path.name}")
    return output_path


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print(json.dumps({
            "success": False,
            "error": "ì‚¬ìš©ë²•: python video_merge.py <config.json>"
        }))
        sys.exit(1)

    config_path = Path(sys.argv[1])
    if not config_path.exists():
        print(json.dumps({
            "success": False,
            "error": f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}"
        }))
        sys.exit(1)

    try:
        # ì„¤ì • íŒŒì¼ ì½ê¸°
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        video_files = [Path(p) for p in config['video_files']]

        # íŒŒì¼ëª…ì— ì‹œí€€ìŠ¤ ë²ˆí˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        def extract_sequence(filename: str):
            """íŒŒì¼ëª…ì—ì„œ ì‹œí€€ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: video_001.mp4 -> 1, clip_03.mp4 -> 3)"""
            match = re.search(r'_(\d+)\.(mp4|mov|avi|mkv)$', filename, re.IGNORECASE)
            if match:
                return int(match.group(1))
            return None

        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ê°€ ìˆëŠ” íŒŒì¼ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
        has_sequence = any(extract_sequence(p.name) is not None for p in video_files)

        if has_sequence:
            # ì‹œí€€ìŠ¤ê°€ ìˆìœ¼ë©´: ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¡œ ì •ë ¬
            logger.info(f"ğŸ“‹ ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¡œ ì •ë ¬")
            video_files.sort(key=lambda p: (extract_sequence(p.name) or 0, p.name))
        else:
            # ì‹œí€€ìŠ¤ê°€ ì—†ìœ¼ë©´: íŒŒì¼ ìƒì„± ì‹œê°„ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ íŒŒì¼ ë¨¼ì €)
            logger.info(f"ğŸ“‹ íŒŒì¼ ìƒì„± ì‹œê°„ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ íŒŒì¼ ë¨¼ì €)")
            video_files.sort(key=lambda p: p.stat().st_ctime)

        narration_text = config.get('narration_text', '')
        add_subtitles = config.get('add_subtitles', False)
        remove_watermark = config.get('remove_watermark', False)
        title = config.get('title', '')  # ëŒ€ë³¸ì˜ title
        scenes = config.get('scenes', None)  # scenes ë°°ì—´ (ë¹„ë””ì˜¤ ë°°ì¹˜ìš©)
        output_dir = Path(config['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)

        # ë¹„ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
        for video_file in video_files:
            if not video_file.exists():
                raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_file}")

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸï¸ ë¹„ë””ì˜¤ ë³‘í•© ì‹œì‘")
        logger.info(f"{'='*60}")
        logger.info(f"ì…ë ¥ ë¹„ë””ì˜¤: {len(video_files)}ê°œ (ì •ë ¬ë¨)")
        for i, vf in enumerate(video_files, 1):
            logger.info(f"  {i}. {vf.name}")

        # ì›Œí„°ë§ˆí¬ ì œê±° ê¸°ëŠ¥ ë¹„í™œì„±í™” (ì‘ë™í•˜ì§€ ì•ŠìŒ)
        processed_video_files = video_files

        # ë‚˜ë ˆì´ì…˜ì´ ìˆìœ¼ë©´ TTSë¥¼ ë¨¼ì € ìƒì„±í•˜ê³  ì„¸ê·¸ë¨¼íŠ¸ì— ë§ì¶° ë¹„ë””ì˜¤ ë°°ì¹˜
        if narration_text:
            logger.info(f"\nğŸ™ï¸ TTS ë‚˜ë ˆì´ì…˜ ìƒì„± (ë¹„ë””ì˜¤ ë°°ì¹˜ ê¸°ì¤€)")
            logger.info(f"í…ìŠ¤íŠ¸: {narration_text[:100]}...")

            tts_audio = output_dir / 'narration.mp3'
            # TTS ìƒì„± ë° Whisper ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ì§‘
            tts_path, subtitle_data = await generate_tts(narration_text, tts_audio)

            if subtitle_data:
                logger.info(f"\nğŸ¬ ë‚˜ë ˆì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì— ë§ì¶° ë¹„ë””ì˜¤ ë°°ì¹˜")
                logger.info(f"   ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜: {len(subtitle_data)}ê°œ")
                logger.info(f"   ë¹„ë””ì˜¤ ê°œìˆ˜: {len(processed_video_files)}ê°œ")

                # scenes ë°°ì—´ì´ ìˆìœ¼ë©´ scenes ê¸°ì¤€ìœ¼ë¡œ ë¹„ë””ì˜¤ ë°°ì¹˜
                merged_video = output_dir / 'merged_video.mp4'
                if scenes:
                    logger.info(f"   ğŸ“‹ scenes ë°°ì—´ ì‚¬ìš©: {len(scenes)}ê°œ ì”¬")
                    align_videos_to_scenes(processed_video_files, scenes, subtitle_data, merged_video)
                else:
                    logger.info(f"   ğŸ“‹ Whisper ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©")
                    align_videos_to_segments(processed_video_files, subtitle_data, merged_video)

                # ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ + ìë§‰ ì¶”ê°€
                final_with_audio = output_dir / 'final_with_narration.mp4'
                add_audio_to_video(merged_video, tts_audio, final_with_audio, narration_text, add_subtitles, subtitle_data)
                final_output = final_with_audio
            else:
                # Whisper ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ (ìˆœì°¨ ë³‘í•©)
                logger.warning(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì—†ìŒ, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë³‘í•©")
                merged_video = output_dir / 'merged_video.mp4'
                concatenate_videos(processed_video_files, merged_video)

                final_with_audio = output_dir / 'final_with_narration.mp4'
                add_audio_to_video(merged_video, tts_audio, final_with_audio, narration_text, add_subtitles, [])
                final_output = final_with_audio
        else:
            # ë‚˜ë ˆì´ì…˜ ì—†ì´ ë³‘í•©ë§Œ ìˆ˜í–‰
            logger.info(f"\nâ„¹ï¸ ë‚˜ë ˆì´ì…˜ ì—†ì´ ë³‘í•©ë§Œ ìˆ˜í–‰")
            merged_video = output_dir / 'merged_video.mp4'
            concatenate_videos(processed_video_files, merged_video)
            final_output = merged_video

        # titleì´ ìˆìœ¼ë©´ ìµœì¢… íŒŒì¼ëª…ì„ title.mp4ë¡œ ë³€ê²½
        if title:
            # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
            safe_title = re.sub(r'[<>:"/\\|?*]', '', title)
            final_output_with_title = output_dir / f"{safe_title}.mp4"

            # íŒŒì¼ ì´ë™ (ë¦¬ë„¤ì„)
            import shutil
            shutil.move(str(final_output), str(final_output_with_title))
            final_output = final_output_with_title
            logger.info(f"ğŸ“ íŒŒì¼ëª…ì„ ëŒ€ë³¸ ì œëª©ìœ¼ë¡œ ë³€ê²½: {safe_title}.mp4")

        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… ë¹„ë””ì˜¤ ë³‘í•© ì™„ë£Œ!")
        logger.info(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {final_output}")
        logger.info(f"{'='*60}\n")

        # ì„±ê³µ ì‘ë‹µ (stdoutìœ¼ë¡œ ëª…ì‹œì  ì¶œë ¥)
        result_json = json.dumps({
            "success": True,
            "output_video": str(final_output),
            "output_dir": str(output_dir)
        })
        sys.stdout.write(result_json + '\n')
        sys.stdout.flush()
        sys.exit(0)

    except Exception as e:
        logger.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc(file=sys.stdout)  # stderr ëŒ€ì‹  stdout ì‚¬ìš©

        error_json = json.dumps({
            "success": False,
            "error": str(e)
        })
        sys.stdout.write(error_json + '\n')
        sys.stdout.flush()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
