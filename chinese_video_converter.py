"""
ì¤‘êµ­ì–´ ì˜ìƒì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
1. ì¤‘êµ­ì–´ ìë§‰/ìŒì„± ì¶”ì¶œ
2. ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­
3. í•œêµ­ì–´ TTS ìƒì„±
4. ì˜ìƒ í•©ì„±

ì‚¬ìš©ë²•:
    python chinese_video_converter.py --input "video.mp4" --output-dir "output"
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
import subprocess
import asyncio
from typing import List, Dict, Optional
import tempfile
import shutil
import cv2
import numpy as np

# Windowsì—ì„œ UTF-8 ì¶œë ¥ì„ ìœ„í•´ stdoutì„ UTF-8ë¡œ ì¬ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    stream=sys.stdout,
    force=True
)
logger = logging.getLogger(__name__)

def should_stop(output_dir: Path) -> bool:
    """
    STOP íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì˜ìƒ ì œì‘ê³¼ ë™ì¼í•œ ë°©ì‹)

    Args:
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬

    Returns:
        bool: STOP íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
    """
    stop_file = Path(output_dir) / 'STOP'
    return stop_file.exists()

class CancelledException(Exception):
    """ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    pass

# OpenAI API (Whisper ë° TTS)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("âš ï¸ openai ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")

# Anthropic Claude API (ë²ˆì—­)
try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    logger.warning("âš ï¸ anthropic ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropic")

# Edge TTS (ëŒ€ì²´ ì˜µì…˜)
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except ImportError:
    EDGE_TTS_AVAILABLE = False
    logger.warning("âš ï¸ edge-tts ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def get_ffmpeg_path():
    """FFmpeg ê²½ë¡œ í™•ì¸"""
    try:
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
        if result.returncode == 0:
            return 'ffmpeg'
    except FileNotFoundError:
        pass

    # imageio-ffmpeg ì‹œë„
    try:
        import imageio_ffmpeg
        return imageio_ffmpeg.get_ffmpeg_exe()
    except ImportError:
        pass

    raise RuntimeError("FFmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. FFmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")


def get_video_dimensions(video_path: Path) -> tuple:
    """ë¹„ë””ì˜¤ í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° (width, height)"""
    try:
        ffmpeg = get_ffmpeg_path()
        ffprobe = ffmpeg.replace('ffmpeg', 'ffprobe')

        cmd = [
            ffprobe,
            '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height',
            '-of', 'csv=p=0',
            str(video_path)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            width, height = map(int, result.stdout.strip().split(','))
            return width, height
        return 1920, 1080  # ê¸°ë³¸ê°’

    except Exception as e:
        logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ í•´ìƒë„ í™•ì¸ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš© (1920x1080)")
        return 1920, 1080


def _remove_subtitle_vsr(input_video: Path, output_video: Path, x: int, y: int, w: int, h: int, output_dir: Path = None) -> bool:
    """
    video-subtitle-removerë¥¼ ì‚¬ìš©í•œ ìë§‰ ì œê±° (ê°€ì¥ íš¨ê³¼ì )

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        x, y, w, h: ìë§‰ ì˜ì—­
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("VSR ìë§‰ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")
        import sys
        vsr_dir = Path(__file__).parent / "video-subtitle-remover"
        backend_dir = vsr_dir / "backend"

        # ê²½ë¡œ ì¶”ê°€
        if str(vsr_dir) not in sys.path:
            sys.path.insert(0, str(vsr_dir))
        if str(backend_dir) not in sys.path:
            sys.path.insert(0, str(backend_dir))

        # video-subtitle-remover ì„í¬íŠ¸
        from backend.main import SubtitleRemover
        from backend import config

        logger.info(f"ğŸ¨ video-subtitle-remover (LAMA) ì´ˆê¸°í™” ì¤‘...")

        # ìë§‰ ì˜ì—­ ì„¤ì • (ymin, ymax, xmin, xmax í˜•ì‹ - íŠœí”Œ)
        sub_area = (y, y+h, x, x+w)

        # SubtitleRemover ì´ˆê¸°í™”
        remover = SubtitleRemover(
            vd_path=str(input_video),
            sub_area=sub_area
        )

        logger.info(f"âœ… LAMA ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        logger.info(f"ğŸ¬ ìë§‰ ì œê±° ì§„í–‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

        # ìë§‰ ì œê±° ì‹¤í–‰
        remover.run()

        # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ì›ë³¸ íŒŒì¼ëª… + _no_sub)
        result_path = Path(str(input_video).replace('.mp4', '_no_sub.mp4'))

        if result_path.exists():
            # ê²°ê³¼ íŒŒì¼ì„ output_videoë¡œ ë³µì‚¬
            shutil.copy2(result_path, output_video)
            logger.info(f"âœ… LAMA-VSR ìë§‰ ì œê±° ì™„ë£Œ")
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            result_path.unlink()
            return True
        else:
            logger.error(f"âŒ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {result_path}")
            return False

    except Exception as e:
        logger.error(f"âŒ LAMA-VSR ìë§‰ ì œê±° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def _remove_watermark_lama(input_video: Path, output_video: Path, x: int, y: int, w: int, h: int, output_dir: Path = None) -> bool:
    """
    LAMAë¥¼ ì‚¬ìš©í•œ ì›Œí„°ë§ˆí¬ ì œê±° (video-subtitle-removerì˜ LAMA ëª¨ë¸ ì‚¬ìš©)

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        x, y, w, h: ì›Œí„°ë§ˆí¬ ì˜ì—­
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("LAMA ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")
        import sys
        vsr_dir = Path(__file__).parent / "video-subtitle-remover"
        backend_dir = vsr_dir / "backend"

        # ê²½ë¡œ ì¶”ê°€
        if str(vsr_dir) not in sys.path:
            sys.path.insert(0, str(vsr_dir))
        if str(backend_dir) not in sys.path:
            sys.path.insert(0, str(backend_dir))

        # LAMA ëª¨ë¸ ê²½ë¡œ í™•ì¸
        lama_model_dir = backend_dir / "models" / "big-lama"
        if not lama_model_dir.exists():
            logger.error(f"âŒ LAMA ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {lama_model_dir}")
            return False

        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_files = list(lama_model_dir.glob("big-lama_*.pt"))
        if len(model_files) == 0:
            logger.error(f"âŒ LAMA ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {lama_model_dir}")
            return False

        logger.info(f"âœ… LAMA ëª¨ë¸ íŒŒì¼ ë°œê²¬: {len(model_files)}ê°œ")

        # LAMA ì¸í˜ì¸íŠ¸ ì„í¬íŠ¸
        from backend.inpaint.lama_inpaint import LamaInpaint
        import torch
        import cv2
        import numpy as np

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path(tempfile.mkdtemp())
        frames_dir = temp_dir / "frames"
        mask_dir = temp_dir / "masks"
        inpaint_dir = temp_dir / "inpainted"

        frames_dir.mkdir(exist_ok=True)
        mask_dir.mkdir(exist_ok=True)
        inpaint_dir.mkdir(exist_ok=True)

        try:
            ffmpeg = get_ffmpeg_path()

            # 1. í”„ë ˆì„ ì¶”ì¶œ
            logger.info(f"ğŸï¸ í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
            cmd = [
                ffmpeg, '-i', str(input_video),
                '-vf', 'fps=30',  # 30fpsë¡œ ê³ ì •
                str(frames_dir / 'frame_%06d.png')
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")
                return False

            # í”„ë ˆì„ íŒŒì¼ ëª©ë¡
            frame_files = sorted(frames_dir.glob("frame_*.png"))
            total_frames = len(frame_files)
            logger.info(f"âœ… {total_frames}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")

            # 2. ë§ˆìŠ¤í¬ ìƒì„±
            logger.info(f"ğŸ¨ ë§ˆìŠ¤í¬ ìƒì„± ì¤‘...")
            first_frame = cv2.imread(str(frame_files[0]))
            mask = np.zeros(first_frame.shape[:2], dtype=np.uint8)
            mask[y:y+h, x:x+w] = 255

            # ëª¨ë“  í”„ë ˆì„ì— ë™ì¼í•œ ë§ˆìŠ¤í¬ ì ìš©
            for frame_file in frame_files:
                mask_file = mask_dir / frame_file.name
                cv2.imwrite(str(mask_file), mask)

            logger.info(f"âœ… {total_frames}ê°œ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")

            # 3. LAMA ì¸í˜ì¸íŒ… ì´ˆê¸°í™”
            logger.info(f"ğŸ¤– LAMA ëª¨ë¸ ë¡œë”© ì¤‘...")
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            logger.info(f"   ë””ë°”ì´ìŠ¤: {device}")

            lama_inpaint = LamaInpaint(device=device)
            logger.info(f"âœ… LAMA ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            # 4. í”„ë ˆì„ë³„ ì¸í˜ì¸íŒ…
            logger.info(f"ğŸ¨ LAMA ì¸í˜ì¸íŒ… ì§„í–‰ ì¤‘...")
            for i, frame_file in enumerate(frame_files, 1):
                # STOP ì²´í¬ (10í”„ë ˆì„ë§ˆë‹¤)
                if i % 10 == 0 and output_dir and should_stop(output_dir):
                    raise CancelledException(f"LAMA ì¸í˜ì¸íŒ… ì¤‘ ì‘ì—… ì·¨ì†Œë¨ ({i}/{total_frames} í”„ë ˆì„)")

                if i % 30 == 0 or i == total_frames:
                    logger.info(f"   ì²˜ë¦¬ ì¤‘: {i}/{total_frames} í”„ë ˆì„ ({i*100//total_frames}%)")

                frame = cv2.imread(str(frame_file))
                mask_file = mask_dir / frame_file.name
                mask_img = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)

                # LAMA ì¸í˜ì¸íŒ… ìˆ˜í–‰
                result_frame = lama_inpaint.inpaint(frame, mask_img)

                # ê²°ê³¼ ì €ì¥
                output_frame_file = inpaint_dir / frame_file.name
                cv2.imwrite(str(output_frame_file), result_frame)

            logger.info(f"âœ… {total_frames}ê°œ í”„ë ˆì„ ì¸í˜ì¸íŒ… ì™„ë£Œ")

            # 5. ë¹„ë””ì˜¤ ì¬ì¡°ë¦½
            logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì¤‘...")
            cmd = [
                ffmpeg, '-framerate', '30',
                '-i', str(inpaint_dir / 'frame_%06d.png'),
                '-i', str(input_video),  # ì˜¤ë””ì˜¤ ì†ŒìŠ¤
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '18',
                '-pix_fmt', 'yuv420p',
                '-c:a', 'copy',  # ì˜¤ë””ì˜¤ ë³µì‚¬
                '-map', '0:v:0',  # ë¹„ë””ì˜¤ëŠ” ì²« ë²ˆì§¸ ì…ë ¥
                '-map', '1:a:0?',  # ì˜¤ë””ì˜¤ëŠ” ë‘ ë²ˆì§¸ ì…ë ¥ (ìˆìœ¼ë©´)
                '-y',
                str(output_video)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info(f"âœ… LAMA ì›Œí„°ë§ˆí¬ ì œê±° ì™„ë£Œ")
            return True

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        logger.error(f"âŒ LAMA ì›Œí„°ë§ˆí¬ ì œê±° ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False


def _remove_watermark_sttn(input_video: Path, output_video: Path, x: int, y: int, w: int, h: int, output_dir: Path = None) -> bool:
    """
    STTNì„ ì‚¬ìš©í•œ ì›Œí„°ë§ˆí¬ ì œê±° (video-subtitle-remover ì‚¬ìš©)

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        x, y, w, h: ì›Œí„°ë§ˆí¬ ì˜ì—­
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("STTN ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")
        # video-subtitle-remover ê²½ë¡œ
        vsr_dir = Path(__file__).parent / "video-subtitle-remover"
        if not vsr_dir.exists():
            logger.error(f"âŒ video-subtitle-remover ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {vsr_dir}")
            return False

        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_path = vsr_dir / "backend" / "models" / "sttn" / "infer_model.pth"
        if not model_path.exists():
            logger.error(f"âŒ STTN ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return False

        logger.info("ğŸš€ STTN ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘...")

        # video-subtitle-removerì˜ main.pyë¥¼ ì§ì ‘ í˜¸ì¶œ
        backend_dir = vsr_dir / "backend"
        main_script = backend_dir / "main.py"

        if not main_script.exists():
            logger.error(f"âŒ main.pyê°€ ì—†ìŠµë‹ˆë‹¤: {main_script}")
            return False

        # Python ëª…ë ¹ì–´ ì‹¤í–‰
        cmd = [
            sys.executable,
            str(main_script),
            '--input_video', str(input_video),
            '--output_video', str(output_video),
            '--x', str(x),
            '--y', str(y),
            '--w', str(w),
            '--h', str(h),
            '--use_sttn'
        ]

        logger.info(f"   ì‹¤í–‰: {' '.join(cmd)}")

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(backend_dir))

        if result.returncode == 0:
            logger.info("âœ… STTN ì›Œí„°ë§ˆí¬ ì œê±° ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ STTN ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
            return False

    except Exception as e:
        logger.error(f"âŒ STTN ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _remove_watermark_e2fgvi(input_video: Path, output_video: Path, x: int, y: int, w: int, h: int, output_dir: Path = None) -> bool:
    """
    E2FGVIë¥¼ ì‚¬ìš©í•œ ì›Œí„°ë§ˆí¬ ì œê±° (ì†ë„ì™€ í’ˆì§ˆì˜ ê· í˜•)

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        x, y, w, h: ì›Œí„°ë§ˆí¬ ì˜ì—­
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("E2FGVI ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")
        # E2FGVI ê²½ë¡œ
        erase_subtitles_dir = Path(__file__).parent / "EraseSubtitles"
        if not erase_subtitles_dir.exists():
            logger.error(f"âŒ EraseSubtitles ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {erase_subtitles_dir}")
            return False

        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_path = erase_subtitles_dir / "E2FGVI" / "release_model" / "E2FGVI-CVPR22.pth"
        if not model_path.exists():
            logger.error(f"âŒ E2FGVI ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            logger.error(f"   ë‹¤ìš´ë¡œë“œ: https://drive.google.com/file/d/1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9/view")
            return False

        # sys.pathì— ì¶”ê°€
        import sys
        if str(erase_subtitles_dir) not in sys.path:
            sys.path.insert(0, str(erase_subtitles_dir))

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path(tempfile.mkdtemp())
        frames_dir = temp_dir / "frames"
        masks_dir = temp_dir / "masks"
        frames_dir.mkdir(exist_ok=True)
        masks_dir.mkdir(exist_ok=True)

        try:
            # FFmpegë¡œ í”„ë ˆì„ ì¶”ì¶œ
            ffmpeg = get_ffmpeg_path()
            logger.info("ğŸ¬ í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")

            extract_cmd = [
                ffmpeg, '-i', str(input_video),
                '-qscale:v', '2',
                str(frames_dir / '%d.jpg')
            ]

            result = subprocess.run(extract_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")
                return False

            frame_files = sorted(frames_dir.glob('*.jpg'), key=lambda p: int(p.stem))
            if not frame_files:
                logger.error("âŒ ì¶”ì¶œëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
                return False

            logger.info(f"âœ… {len(frame_files)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")

            # ë§ˆìŠ¤í¬ ìƒì„± (ëª¨ë“  í”„ë ˆì„ì— ë™ì¼í•œ ë§ˆìŠ¤í¬)
            logger.info("ğŸ¨ ë§ˆìŠ¤í¬ ìƒì„± ì¤‘...")
            first_frame = cv2.imread(str(frame_files[0]))
            height_vid, width_vid = first_frame.shape[:2]

            # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ìƒì„± (ì›Œí„°ë§ˆí¬ ì˜ì—­ì„ í°ìƒ‰ìœ¼ë¡œ)
            mask = np.zeros((height_vid, width_vid), dtype=np.uint8)
            mask[y:y+h, x:x+w] = 255

            # ëª¨ë“  í”„ë ˆì„ì— ëŒ€í•´ ë™ì¼í•œ ë§ˆìŠ¤í¬ ì €ì¥
            for i in range(len(frame_files)):
                cv2.imwrite(str(masks_dir / f"{i}.png"), mask)

            logger.info(f"âœ… {len(frame_files)}ê°œ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")

            # E2FGVI inpaint í•¨ìˆ˜ import
            from inpaint import set_up_model, get_images_and_masks, preprocess_images_and_masks, inpaint

            logger.info("ğŸ¤– E2FGVI ëª¨ë¸ ë¡œë“œ ì¤‘...")
            model, device = set_up_model()

            logger.info("ğŸ¨ E2FGVI ì¸í˜ì¸íŒ… ì‹œì‘...")
            frames, masks = get_images_and_masks(str(frames_dir), str(masks_dir))
            f, binary_masks, imgs, m = preprocess_images_and_masks(frames, masks, device)
            video_length = len(frames)
            comp_frames = inpaint(f, binary_masks, imgs, m, video_length, model)

            # ê²°ê³¼ í”„ë ˆì„ ì €ì¥
            logger.info("ğŸ’¾ ê²°ê³¼ í”„ë ˆì„ ì €ì¥ ì¤‘...")
            output_frames_dir = temp_dir / "output_frames"
            output_frames_dir.mkdir(exist_ok=True)

            ind = -1
            for i in range(video_length):
                if i % 30 == 0:
                    ind += 1
                frame = comp_frames[ind][i % 30]
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                cv2.imwrite(str(output_frames_dir / f"{i:05d}.jpg"), frame_bgr)

            # FFmpegë¡œ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½
            logger.info("ğŸ¬ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì¤‘...")

            fps = get_video_fps(input_video)

            assemble_cmd = [
                ffmpeg, '-y',
                '-framerate', str(fps),
                '-i', str(output_frames_dir / '%05d.jpg'),
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-crf', '18',
                str(output_video)
            ]

            result = subprocess.run(assemble_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info(f"âœ… E2FGVI ì²˜ë¦¬ ì™„ë£Œ: {output_video}")
            return True

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_dir.exists():
                shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        logger.error(f"âŒ E2FGVI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _remove_watermark_propainter(input_video: Path, output_video: Path, x: int, y: int, w: int, h: int, output_dir: Path = None) -> bool:
    """
    ProPainterë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ì›Œí„°ë§ˆí¬ ì œê±°

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        x, y, w, h: ì›Œí„°ë§ˆí¬ ì˜ì—­
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("ProPainter ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")
        # ProPainter ê²½ë¡œ
        propainter_dir = Path(__file__).parent / "ProPainter"
        if not propainter_dir.exists():
            logger.error(f"âŒ ProPainter ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {propainter_dir}")
            return False

        # ProPainterëŠ” sys.pathì— ì¶”ê°€í•´ì•¼ ëª¨ë“ˆì„ importí•  ìˆ˜ ìˆìŒ
        import sys
        if str(propainter_dir) not in sys.path:
            sys.path.insert(0, str(propainter_dir))

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path(tempfile.mkdtemp())
        mask_path = temp_dir / "mask.png"
        frames_dir = temp_dir / "frames"
        frames_dir.mkdir(exist_ok=True)

        try:
            # 1. ë§ˆìŠ¤í¬ ìƒì„± (ì›Œí„°ë§ˆí¬ ì˜ì—­ì„ í°ìƒ‰ìœ¼ë¡œ)
            logger.info(f"ğŸ¨ ë§ˆìŠ¤í¬ ìƒì„± ì¤‘...")

            # ë¹„ë””ì˜¤ì—ì„œ ì²« í”„ë ˆì„ ì½ì–´ì„œ í•´ìƒë„ í™•ì¸
            cap = cv2.VideoCapture(str(input_video))
            ret, first_frame = cap.read()
            cap.release()

            if not ret:
                logger.error("âŒ ë¹„ë””ì˜¤ ì²« í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                return False

            height_vid, width_vid = first_frame.shape[:2]

            # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ìƒì„± (ì „ì²´ ê²€ì€ìƒ‰, ì›Œí„°ë§ˆí¬ ì˜ì—­ë§Œ í°ìƒ‰)
            mask = np.zeros((height_vid, width_vid), dtype=np.uint8)
            mask[y:y+h, x:x+w] = 255
            cv2.imwrite(str(mask_path), mask)

            logger.info(f"âœ… ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ: {mask_path}")

            # 2. ProPainter ì‹¤í–‰
            logger.info(f"ğŸš€ ProPainter ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

            # ProPainter inference ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            inference_script = propainter_dir / "inference_propainter.py"
            output_dir = temp_dir / "propainter_output"

            cmd = [
                sys.executable,
                str(inference_script),
                '--video', str(input_video),
                '--mask', str(mask_path),
                '--output', str(output_dir),
                '--fp16',  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ fp16 ì‚¬ìš©
                '--width', str(width_vid),
                '--height', str(height_vid)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
                cwd=str(propainter_dir)
            )

            if result.returncode != 0:
                logger.error(f"âŒ ProPainter ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
                return False

            # 3. ê²°ê³¼ íŒŒì¼ ì°¾ê¸° ë° ë³µì‚¬
            # ProPainterëŠ” ê²°ê³¼ë¥¼ output_dirì— ì €ì¥
            result_files = list(output_dir.glob('*.mp4'))
            if not result_files:
                logger.error("âŒ ProPainter ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False

            # ê²°ê³¼ íŒŒì¼ ë³µì‚¬
            shutil.copy(result_files[0], output_video)
            logger.info(f"âœ… ProPainter ì›Œí„°ë§ˆí¬ ì œê±° ì™„ë£Œ")

            return True

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        logger.error(f"âŒ ProPainter ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def remove_watermark_ai(input_video: Path, output_video: Path, watermark_region: tuple = None, quality_mode: str = 'lama-vsr', output_dir: Path = None) -> bool:
    """
    AI ê¸°ë°˜ ì›Œí„°ë§ˆí¬ ì œê±°

    Args:
        input_video: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_video: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        watermark_region: (x, y, w, h) ì›Œí„°ë§ˆí¬ ì˜ì—­, Noneì´ë©´ ìë™ ê°ì§€ (í•˜ë‹¨ ì¤‘êµ­ì–´ ìë§‰)
        quality_mode:
            - 'sttn' (ê¸°ë³¸ê°’, ì†ë„ì™€ í’ˆì§ˆ ê· í˜•, ë¹ ë¦„)
            - 'e2fgvi' (E2FGVI, ëª¨ë¸ í•„ìš”)
            - 'fast' (OpenCV Telea, ê°€ì¥ ë¹ ë¦„)
            - 'high' (ProPainter, ê°€ì¥ ëŠë¦¼)
        output_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (STOP íŒŒì¼ ì²´í¬ìš©)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # STOP ì²´í¬
        if output_dir and should_stop(output_dir):
            raise CancelledException("ì›Œí„°ë§ˆí¬ ì œê±° ì‹œì‘ ì „ ì‘ì—… ì·¨ì†Œë¨")

        ffmpeg = get_ffmpeg_path()

        # ë¹„ë””ì˜¤ í•´ìƒë„ í™•ì¸
        width, height = get_video_dimensions(input_video)
        logger.info(f"ğŸ“ ë¹„ë””ì˜¤ í•´ìƒë„: {width}x{height}")

        # ì›Œí„°ë§ˆí¬ ì˜ì—­ ê²°ì •
        if watermark_region is None:
            # ì¤‘êµ­ì–´ ìë§‰ì€ ë³´í†µ í™”ë©´ í•˜ë‹¨ì— ê³ ì • ìœ„ì¹˜
            subtitle_height = 150
            x = 0
            y = height - subtitle_height
            w = width
            h = subtitle_height
            logger.info(f"ğŸ¤– ì¤‘êµ­ì–´ ìë§‰ ì˜ì—­ ìë™ ê°ì§€")
            logger.info(f"   ì˜ì—­: x={x}, y={y}, w={w}, h={h} (í•˜ë‹¨ {subtitle_height}px)")
        else:
            x, y, w, h = watermark_region
            logger.info(f"ğŸ¤– ì›Œí„°ë§ˆí¬ ì œê±° ì¤‘ (ì§€ì • ì˜ì—­: x={x}, y={y}, w={w}, h={h})")

        # í’ˆì§ˆ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë°©ë²• ê²°ì •
        if quality_mode == 'lama-vsr':
            # video-subtitle-removerì˜ LAMA ì‚¬ìš© (ê°€ì¥ íš¨ê³¼ì ì¸ ìë§‰ ì œê±°)
            logger.info(f"   ë°©ë²•: LAMA-VSR (AI ìë§‰ ì œê±° ì „ìš©)")
            return _remove_subtitle_vsr(input_video, output_video, x, y, w, h, output_dir)

        elif quality_mode == 'lama':
            # LAMA (Big-LaMa) AI ì¸í˜ì¸íŒ… (ê· í˜•ì¡íŒ ì†ë„ì™€ í’ˆì§ˆ)
            logger.info(f"   ë°©ë²•: LAMA (AI ì¸í˜ì¸íŒ…, ê· í˜•ì¡íŒ ì„±ëŠ¥)")
            return _remove_watermark_lama(input_video, output_video, x, y, w, h, output_dir)

        elif quality_mode == 'black':
            # ê²€ì€ìƒ‰ìœ¼ë¡œ ê°€ë¦¬ê¸° (ê°€ì¥ ë¹ ë¦„, 1-2ì´ˆ)
            logger.info(f"   ë°©ë²•: ê²€ì€ìƒ‰ ë°•ìŠ¤ë¡œ ê°€ë¦¬ê¸° (ì´ˆê³ ì†)")

            cmd = [
                ffmpeg, '-i', str(input_video),
                '-vf', f'drawbox=x={x}:y={y}:w={w}:h={h}:color=black:t=fill',
                '-c:a', 'copy',
                '-y',
                str(output_video)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"âœ… ê²€ì€ìƒ‰ ë°•ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ FFmpeg ì²˜ë¦¬ ì‹¤íŒ¨: {result.stderr}")
                return False

        elif quality_mode == 'sttn':
            logger.info(f"   ë°©ë²•: STTN (Spatial-Temporal Transformer)")
            return _remove_watermark_sttn(input_video, output_video, x, y, w, h, output_dir)
        elif quality_mode == 'e2fgvi':
            logger.info(f"   ë°©ë²•: E2FGVI (Flow-Guided Video Inpainting)")
            return _remove_watermark_e2fgvi(input_video, output_video, x, y, w, h, output_dir)
        elif quality_mode == 'high':
            logger.info(f"   ë°©ë²•: ProPainter (ê³ í’ˆì§ˆ AI ì¸í˜ì¸íŒ…)")
            return _remove_watermark_propainter(input_video, output_video, x, y, w, h, output_dir)
        else:  # fast
            logger.info(f"   ë°©ë²•: OpenCV Inpainting (Telea ì•Œê³ ë¦¬ì¦˜)")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path(tempfile.mkdtemp())
        frames_dir = temp_dir / "frames"
        frames_dir.mkdir(exist_ok=True)

        try:
            # 1. ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
            logger.info(f"ğŸï¸ ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ ë° ì›Œí„°ë§ˆí¬ ì œê±° ì¤‘...")
            cmd = [
                ffmpeg,
                '-i', str(input_video),
                '-qscale:v', '2',  # ê³ í’ˆì§ˆ ìœ ì§€
                str(frames_dir / 'frame_%05d.png')
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            if result.returncode != 0:
                raise Exception(f"í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")

            # 2. ê° í”„ë ˆì„ì— ì¸í˜ì¸íŒ… ì ìš©
            frame_files = sorted(frames_dir.glob('frame_*.png'))
            total_frames = len(frame_files)

            # ë§ˆìŠ¤í¬ ìƒì„± (ì›Œí„°ë§ˆí¬ ì˜ì—­ì„ í°ìƒ‰ìœ¼ë¡œ)
            mask = np.zeros((height, width), dtype=np.uint8)
            mask[y:y+h, x:x+w] = 255

            for idx, frame_file in enumerate(frame_files):
                # STOP ì²´í¬ (10í”„ë ˆì„ë§ˆë‹¤)
                if idx % 10 == 0 and output_dir and should_stop(output_dir):
                    raise CancelledException(f"OpenCV ì¸í˜ì¸íŒ… ì¤‘ ì‘ì—… ì·¨ì†Œë¨ ({idx+1}/{total_frames} í”„ë ˆì„)")

                # í”„ë ˆì„ ì½ê¸°
                frame = cv2.imread(str(frame_file))

                # ì¸í˜ì¸íŒ… ì ìš© (Telea ì•Œê³ ë¦¬ì¦˜, radius=3)
                inpainted = cv2.inpaint(frame, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

                # ê²°ê³¼ ì €ì¥ (ì›ë³¸ íŒŒì¼ ë®ì–´ì“°ê¸°)
                cv2.imwrite(str(frame_file), inpainted)

                # ì§„í–‰ë¥  ì¶œë ¥ (30í”„ë ˆì„ë§ˆë‹¤)
                if (idx + 1) % 30 == 0 or (idx + 1) == total_frames:
                    progress = (idx + 1) / total_frames * 100
                    logger.info(f"   ì²˜ë¦¬ ì¤‘: {idx+1}/{total_frames} í”„ë ˆì„ ({progress:.1f}%)")

            logger.info(f"âœ… í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ: {total_frames}ê°œ í”„ë ˆì„")

            # 3. í”„ë ˆì„ì„ ë¹„ë””ì˜¤ë¡œ ì¬ì¡°ë¦½
            logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì¤‘...")
            cmd = [
                ffmpeg,
                '-framerate', '30',  # ì›ë³¸ í”„ë ˆì„ë ˆì´íŠ¸
                '-i', str(frames_dir / 'frame_%05d.png'),
                '-i', str(input_video),  # ì›ë³¸ ë¹„ë””ì˜¤ (ì˜¤ë””ì˜¤ìš©)
                '-map', '0:v',  # ìƒˆ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
                '-map', '1:a',  # ì›ë³¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
                '-c:a', 'copy',
                '-pix_fmt', 'yuv420p',
                '-y',
                str(output_video)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            if result.returncode != 0:
                raise Exception(f"ë¹„ë””ì˜¤ ì¬ì¡°ë¦½ ì‹¤íŒ¨: {result.stderr}")

            logger.info(f"âœ… OpenCV Inpainting ì›Œí„°ë§ˆí¬ ì œê±° ì™„ë£Œ")
            return True

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        logger.error(f"âŒ ì›Œí„°ë§ˆí¬ ì œê±° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë³µì‚¬
        try:
            shutil.copy(input_video, output_video)
        except:
            pass
        return True


def extract_audio(video_path: Path, output_audio: Path) -> bool:
    """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
    try:
        ffmpeg = get_ffmpeg_path()
        logger.info(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {video_path.name}")

        cmd = [
            ffmpeg,
            '-i', str(video_path),
            '-vn',  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì œì™¸
            '-acodec', 'pcm_s16le',  # WAV í¬ë§·
            '-ar', '16000',  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
            '-ac', '1',  # ëª¨ë…¸
            '-y',  # ë®ì–´ì“°ê¸°
            str(output_audio)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}")
            return False

        logger.info(f"âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {output_audio.name}")
        return True

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return False


def transcribe_audio_whisper(audio_path: Path, language: str = 'zh') -> Optional[List[Dict]]:
    """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì „ì‚¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)"""
    try:
        import whisper
        logger.info(f"ğŸ¤ Whisperë¡œ ìŒì„± ì¸ì‹ ì¤‘ (ì–¸ì–´: {language})...")

        # ëª¨ë¸ ë¡œë“œ (medium ì¶”ì²œ, ì •í™•ë„ì™€ ì†ë„ ê· í˜•)
        model = whisper.load_model("medium")

        # ì „ì‚¬
        result = model.transcribe(
            str(audio_path),
            language=language,
            task='transcribe',
            verbose=False
        )

        segments = []
        for segment in result['segments']:
            segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'text': segment['text'].strip()
            })

        logger.info(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return segments

    except ImportError:
        logger.error("âŒ whisper ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai-whisper")
        return None
    except Exception as e:
        logger.error(f"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
        return None


def transcribe_audio_openai(audio_path: Path) -> Optional[List[Dict]]:
    """OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì „ì‚¬"""
    if not OPENAI_AVAILABLE:
        logger.error("âŒ OpenAI ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    try:
        client = OpenAI()
        logger.info(f"ğŸ¤ OpenAI Whisper APIë¡œ ìŒì„± ì¸ì‹ ì¤‘...")

        with open(audio_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )

        segments = []
        if hasattr(transcript, 'segments'):
            for segment in transcript.segments:
                segments.append({
                    'start': segment['start'],
                    'end': segment['end'],
                    'text': segment['text'].strip()
                })
        else:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ëŠ” ê²½ìš°
            segments.append({
                'start': 0,
                'end': 0,
                'text': transcript.text
            })

        logger.info(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return segments

    except Exception as e:
        logger.error(f"âŒ OpenAI ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
        return None


def translate_segments_claude(segments: List[Dict], source_lang: str = 'zh', target_lang: str = 'ko') -> List[Dict]:
    """Claude APIë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¼ê´„ ë²ˆì—­ (ë¹ ë¥´ê³  ì €ë ´)"""
    if not ANTHROPIC_AVAILABLE:
        logger.error("âŒ Anthropic ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return segments

    try:
        client = Anthropic()
        logger.info(f"ğŸŒ Claudeë¡œ ë²ˆì—­ ì¤‘: {source_lang} â†’ {target_lang} ({len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")

        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ JSON í˜•íƒœë¡œ í•œ ë²ˆì— ë³´ë‚´ê¸°
        texts_to_translate = []
        for i, segment in enumerate(segments):
            texts_to_translate.append({
                'id': i,
                'text': segment['text']
            })

        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        import json
        batch_input = json.dumps(texts_to_translate, ensure_ascii=False, indent=2)

        # Claude API í˜¸ì¶œ (í•œ ë²ˆì— ì „ì²´ ë²ˆì—­)
        message = client.messages.create(
            model="claude-3-5-haiku-20241022",  # ê°€ì¥ ì €ë ´í•˜ê³  ë¹ ë¥¸ ëª¨ë¸
            max_tokens=8000,
            temperature=0.3,
            messages=[
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ JSON ë°°ì—´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ {source_lang}ì—ì„œ {target_lang}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.
ê°™ì€ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ë˜, text í•„ë“œë§Œ ë²ˆì—­ëœ ë‚´ìš©ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ë²ˆì—­í•˜ì„¸ìš”.

ì…ë ¥:
{batch_input}

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
[
  {{"id": 0, "text": "ë²ˆì—­ëœ í…ìŠ¤íŠ¸"}},
  {{"id": 1, "text": "ë²ˆì—­ëœ í…ìŠ¤íŠ¸"}},
  ...
]

JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ë¶™ì´ì§€ ë§ˆì„¸ìš”."""
                }
            ]
        )

        # ì‘ë‹µ íŒŒì‹±
        response_text = message.content[0].text.strip()

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` ë“± ì œê±°)
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0].strip()
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0].strip()

        translated_data = json.loads(response_text)

        # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ì— ë§¤í•‘
        translated_segments = []
        for segment in segments:
            segment_id = segments.index(segment)
            translated_item = next((item for item in translated_data if item['id'] == segment_id), None)

            if translated_item:
                translated_text = translated_item['text']
            else:
                translated_text = segment['text']  # ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ìœ ì§€

            translated_segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'original': segment['text'],
                'translated': translated_text
            })

        logger.info(f"âœ… ë²ˆì—­ ì™„ë£Œ: {len(translated_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

        # ìƒ˜í”Œ ì¶œë ¥
        for i in range(min(3, len(translated_segments))):
            logger.info(f"  [{i+1}] {translated_segments[i]['original'][:40]}...")
            logger.info(f"      â†’ {translated_segments[i]['translated'][:40]}...")

        return translated_segments

    except Exception as e:
        logger.error(f"âŒ Claude ë²ˆì—­ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return segments


def translate_segments_openai(segments: List[Dict], source_lang: str = 'zh', target_lang: str = 'ko') -> List[Dict]:
    """OpenAI APIë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¼ê´„ ë²ˆì—­ (ëŒ€ì²´ ì˜µì…˜)"""
    if not OPENAI_AVAILABLE:
        logger.error("âŒ OpenAI ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return segments

    try:
        client = OpenAI()
        logger.info(f"ğŸŒ OpenAIë¡œ ë²ˆì—­ ì¤‘: {source_lang} â†’ {target_lang} ({len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")

        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë³´ë‚´ê¸°
        import json
        texts_to_translate = []
        for i, segment in enumerate(segments):
            texts_to_translate.append({
                'id': i,
                'text': segment['text']
            })

        batch_input = json.dumps(texts_to_translate, ensure_ascii=False, indent=2)

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"ë‹¹ì‹ ì€ {source_lang}ì—ì„œ {target_lang}ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ JSON ë°°ì—´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•˜ê³  ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{batch_input}"""
                }
            ],
            temperature=0.3
        )

        response_text = response.choices[0].message.content.strip()

        # JSON ì¶”ì¶œ
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0].strip()
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0].strip()

        translated_data = json.loads(response_text)

        translated_segments = []
        for segment in segments:
            segment_id = segments.index(segment)
            translated_item = next((item for item in translated_data if item['id'] == segment_id), None)

            translated_segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'original': segment['text'],
                'translated': translated_item['text'] if translated_item else segment['text']
            })

        logger.info(f"âœ… ë²ˆì—­ ì™„ë£Œ: {len(translated_segments)}ê°œ")
        return translated_segments

    except Exception as e:
        logger.error(f"âŒ OpenAI ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return segments


async def generate_tts_edge(text: str, output_path: Path, voice: str = 'ko-KR-SunHiNeural') -> bool:
    """Edge TTSë¡œ ìŒì„± ìƒì„±

    ì¶”ì²œ í•œêµ­ì–´ ìŒì„±:
    - ko-KR-SunHiNeural: ë°ê³  ê²½ì¾Œí•œ ì—¬ì„± ìŒì„± (ê¸°ë³¸)
    - ko-KR-JiMinNeural: ë¶€ë“œëŸ¬ìš´ ì—¬ì„± ìŒì„±
    """
    if not EDGE_TTS_AVAILABLE:
        logger.error("âŒ edge-tts ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(str(output_path))
        return True
    except Exception as e:
        logger.error(f"âŒ Edge TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def generate_tts_openai(text: str, output_path: Path, voice: str = 'shimmer') -> bool:
    """OpenAI TTSë¡œ ìŒì„± ìƒì„±

    ìŒì„± ì˜µì…˜:
    - shimmer: ë°ê³  ê²½ì¾Œí•œ ì—¬ì„± ìŒì„± (ì¶”ì²œ)
    - nova: í™œê¸°ì°¬ ì—¬ì„± ìŒì„±
    - alloy: ì¤‘ì„±ì ì´ê³  ë¶€ë“œëŸ¬ìš´ ìŒì„±
    """
    if not OPENAI_AVAILABLE:
        logger.error("âŒ OpenAI ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        client = OpenAI()

        response = client.audio.speech.create(
            model="tts-1-hd",  # HD í’ˆì§ˆ ì‚¬ìš©
            voice=voice,
            input=text,
            speed=1.0  # ì†ë„ (0.25 ~ 4.0)
        )

        response.stream_to_file(str(output_path))
        return True

    except Exception as e:
        logger.error(f"âŒ OpenAI TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False


async def generate_audio_for_segments(segments: List[Dict], output_dir: Path, use_openai: bool = False) -> List[Dict]:
    """ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± (ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ ë°˜í™˜)"""
    logger.info(f"ğŸ¤ TTS ìƒì„± ì¤‘: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    audio_segments = []

    for i, segment in enumerate(segments, 1):
        audio_path = output_dir / f"segment_{i:03d}.mp3"
        text = segment.get('translated', segment.get('text', ''))

        if not text:
            logger.warning(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {i}: í…ìŠ¤íŠ¸ ì—†ìŒ")
            continue

        logger.info(f"  [{i}/{len(segments)}] TTS ìƒì„±: {text[:50]}...")

        success = False
        if EDGE_TTS_AVAILABLE:
            success = await generate_tts_edge(text, audio_path)
        elif use_openai and OPENAI_AVAILABLE:
            logger.warning(f"âš ï¸ Edge TTS ì‚¬ìš© ë¶ˆê°€, OpenAI TTS ì‚¬ìš© (ìœ ë£Œ)")
            success = generate_tts_openai(text, audio_path)

        if success and audio_path.exists():
            # ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
            try:
                import subprocess
                ffmpeg = get_ffmpeg_path()
                result = subprocess.run(
                    [ffmpeg, '-i', str(audio_path)],
                    capture_output=True,
                    text=True
                )
                # FFmpeg stderrì—ì„œ Duration ì¶”ì¶œ
                duration_match = None
                for line in result.stderr.split('\n'):
                    if 'Duration:' in line:
                        import re
                        duration_match = re.search(r'Duration: (\d{2}):(\d{2}):(\d{2}\.\d{2})', line)
                        if duration_match:
                            h, m, s = duration_match.groups()
                            actual_duration = int(h) * 3600 + int(m) * 60 + float(s)
                            break

                if duration_match:
                    audio_segments.append({
                        'path': audio_path,
                        'text': text,
                        'original_start': segment['start'],
                        'original_end': segment['end'],
                        'actual_duration': actual_duration
                    })
                else:
                    # Durationì„ ëª» ì°¾ìœ¼ë©´ ì›ë³¸ ê¸¸ì´ ì‚¬ìš©
                    audio_segments.append({
                        'path': audio_path,
                        'text': text,
                        'original_start': segment['start'],
                        'original_end': segment['end'],
                        'actual_duration': segment['end'] - segment['start']
                    })
            except Exception as e:
                logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • ì‹¤íŒ¨ (ì›ë³¸ ê¸¸ì´ ì‚¬ìš©): {e}")
                audio_segments.append({
                    'path': audio_path,
                    'text': text,
                    'original_start': segment['start'],
                    'original_end': segment['end'],
                    'actual_duration': segment['end'] - segment['start']
                })
        else:
            logger.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ {i} TTS ìƒì„± ì‹¤íŒ¨")

    logger.info(f"âœ… TTS ìƒì„± ì™„ë£Œ: {len(audio_segments)}ê°œ íŒŒì¼")
    return audio_segments


def merge_audio_segments(audio_segments: List[Dict], output_audio: Path) -> bool:
    """ì„¸ê·¸ë¨¼íŠ¸ ì˜¤ë””ì˜¤ë¥¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°"""
    try:
        ffmpeg = get_ffmpeg_path()
        logger.info(f"ğŸ”Š ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘...")

        if len(audio_segments) == 0:
            logger.error("âŒ ë³‘í•©í•  ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        list_file = output_audio.parent / "audio_list.txt"
        with open(list_file, 'w', encoding='utf-8') as f:
            for seg in audio_segments:
                f.write(f"file '{seg['path'].absolute()}'\n")

        cmd = [
            ffmpeg,
            '-f', 'concat',
            '-safe', '0',
            '-i', str(list_file),
            '-c', 'copy',
            '-y',
            str(output_audio)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨: {result.stderr}")
            return False

        logger.info(f"âœ… ì˜¤ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_audio.name}")

        # ì •ë¦¬
        list_file.unlink()

        return True

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ë³‘í•© ì˜¤ë¥˜: {e}")
        return False


def create_simple_srt(full_text: str, audio_path: Path, output_srt: Path) -> bool:
    """ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ 25ì ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ SRT ìë§‰ ìƒì„±"""
    try:
        logger.info(f"ğŸ“ SRT ìë§‰ íŒŒì¼ ìƒì„± ì¤‘: {output_srt.name}")

        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
        ffmpeg = get_ffmpeg_path()
        result = subprocess.run(
            [ffmpeg, '-i', str(audio_path)],
            capture_output=True,
            text=True
        )

        audio_duration = 0
        for line in result.stderr.split('\n'):
            if 'Duration:' in line:
                import re
                match = re.search(r'Duration: (\d{2}):(\d{2}):(\d{2}\.\d{2})', line)
                if match:
                    h, m, s = match.groups()
                    audio_duration = int(h) * 3600 + int(m) * 60 + float(s)
                    break

        if audio_duration == 0:
            logger.error("âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ì¸¡ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        logger.info(f"â±ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")

        # í…ìŠ¤íŠ¸ë¥¼ 25ì ë‹¨ìœ„ë¡œ ë¶„í• 
        words = full_text.split()
        chunks = []
        current_chunk = ""

        for word in words:
            test_chunk = current_chunk + (" " if current_chunk else "") + word
            if len(test_chunk) <= 25:
                current_chunk = test_chunk
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = word

        if current_chunk:
            chunks.append(current_chunk)

        if not chunks:
            chunks = [full_text]

        # ìë§‰ íƒ€ì´ë° ê³„ì‚° (ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ì²­í¬ ìˆ˜ë¡œ ë‚˜ëˆ”)
        time_per_chunk = audio_duration / len(chunks)

        with open(output_srt, 'w', encoding='utf-8') as f:
            for i, chunk in enumerate(chunks, 1):
                start_time = (i - 1) * time_per_chunk
                end_time = i * time_per_chunk

                start_srt = format_srt_time(start_time)
                end_srt = format_srt_time(end_time)

                f.write(f"{i}\n")
                f.write(f"{start_srt} --> {end_srt}\n")
                f.write(f"{chunk}\n")
                f.write("\n")

        logger.info(f"âœ… SRT ìë§‰ ìƒì„± ì™„ë£Œ: {len(chunks)}ê°œ ìë§‰")
        return True

    except Exception as e:
        logger.error(f"âŒ SRT ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def create_srt_subtitle(audio_segments: List[Dict], output_srt: Path) -> bool:
    """ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹¤ì œ ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SRT ìë§‰ íŒŒì¼ ìƒì„±"""
    try:
        logger.info(f"ğŸ“ SRT ìë§‰ íŒŒì¼ ìƒì„± ì¤‘ (ì‹¤ì œ TTS ê¸¸ì´ ê¸°ì¤€): {output_srt.name}")

        with open(output_srt, 'w', encoding='utf-8') as f:
            current_time = 0.0

            for i, segment in enumerate(audio_segments, 1):
                text = segment['text']
                actual_duration = segment['actual_duration']

                if not text:
                    continue

                # ê¸´ í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (25ì ì´ìƒì´ë©´ ì¤„ë°”ê¿ˆ)
                if len(text) > 25:
                    # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ë¶„ë¦¬
                    words = text.split()
                    lines = []
                    current_line = ""

                    for word in words:
                        test_line = current_line + (" " if current_line else "") + word
                        if len(test_line) <= 25:
                            current_line = test_line
                        else:
                            if current_line:
                                lines.append(current_line)
                            current_line = word

                    if current_line:
                        lines.append(current_line)

                    # ìµœëŒ€ 2ì¤„ë¡œ ì œí•œ
                    if len(lines) > 2:
                        text = "\n".join(lines[:2])
                    else:
                        text = "\n".join(lines)

                # ì‹¤ì œ TTS ê¸¸ì´ ê¸°ë°˜ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
                start_time = current_time
                end_time = current_time + actual_duration

                # SRT ì‹œê°„ í˜•ì‹ ë³€í™˜ (HH:MM:SS,mmm)
                start_srt = format_srt_time(start_time)
                end_srt = format_srt_time(end_time)

                # SRT í˜•ì‹
                f.write(f"{i}\n")
                f.write(f"{start_srt} --> {end_srt}\n")
                f.write(f"{text}\n")
                f.write("\n")

                current_time = end_time

        logger.info(f"âœ… SRT ìë§‰ ìƒì„± ì™„ë£Œ: {len(audio_segments)}ê°œ ìë§‰")
        return True

    except Exception as e:
        logger.error(f"âŒ SRT ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def format_srt_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def replace_video_audio_with_subtitle(
    video_path: Path,
    audio_path: Path,
    subtitle_path: Path,
    output_video: Path,
    burn_subtitle: bool = True
) -> bool:
    """ë¹„ë””ì˜¤ì˜ ì˜¤ë””ì˜¤ë¥¼ êµì²´í•˜ê³  ìë§‰ ì¶”ê°€

    ì£¼ì˜: ì›ë³¸ ì˜ìƒì— í•˜ë“œì½”ë”©ëœ ì¤‘êµ­ì–´ ìë§‰ì€ ì œê±°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
    í•˜ë“œì½”ë”©ëœ ìë§‰ì€ ì˜ìƒ í”½ì…€ì— í¬í•¨ë˜ì–´ ìˆì–´ ì™„ì „íˆ ì œê±°í•˜ë ¤ë©´
    OCR + ì¸í˜ì¸íŒ… ë˜ëŠ” ì˜ìƒ í¬ë¡­ì´ í•„ìš”í•©ë‹ˆë‹¤.

    í˜„ì¬ëŠ” í•œêµ­ì–´ ìë§‰ì„ ë” í¬ê³  ì„ ëª…í•˜ê²Œ ì¶”ê°€í•˜ì—¬ ì¤‘êµ­ì–´ ìë§‰ì„ ê°€ë¦¬ë„ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        ffmpeg = get_ffmpeg_path()
        logger.info(f"ğŸï¸ ì˜ìƒ í•©ì„± ì¤‘...")

        if burn_subtitle:
            # ìë§‰ì„ ë¹„ë””ì˜¤ì— í•˜ë“œì½”ë”© (burned-in)
            # Windows ê²½ë¡œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
            subtitle_path_escaped = str(subtitle_path).replace('\\', '/').replace(':', '\\:')

            # ìë§‰ ìŠ¤íƒ€ì¼ (ì ë‹¹í•œ í¬ê¸°, í•˜ë‹¨ì—ì„œ 20px ìœ„)
            subtitle_style = (
                "FontName=NanumGothic,"       # ë‚˜ëˆ”ê³ ë”•
                "Fontsize=21,"                # í°íŠ¸ í¬ê¸° (23 * 0.9 = 20.7 â‰ˆ 21)
                "Bold=1,"                     # ë³¼ë“œ
                "PrimaryColour=&H00FFFFFF,"   # í°ìƒ‰
                "OutlineColour=&H00000000,"   # ê²€ì€ í…Œë‘ë¦¬
                "BorderStyle=1,"              # ì™¸ê³½ì„  ìŠ¤íƒ€ì¼
                "Outline=2,"                  # í…Œë‘ë¦¬
                "Shadow=1,"                   # ê·¸ë¦¼ì
                "MarginV=20,"                 # í•˜ë‹¨ì—ì„œ 20px ìœ„
                "Alignment=2"                 # í•˜ë‹¨ ì¤‘ì•™
            )

            # ì¤‘êµ­ì–´ ìë§‰ ìœ„ì— ì™„ì „ ë¶ˆíˆ¬ëª… ê²€ì€ ë ˆì´ì–´ (í™”ë©´ í•˜ë‹¨ 150px)
            # í•˜ë‹¨ 150pxë¥¼ ì™„ì „íˆ ê²€ì€ìƒ‰ìœ¼ë¡œ ë®ìŒ
            video_filter = (
                f"drawbox=x=0:y=ih-150:w=iw:h=150:color=black:t=fill,"  # í•˜ë‹¨ 150px ì™„ì „ ë¶ˆíˆ¬ëª… ê²€ì€ ë°•ìŠ¤
                f"subtitles='{subtitle_path_escaped}':force_style='{subtitle_style}'"  # í•œêµ­ì–´ ìë§‰
            )

            # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
            result = subprocess.run(
                [ffmpeg, '-i', str(audio_path)],
                capture_output=True,
                text=True
            )
            audio_duration = 0
            for line in result.stderr.split('\n'):
                if 'Duration:' in line:
                    import re
                    match = re.search(r'Duration: (\d{2}):(\d{2}):(\d{2}\.\d{2})', line)
                    if match:
                        h, m, s = match.groups()
                        audio_duration = int(h) * 3600 + int(m) * 60 + float(s)
                        break

            logger.info(f"ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")

            # ì˜ìƒì„ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶”ê¸° (loop ì‚¬ìš©)
            cmd = [
                ffmpeg,
                '-stream_loop', '-1',  # ë¹„ë””ì˜¤ ë¬´í•œ ë°˜ë³µ
                '-i', str(video_path),
                '-i', str(audio_path),
                '-c:v', 'libx264',     # ë¹„ë””ì˜¤ ì¬ì¸ì½”ë”©
                '-preset', 'medium',   # ì¸ì½”ë”© ì†ë„/í’ˆì§ˆ ê· í˜•
                '-crf', '23',          # í’ˆì§ˆ ì„¤ì • (ë‚®ì„ìˆ˜ë¡ ê³ í’ˆì§ˆ)
                '-c:a', 'aac',         # ì˜¤ë””ì˜¤ AAC ì¸ì½”ë”©
                '-b:a', '192k',        # ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸
                '-vf', video_filter,   # ë¹„ë””ì˜¤ í•„í„° (ì¤‘êµ­ì–´ ìë§‰ ì œê±° + í•œêµ­ì–´ ìë§‰ ì¶”ê°€)
                '-map', '0:v:0',       # ì²« ë²ˆì§¸ ì…ë ¥ì˜ ë¹„ë””ì˜¤
                '-map', '1:a:0',       # ë‘ ë²ˆì§¸ ì…ë ¥ì˜ ì˜¤ë””ì˜¤
                '-sn',                 # ì›ë³¸ ìë§‰ ìŠ¤íŠ¸ë¦¼ ì œê±° (ì†Œí”„íŠ¸ ìë§‰ë§Œ)
                '-shortest',           # ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤ (ì˜¤ë””ì˜¤ê°€ ëë‚˜ë©´ ì˜ìƒë„ ë)
                '-y',
                str(output_video)
            ]
        else:
            # ì†Œí”„íŠ¸ ìë§‰ (ë³„ë„ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì¶”ê°€)
            cmd = [
                ffmpeg,
                '-i', str(video_path),
                '-i', str(audio_path),
                '-i', str(subtitle_path),
                '-c:v', 'copy',        # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë³µì‚¬
                '-c:a', 'aac',         # ì˜¤ë””ì˜¤ AAC ì¸ì½”ë”©
                '-c:s', 'mov_text',    # ìë§‰ ì¸ì½”ë”©
                '-map', '0:v:0',       # ì²« ë²ˆì§¸ ì…ë ¥ì˜ ë¹„ë””ì˜¤
                '-map', '1:a:0',       # ë‘ ë²ˆì§¸ ì…ë ¥ì˜ ì˜¤ë””ì˜¤
                '-map', '2:s:0',       # ì„¸ ë²ˆì§¸ ì…ë ¥ì˜ ìë§‰
                '-metadata:s:s:0', 'language=kor',
                '-shortest',
                '-y',
                str(output_video)
            ]

        logger.info(f"ğŸ“¹ FFmpeg ëª…ë ¹ ì‹¤í–‰ ì¤‘...")
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            logger.error(f"âŒ ì˜ìƒ í•©ì„± ì‹¤íŒ¨: {result.stderr}")
            return False

        logger.info(f"âœ… ì˜ìƒ í•©ì„± ì™„ë£Œ: {output_video.name}")
        return True

    except Exception as e:
        logger.error(f"âŒ ì˜ìƒ í•©ì„± ì˜¤ë¥˜: {e}")
        return False


async def convert_chinese_video(
    input_video: Path,
    output_dir: Path,
    title: str = None,
    use_openai_whisper: bool = False,
    use_openai_tts: bool = False,  # Edge TTS ì‚¬ìš© (ë¬´ë£Œ)
    use_claude: bool = True
) -> Optional[Path]:
    """ì¤‘êµ­ì–´ ì˜ìƒì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""

    logger.info("=" * 60)
    logger.info("ğŸ‡¨ğŸ‡³ â†’ ğŸ‡°ğŸ‡· ì¤‘êµ­ì–´ ì˜ìƒ ë³€í™˜ ì‹œì‘")
    logger.info("=" * 60)
    logger.info(f"ì…ë ¥: {input_video.name}")
    logger.info(f"ì¶œë ¥ í´ë”: {output_dir}")
    logger.info(f"ğŸ“ STOP íŒŒì¼ ê²½ë¡œ: {output_dir / 'STOP'}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    temp_dir = output_dir / "temp"
    temp_dir.mkdir(exist_ok=True)

    try:
        # 1. ì¤‘êµ­ì–´ ìë§‰ ì›Œí„°ë§ˆí¬ ì œê±°
        logger.info("\n" + "=" * 60)
        logger.info("1ï¸âƒ£ ë‹¨ê³„ 1: ì¤‘êµ­ì–´ ìë§‰ ì›Œí„°ë§ˆí¬ ì œê±°")
        logger.info("=" * 60)

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("ì›Œí„°ë§ˆí¬ ì œê±° ì „ ì‘ì—… ì·¨ì†Œë¨")

        # ì›Œí„°ë§ˆí¬ ì œê±°ëœ ë¹„ë””ì˜¤ ê²½ë¡œ
        watermark_removed_video = temp_dir / "no_watermark.mp4"
        if not remove_watermark_ai(input_video, watermark_removed_video, output_dir=output_dir):
            logger.error("âŒ ì›Œí„°ë§ˆí¬ ì œê±° ì‹¤íŒ¨ (ì›ë³¸ ì‚¬ìš©)")
            watermark_removed_video = input_video

        # ì´í›„ ë‹¨ê³„ì—ì„œëŠ” ì›Œí„°ë§ˆí¬ ì œê±°ëœ ë¹„ë””ì˜¤ ì‚¬ìš©
        working_video = watermark_removed_video

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("ì›Œí„°ë§ˆí¬ ì œê±° í›„ ì‘ì—… ì·¨ì†Œë¨")

        # 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        logger.info("\n" + "=" * 60)
        logger.info("2ï¸âƒ£ ë‹¨ê³„ 2: ì˜¤ë””ì˜¤ ì¶”ì¶œ")
        logger.info("=" * 60)

        audio_path = temp_dir / "original_audio.wav"
        if not extract_audio(working_video, audio_path):
            logger.error("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
            return None

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("ì˜¤ë””ì˜¤ ì¶”ì¶œ í›„ ì‘ì—… ì·¨ì†Œë¨")

        # 3. ìŒì„± ì¸ì‹ (ì¤‘êµ­ì–´)
        logger.info("\n" + "=" * 60)
        logger.info("3ï¸âƒ£ ë‹¨ê³„ 3: ì¤‘êµ­ì–´ ìŒì„± ì¸ì‹")
        logger.info("=" * 60)

        if use_openai_whisper:
            segments = transcribe_audio_openai(audio_path)
        else:
            segments = transcribe_audio_whisper(audio_path, language='zh')

        if not segments:
            logger.error("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            return None

        # ìë§‰ ì €ì¥
        transcript_file = output_dir / "chinese_transcript.json"
        with open(transcript_file, 'w', encoding='utf-8') as f:
            json.dump(segments, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ ì¤‘êµ­ì–´ ìë§‰ ì €ì¥: {transcript_file.name}")

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("ìŒì„± ì¸ì‹ í›„ ì‘ì—… ì·¨ì†Œë¨")

        # 4. ë²ˆì—­ (ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´)
        logger.info("\n" + "=" * 60)
        logger.info("4ï¸âƒ£ ë‹¨ê³„ 4: ë²ˆì—­ (ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´)")
        logger.info("=" * 60)

        if use_claude and ANTHROPIC_AVAILABLE:
            translated_segments = translate_segments_claude(segments, source_lang='zh', target_lang='ko')
        elif OPENAI_AVAILABLE:
            translated_segments = translate_segments_openai(segments, source_lang='zh', target_lang='ko')
        else:
            logger.error("âŒ ë²ˆì—­ APIê°€ ì—†ìŠµë‹ˆë‹¤ (Claude ë˜ëŠ” OpenAI í•„ìš”)")
            return None

        # ë²ˆì—­ ì €ì¥
        translation_file = output_dir / "korean_translation.json"
        with open(translation_file, 'w', encoding='utf-8') as f:
            json.dump(translated_segments, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ í•œêµ­ì–´ ë²ˆì—­ ì €ì¥: {translation_file.name}")

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("ë²ˆì—­ í›„ ì‘ì—… ì·¨ì†Œë¨")

        # 5. ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ TTSë¡œ ìƒì„±
        logger.info("\n" + "=" * 60)
        logger.info("5ï¸âƒ£ ë‹¨ê³„ 5: í•œêµ­ì–´ ìŒì„± ìƒì„± (ì „ì²´)")
        logger.info("=" * 60)

        # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ì „ì²´ í•©ì¹˜ê¸° (ê° ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ì´ì— 24ê°œ ì¤„ë°”ê¿ˆ ì¶”ê°€)
        newline_separator = '\n' * 24
        full_korean_text = newline_separator.join([seg.get('translated', '') for seg in translated_segments])
        logger.info(f"ğŸ“ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_korean_text)}ì")
        logger.info(f"ğŸ“ ë¯¸ë¦¬ë³´ê¸°: {full_korean_text[:100]}...")
        logger.info(f"ğŸ« ìˆ¨ì‰¬ëŠ” í¬ì¸íŠ¸ ì¶”ê°€ ì™„ë£Œ (ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ì´ë§ˆë‹¤ 24ê°œ ì¤„ë°”ê¿ˆ)")

        # í•˜ë‚˜ì˜ TTS íŒŒì¼ë¡œ ìƒì„±
        korean_audio_path = temp_dir / "korean_audio.mp3"

        if EDGE_TTS_AVAILABLE:
            logger.info("ğŸ¤ Edge TTSë¡œ ìŒì„± ìƒì„± ì¤‘...")
            success = await generate_tts_edge(full_korean_text, korean_audio_path)
        elif use_openai_tts and OPENAI_AVAILABLE:
            logger.warning("âš ï¸ Edge TTS ì‚¬ìš© ë¶ˆê°€, OpenAI TTS ì‚¬ìš© (ìœ ë£Œ)")
            success = generate_tts_openai(full_korean_text, korean_audio_path)
        else:
            logger.error("âŒ TTS ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤")
            return None

        if not success or not korean_audio_path.exists():
            logger.error("âŒ TTS ìƒì„± ì‹¤íŒ¨")
            return None

        logger.info(f"âœ… TTS ìƒì„± ì™„ë£Œ: {korean_audio_path.name}")

        # ì·¨ì†Œ ì²´í¬
        if should_stop(output_dir):
            raise CancelledException("TTS ìƒì„± í›„ ì‘ì—… ì·¨ì†Œë¨")

        # 6. ê°„ë‹¨í•œ ìë§‰ ìƒì„± (ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ 25ì ë‹¨ìœ„ë¡œ ë¶„í• )
        logger.info("\n" + "=" * 60)
        logger.info("6ï¸âƒ£ ë‹¨ê³„ 6: í•œêµ­ì–´ ìë§‰ ìƒì„±")
        logger.info("=" * 60)

        subtitle_path = output_dir / "korean_subtitle.srt"
        if not create_simple_srt(full_korean_text, korean_audio_path, subtitle_path):
            logger.error("âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨")
            return None

        # 7. ì˜ìƒ í•©ì„± (í•œêµ­ì–´ ìë§‰ + ì˜¤ë””ì˜¤)
        logger.info("\n" + "=" * 60)
        logger.info("7ï¸âƒ£ ë‹¨ê³„ 7: ì˜ìƒ í•©ì„±")
        logger.info("=" * 60)

        # ì¶œë ¥ íŒŒì¼ëª… ê²°ì • (ì œëª©ì´ ìˆìœ¼ë©´ ì œëª© ì‚¬ìš©)
        if title:
            # ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            import re
            safe_title = re.sub(r'[<>:"/\\|?*]', '', title)
            safe_title = safe_title.strip()[:100]  # ìµœëŒ€ 100ì
            output_filename = f"{safe_title}.mp4"
            logger.info(f"ğŸ“ ì œëª© ì‚¬ìš©: {title} â†’ {output_filename}")
        else:
            output_filename = f"converted_{input_video.stem}.mp4"

        # ì›Œí„°ë§ˆí¬ ì œê±°ëœ ë¹„ë””ì˜¤ ì‚¬ìš©
        output_video = output_dir / output_filename
        if not replace_video_audio_with_subtitle(
            working_video,  # ì›Œí„°ë§ˆí¬ ì œê±°ëœ ë¹„ë””ì˜¤ ì‚¬ìš©
            korean_audio_path,
            subtitle_path,
            output_video,
            burn_subtitle=True  # ìë§‰ì„ ë¹„ë””ì˜¤ì— í•˜ë“œì½”ë”©
        ):
            logger.error("âŒ ì˜ìƒ í•©ì„± ì‹¤íŒ¨")
            return None

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        logger.info("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        shutil.rmtree(temp_dir, ignore_errors=True)

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ë³€í™˜ ì™„ë£Œ!")
        logger.info("=" * 60)
        logger.info(f"ì¶œë ¥ íŒŒì¼: {output_video}")

        return output_video

    except CancelledException as e:
        logger.warning(f"\nğŸ›‘ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if 'temp_dir' in locals():
            shutil.rmtree(temp_dir, ignore_errors=True)
        return None

    except Exception as e:
        logger.error(f"\nâŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description='ì¤‘êµ­ì–´ ì˜ìƒì„ í•œêµ­ì–´ë¡œ ë³€í™˜')
    parser.add_argument('--input', type=str, required=True, help='ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output-dir', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--title', type=str, help='ìƒí’ˆ ì œëª© (íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©)')
    parser.add_argument('--use-openai-whisper', action='store_true', help='OpenAI Whisper API ì‚¬ìš© (ê¸°ë³¸: ë¡œì»¬ whisper)')
    parser.add_argument('--use-edge-tts', action='store_true', help='Edge TTS ì‚¬ìš© (ê¸°ë³¸: OpenAI TTS)')
    parser.add_argument('--use-openai-translate', action='store_true', help='OpenAIë¡œ ë²ˆì—­ (ê¸°ë³¸: Claude)')

    args = parser.parse_args()

    input_video = Path(args.input)
    output_dir = Path(args.output_dir)

    if not input_video.exists():
        logger.error(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_video}")
        return

    # í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸
    logger.info("\nğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    logger.info("  - openai-whisper (ìŒì„± ì¸ì‹)")
    logger.info("  - anthropic (ë²ˆì—­ - ì €ë ´)")
    logger.info("  - openai (TTS)")
    logger.info("  - edge-tts (TTS ëŒ€ì²´)")
    logger.info("\nì„¤ì¹˜: pip install openai-whisper anthropic openai edge-tts\n")

    # ë¹„ë™ê¸° ì‹¤í–‰
    result = asyncio.run(convert_chinese_video(
        input_video,
        output_dir,
        title=args.title,
        use_openai_whisper=args.use_openai_whisper,
        use_openai_tts=not args.use_edge_tts,
        use_claude=not args.use_openai_translate
    ))

    if result:
        logger.info(f"\nâœ… ì„±ê³µ: {result}")
    else:
        logger.error("\nâŒ ë³€í™˜ ì‹¤íŒ¨")
        sys.exit(1)


if __name__ == '__main__':
    main()
