"""
í´ë”ì— ìˆëŠ” story.jsonê³¼ ì´ë¯¸ì§€ë“¤ë¡œ ì˜ìƒì„ ìë™ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python create_video_from_folder.py --folder "path/to/folder"

í´ë” êµ¬ì¡°:
    folder/
        story.json (ë˜ëŠ” story_metadata.json)
        scene_01_image.png
        scene_02_image.png
        ...
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
import warnings
from time import time
import signal

# ë²„ì „ í˜¸í™˜ì„± ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore", message="Model was trained with")
warnings.filterwarnings("ignore", message="Lightning automatically upgraded")
warnings.filterwarnings("ignore", message="torchaudio._backend")
warnings.filterwarnings("ignore", category=UserWarning, module="pyannote")
warnings.filterwarnings("ignore", category=UserWarning, module="speechbrain")
warnings.filterwarnings("ignore", category=UserWarning, module="pytorch_lightning")

# ë¡œê¹… ë ˆë²¨ ì¡°ì • (pytorch_lightning INFO ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°)
import logging as base_logging
base_logging.getLogger("pytorch_lightning").setLevel(base_logging.WARNING)
from typing import Dict, List, Optional
import edge_tts
import asyncio
from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, VideoFileClip
import re
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing
import tempfile

# ë¡œê¹… ì„¤ì • (ë¨¼ì € ì„¤ì •)
# Windowsì—ì„œ UTF-8 ì¶œë ¥ì„ ìœ„í•´ stdoutì„ UTF-8ë¡œ ì¬ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/video_from_folder.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Global cancellation flag and child processes tracking
cancellation_requested = False
child_processes = []

def signal_handler(signum, frame):
    """Handle SIGTERM/SIGINT for graceful shutdown"""
    global cancellation_requested, child_processes
    logger.info("ğŸ›‘ ì·¨ì†Œ ì‹œê·¸ë„ ìˆ˜ì‹ , ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤...")
    cancellation_requested = True

    # ëª¨ë“  ìì‹ í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
    for proc in child_processes:
        try:
            if proc.poll() is None:  # ì•„ì§ ì‹¤í–‰ ì¤‘
                logger.info(f"ğŸ›‘ ìì‹ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì¤‘: PID {proc.pid}")
                proc.kill()  # SIGKILL
                proc.wait(timeout=2)
        except Exception as e:
            logger.error(f"âŒ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨: {e}")

    sys.exit(1)

# Google Image Search (ì˜µì…˜)
try:
    from google_image_search import GoogleImageSearcher, DailyLimitExceededError, GoogleImageSearchError
    GOOGLE_SEARCH_AVAILABLE = True
except ImportError:
    GOOGLE_SEARCH_AVAILABLE = False
    logger.warning("[WARNING] google_image_search module not found. Auto image search disabled.")

# DALL-E (ì˜µì…˜)
try:
    from openai import OpenAI
    DALLE_AVAILABLE = True
except ImportError:
    DALLE_AVAILABLE = False
    logger.warning("[WARNING] openai module not found. DALL-E image generation disabled.")


class VideoFromFolderCreator:
    """story.jsonê³¼ ì´ë¯¸ì§€ë¡œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, folder_path: str, voice: str = "ko-KR-SoonBokNeural",
                 aspect_ratio: str = "16:9", add_subtitles: bool = False,
                 image_source: str = "none", is_admin: bool = False):
        """
        Args:
            folder_path: story.jsonê³¼ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
            voice: TTS ìŒì„± (ê¸°ë³¸: ko-KR-SoonBokNeural)
            aspect_ratio: ë¹„ë””ì˜¤ ë¹„ìœ¨ (ê¸°ë³¸: 16:9)
            add_subtitles: ìë§‰ ì¶”ê°€ ì—¬ë¶€ (ê¸°ë³¸: False)
            image_source: ì´ë¯¸ì§€ ì†ŒìŠ¤ ("none", "google", "dalle")
            is_admin: ê´€ë¦¬ì ëª¨ë“œ (ë¹„ìš© ë¡œê·¸ í‘œì‹œ)
        """
        self.folder_path = Path(folder_path)
        self.voice = voice
        self.aspect_ratio = aspect_ratio
        self.add_subtitles = add_subtitles
        self.image_source = image_source.lower()
        self.is_admin = is_admin

        # ì´ë¯¸ì§€ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.image_searcher = None
        self.dalle_client = None

        if self.image_source == "google" and GOOGLE_SEARCH_AVAILABLE:
            try:
                self.image_searcher = GoogleImageSearcher()
                logger.info("âœ… Google Image Search í™œì„±í™”ë¨")
            except GoogleImageSearchError as e:
                logger.warning(f"âš ï¸ Google Image Search ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.image_source = "none"

        elif self.image_source == "dalle":
            if not DALLE_AVAILABLE:
                logger.error("âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")
                self.image_source = "none"
            else:
                import os
                api_key = os.getenv('OPENAI_API_KEY')
                if not api_key:
                    logger.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    self.image_source = "none"
                else:
                    self.dalle_client = OpenAI(api_key=api_key)
                    logger.info("âœ… DALL-E 3 ì´ë¯¸ì§€ ìƒì„± í™œì„±í™”ë¨")

        # ë¹„ìœ¨ íŒŒì‹±
        if aspect_ratio == "9:16":
            self.width, self.height = 1080, 1920
        elif aspect_ratio == "16:9":
            self.width, self.height = 1920, 1080
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¹„ìœ¨: {aspect_ratio}")

        # story.json ë¡œë“œ
        self.story_data = self._load_story_json()

        # ì¸ë„¤ì¼ ìë™ ìƒì„±
        self._create_thumbnail()

        # GPU ì¸ì½”ë” ê°ì§€
        self.video_codec, self.codec_preset = self._detect_best_encoder()

        # Whisper ëª¨ë¸ ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
        self._whisper_model = None

    def _detect_best_encoder(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœê³ ì˜ ë¹„ë””ì˜¤ ì¸ì½”ë” ê°ì§€"""
        try:
            # ffmpegì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ì½”ë” ëª©ë¡ í™•ì¸
            result = subprocess.run(
                ['ffmpeg', '-encoders'],
                capture_output=True,
                text=True,
                timeout=5
            )
            encoders = result.stdout

            # NVIDIA GPU ì¸ì½”ë” (ê°€ì¥ ë¹ ë¦„)
            if 'h264_nvenc' in encoders:
                # ë“œë¼ì´ë²„ ë²„ì „ ì²´í¬
                try:
                    driver_check = subprocess.run(
                        ['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'],
                        capture_output=True,
                        text=True,
                        timeout=5
                    )
                    driver_version = driver_check.stdout.strip()
                    driver_major = int(driver_version.split('.')[0])

                    if driver_major >= 570:
                        logger.info(f"âœ“ NVIDIA GPU ì¸ì½”ë” ì‚¬ìš© (h264_nvenc, ë“œë¼ì´ë²„ {driver_version})")
                        return 'h264_nvenc', 'p4'
                    else:
                        logger.warning(f"âš ï¸  NVIDIA ë“œë¼ì´ë²„ê°€ ë‚®ìŒ ({driver_version} < 570.0), CPU ì¸ì½”ë” ì‚¬ìš©")
                        logger.info("   ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸: https://www.nvidia.com/Download/index.aspx")
                except:
                    # ë“œë¼ì´ë²„ ì²´í¬ ì‹¤íŒ¨ ì‹œ GPU ì‹œë„ (í´ë°± ìˆìŒ)
                    logger.info("âœ“ NVIDIA GPU ì¸ì½”ë” ê°ì§€ (h264_nvenc) - ë“œë¼ì´ë²„ ë²„ì „ í™•ì¸ ì‹¤íŒ¨, ì‹œë„í•©ë‹ˆë‹¤")
                    return 'h264_nvenc', 'p4'

            # Intel QSV ì¸ì½”ë”
            if 'h264_qsv' in encoders:
                logger.info("âœ“ Intel QSV GPU ì¸ì½”ë” ì‚¬ìš© (h264_qsv)")
                return 'h264_qsv', 'fast'

            # AMD GPU ì¸ì½”ë”
            if 'h264_amf' in encoders:
                logger.info("âœ“ AMD GPU ì¸ì½”ë” ì‚¬ìš© (h264_amf)")
                return 'h264_amf', 'speed'

        except Exception as e:
            logger.warning(f"GPU ì¸ì½”ë” ê°ì§€ ì‹¤íŒ¨: {e}")

        # í´ë°±: CPU ì¸ì½”ë”
        logger.info("âœ— GPU ì¸ì½”ë” ì—†ìŒ. CPU ì¸ì½”ë” ì‚¬ìš© (libx264)")
        return 'libx264', 'ultrafast'

    def _load_story_json(self) -> Dict:
        """storyë¡œ ì‹œì‘í•˜ëŠ” JSON íŒŒì¼ ë¡œë“œ"""
        # ê²½ë¡œ ì •ê·œí™” (ë”°ì˜´í‘œ ì œê±°)
        folder_str = str(self.folder_path).strip('"').strip("'")
        self.folder_path = Path(folder_str)

        logger.info(f"í´ë” ê²½ë¡œ: {self.folder_path}")
        logger.info(f"í´ë” ì¡´ì¬ ì—¬ë¶€: {self.folder_path.exists()}")

        # storyê°€ í¬í•¨ëœ ëª¨ë“  JSON íŒŒì¼ ì°¾ê¸°
        story_files = list(self.folder_path.glob("*story*.json"))

        logger.info(f"ì°¾ì€ *story*.json íŒŒì¼: {[f.name for f in story_files]}")

        if story_files:
            # íŒŒì¼ì´ ì—¬ëŸ¬ ê°œë©´ ì²« ë²ˆì§¸ ì‚¬ìš©
            json_path = story_files[0]
            logger.info(f"JSON íŒŒì¼ ë¡œë“œ: {json_path.name}")
            with open(json_path, 'r', encoding='utf-8') as f:
                json_text = f.read()

                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ``` í˜•ì‹)
                json_text = re.sub(r'^```json\s*', '', json_text, flags=re.IGNORECASE)
                json_text = re.sub(r'\s*```\s*$', '', json_text)
                json_text = json_text.strip()

                # JSON íŒŒì‹± ì‹œë„
                try:
                    return json.loads(json_text)
                except json.JSONDecodeError as e:
                    logger.warning(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ìë™ ìˆ˜ì • ì‹œë„ ì¤‘... (ì›ì¸: {e})")

                    # JSON ë¬¸ìì—´ ê°’ ë‚´ë¶€ì˜ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œ ìˆ˜ì •
                    # "text": "He said "hello"" -> "text": "He said \"hello\""
                    def fix_quotes(match):
                        key = match.group(1)
                        value = match.group(2)
                        # ê°’ ë‚´ë¶€ì˜ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                        # ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ(\")ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
                        fixed_value = re.sub(r'(?<!\\)"', r'\\"', value)
                        return f'"{key}": "{fixed_value}"'

                    # "key": "value" íŒ¨í„´ì„ ì°¾ì•„ì„œ value ë‚´ë¶€ì˜ ë”°ì˜´í‘œ ìˆ˜ì •
                    # ë‹¨, value ëì˜ ë”°ì˜´í‘œëŠ” ìœ ì§€
                    json_text_fixed = re.sub(
                        r'"([^"]+)"\s*:\s*"((?:[^"\\]|\\.)*)(?<!\\)"',
                        fix_quotes,
                        json_text
                    )

                    try:
                        logger.info("âœ… JSON ìë™ ìˆ˜ì • ì„±ê³µ")
                        return json.loads(json_text_fixed)
                    except json.JSONDecodeError as e2:
                        logger.error(f"âŒ JSON ìë™ ìˆ˜ì • ì‹¤íŒ¨: {e2}")
                        # ì›ë³¸ ì—ëŸ¬ ë°œìƒ
                        raise e

        raise FileNotFoundError(f"{self.folder_path}ì— 'story'ê°€ í¬í•¨ëœ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    def _create_thumbnail(self):
        """ì”¬ 1 ì´ë¯¸ì§€ë¡œ ì¸ë„¤ì¼ ìë™ ìƒì„±"""
        try:
            logger.info("ğŸ–¼ï¸  ì¸ë„¤ì¼ ìë™ ìƒì„± ì¤‘...")

            # create_thumbnail.pyë¥¼ subprocessë¡œ ì‹¤í–‰
            import subprocess

            thumbnail_script = Path(__file__).parent / "create_thumbnail.py"

            if not thumbnail_script.exists():
                logger.warning(f"ì¸ë„¤ì¼ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {thumbnail_script}")
                return

            result = subprocess.run(
                [sys.executable, str(thumbnail_script), "-f", str(self.folder_path)],
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore'
            )

            if result.returncode == 0:
                logger.info("âœ… ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ")
            else:
                logger.warning(f"ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨: {result.stderr}")

        except Exception as e:
            logger.warning(f"ì¸ë„¤ì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")

    def _find_images(self) -> Dict[int, Path]:
        """ì”¬ë³„ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (scene_XX íŒ¨í„´ ë˜ëŠ” ì‹œê°„ìˆœ ìë™ ì •ë ¬)"""
        images = {}

        # 1. scene_XX_image íŒ¨í„´ ì°¾ê¸°
        for file in self.folder_path.glob("scene_*_image.*"):
            match = re.match(r"scene_(\d+)_image\.(png|jpg|jpeg)", file.name)
            if match:
                scene_num = int(match.group(1))
                images[scene_num] = file

        # images ì„œë¸Œí´ë”ì—ì„œë„ ì°¾ê¸°
        images_folder = self.folder_path / "images"
        if images_folder.exists():
            for file in images_folder.glob("scene_*_image.*"):
                match = re.match(r"scene_(\d+)_image\.(png|jpg|jpeg)", file.name)
                if match:
                    scene_num = int(match.group(1))
                    if scene_num not in images:
                        images[scene_num] = file

        # 2. scene íŒ¨í„´ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        if not images:
            logger.info("scene_XX íŒ¨í„´ ì—†ìŒ. ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")

            # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (generated_videos í´ë” ë° ì¸ë„¤ì¼ ì œì™¸, ì¤‘ë³µ ì œê±°)
            all_images_set = set()
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']:
                for img_file in self.folder_path.glob(ext):
                    # generated_videos í´ë” ì•ˆì˜ íŒŒì¼ê³¼ ì¸ë„¤ì¼ì€ ì œì™¸
                    if 'generated_videos' not in str(img_file) and 'thumbnail' not in img_file.name.lower():
                        all_images_set.add(img_file)

            if images_folder and images_folder.exists():
                for ext in ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']:
                    for img_file in images_folder.glob(ext):
                        # ì¸ë„¤ì¼ ì œì™¸
                        if 'thumbnail' not in img_file.name.lower():
                            all_images_set.add(img_file)

            # Setì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì •ë ¬
            # âš ï¸ ì¤‘ìš”: Frontendì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©!
            # 1. ëª…í™•í•œ ì‹œí€€ìŠ¤ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‹œí€€ìŠ¤ë¡œ ì •ë ¬
            # 2. ì—†ìœ¼ë©´ íŒŒì¼ ìˆ˜ì • ì‹œê°„ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
            def extract_sequence(filepath):
                """
                ëª…í™•í•œ ì‹œí€€ìŠ¤ ë²ˆí˜¸ë§Œ ì¶”ì¶œ:
                - image_01, scene_1, img_5 ë“±
                - image(1), scene(2) ë“±
                - (1), (2) ë“±
                - íŒŒì¼ëª… ì „ì²´ê°€ ìˆ«ì (1.jpg, 2.png)

                Returns: (sequence_number or None, mtime)
                """
                import re
                name = filepath.stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…

                # image_01, scene_1, img_5 íŒ¨í„´
                match = re.match(r'^(image|scene|img)[-_](\d+)$', name, re.IGNORECASE)
                if match:
                    return (int(match.group(2)), 0)

                # image(1), scene(2) íŒ¨í„´
                match = re.match(r'^(image|scene|img)\((\d+)\)$', name, re.IGNORECASE)
                if match:
                    return (int(match.group(2)), 0)

                # (1), (2) íŒ¨í„´
                match = re.match(r'^\((\d+)\)$', name)
                if match:
                    return (int(match.group(1)), 0)

                # íŒŒì¼ëª… ì „ì²´ê°€ ìˆ«ì (1, 2, 3)
                match = re.match(r'^(\d+)$', name)
                if match:
                    return (int(match.group(1)), 0)

                # ì‹œí€€ìŠ¤ ë²ˆí˜¸ ì—†ìŒ - íŒŒì¼ ìˆ˜ì • ì‹œê°„ ì‚¬ìš©
                try:
                    mtime = filepath.stat().st_mtime
                except:
                    mtime = 0
                return (None, mtime)

            # ì •ë ¬: ì‹œí€€ìŠ¤ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ì‹œê°„ ìˆœì„œ
            all_images_list = list(all_images_set)
            all_images = sorted(all_images_list, key=lambda f: (
                extract_sequence(f)[0] is None,  # ì‹œí€€ìŠ¤ ì—†ëŠ” ê²ƒì„ ë’¤ë¡œ
                extract_sequence(f)[0] if extract_sequence(f)[0] is not None else 0,  # ì‹œí€€ìŠ¤ ì •ë ¬
                extract_sequence(f)[1]  # ì‹œê°„ ì •ë ¬
            ))

            # ì”¬ ë²ˆí˜¸ ìë™ í• ë‹¹ ë° ë¡œê·¸ ì¶œë ¥
            logger.info(f"\nğŸ“· ì´ë¯¸ì§€ ì •ë ¬ ì™„ë£Œ (ì´ {len(all_images)}ê°œ):")
            for idx, img_path in enumerate(all_images, start=1):
                images[idx] = img_path
                seq_info = extract_sequence(img_path)
                if seq_info[0] is not None:
                    logger.info(f"  ì”¬ {idx}: {img_path.name} (ì‹œí€€ìŠ¤: {seq_info[0]})")
                else:
                    import datetime
                    mtime_str = datetime.datetime.fromtimestamp(seq_info[1]).strftime('%Y-%m-%d %H:%M:%S')
                    logger.info(f"  ì”¬ {idx}: {img_path.name} (ì‹œê°„: {mtime_str})")

        logger.info(f"ì´ë¯¸ì§€ {len(images)}ê°œ ë°œê²¬")

        # 3. ìë™ ì´ë¯¸ì§€ ìƒì„±/ë‹¤ìš´ë¡œë“œ (í™œì„±í™”ëœ ê²½ìš°)
        if self.image_source in ["google", "dalle"]:
            images = self._download_missing_images(images)

        return images

    def _download_missing_images(self, images: Dict[int, Path]) -> Dict[int, Path]:
        """
        ëˆ„ë½ëœ ì´ë¯¸ì§€ë¥¼ Google Search ë˜ëŠ” DALL-Eë¡œ ìë™ ìƒì„±

        Args:
            images: ê¸°ì¡´ ì´ë¯¸ì§€ ë”•ì…”ë„ˆë¦¬

        Returns:
            ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ ë”•ì…”ë„ˆë¦¬
        """
        scenes = self.story_data.get('scenes', [])

        if not scenes:
            logger.warning("âš ï¸ story.jsonì— scenes ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return images

        logger.info(f"ğŸ” ì´ {len(scenes)}ê°œ ì”¬ì— ëŒ€í•´ ì´ë¯¸ì§€ í™•ì¸ ì¤‘...")

        missing_scenes = []
        for idx, scene in enumerate(scenes, start=1):
            if idx not in images:
                missing_scenes.append((idx, scene))

        if not missing_scenes:
            logger.info("âœ… ëª¨ë“  ì”¬ì— ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤.")
            return images

        source_name = "Google Image Search" if self.image_source == "google" else "DALL-E 3"
        logger.info(f"âš ï¸ {len(missing_scenes)}ê°œ ì”¬ì˜ ì´ë¯¸ì§€ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. {source_name}ë¡œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        # ë¹„ìš© ì˜ˆì¸¡
        if self.image_source == "google":
            self.image_searcher.log_cost_estimate(len(missing_scenes))
        elif self.image_source == "dalle":
            self._log_dalle_cost_estimate(len(missing_scenes))

        try:
            success_count = 0
            fail_count = 0

            for scene_num, scene in missing_scenes:
                # image_prompt ì¶”ì¶œ (imagefx_promptë„ ì§€ì›)
                image_prompt = scene.get('image_prompt') or scene.get('imagefx_prompt', '')

                if not image_prompt:
                    logger.warning(f"âš ï¸ ì”¬ {scene_num}: image_prompt ë˜ëŠ” imagefx_promptê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                # íŒŒì¼ëª… ìƒì„±
                filename = f"scene_{scene_num:02d}_image.jpg"

                if self.image_source == "google":
                    # Google Image Search
                    logger.info(f"ğŸ” ì”¬ {scene_num}: '{image_prompt}' ê²€ìƒ‰ ì¤‘...")
                    downloaded_path = self.image_searcher.search_and_download(
                        query=image_prompt,
                        save_dir=self.folder_path,
                        filename=filename
                    )

                    if downloaded_path:
                        images[scene_num] = downloaded_path
                        success_count += 1
                        logger.info(f"âœ… ì”¬ {scene_num}: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                    else:
                        fail_count += 1
                        logger.error(f"âŒ ì”¬ {scene_num}: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

                elif self.image_source == "dalle":
                    # DALL-E 3 Image Generation
                    logger.info(f"ğŸ¨ ì”¬ {scene_num}: '{image_prompt}' DALL-E ìƒì„± ì¤‘...")
                    generated_path = self._generate_dalle_image(
                        prompt=image_prompt,
                        save_dir=self.folder_path,
                        filename=filename
                    )

                    if generated_path:
                        images[scene_num] = generated_path
                        success_count += 1
                        logger.info(f"âœ… ì”¬ {scene_num}: ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
                        logger.info(f"   â†’ images[{scene_num}] = {generated_path}")
                    else:
                        fail_count += 1
                        logger.error(f"âŒ ì”¬ {scene_num}: ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")

        except DailyLimitExceededError as e:
            logger.error(f"\n{'='*60}")
            logger.error(str(e))
            logger.error(f"{'='*60}\n")
            logger.error("âš ï¸ ì¼ì¼ í•œë„ ì´ˆê³¼ë¡œ ìë™ ë‹¤ìš´ë¡œë“œë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            logger.error("   - ë‚¨ì€ ì”¬ì€ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì—…ë¡œë“œí•˜ê±°ë‚˜")
            logger.error("   - ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ìë™ ìƒì„±/ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ìµœì¢… ë¹„ìš© ìš”ì•½
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š ì´ë¯¸ì§€ ìƒì„±/ë‹¤ìš´ë¡œë“œ ì™„ë£Œ - ì´ {len(images)}ê°œ ì´ë¯¸ì§€ í™•ë³´")
        logger.info(f"   âœ… ì„±ê³µ: {success_count}ê°œ, âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        logger.info(f"   ğŸ” images ë”•ì…”ë„ˆë¦¬ ë‚´ìš©:")
        for scene_num, img_path in sorted(images.items()):
            logger.info(f"      ì”¬ {scene_num}: {img_path.name}")

        if self.image_source == "google" and self.image_searcher:
            logger.info(f"{self.image_searcher.get_cost_summary()}")
        elif self.image_source == "dalle":
            total_cost = success_count * 0.080  # HD quality
            logger.info(f"ğŸ’° ì´ ë¹„ìš©: ${total_cost:.2f} (ì•½ â‚©{total_cost * 1300:.0f})")

        logger.info(f"{'='*60}\n")

        return images

    def _generate_dalle_image(self, prompt: str, save_dir: Path, filename: str) -> Optional[Path]:
        """
        DALL-E 3ë¡œ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥

        Args:
            prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
            save_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            filename: ì €ì¥ íŒŒì¼ëª…

        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        if not self.dalle_client:
            logger.error("âŒ DALL-E í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # aspect_ratioì— ë”°ë¼ ì´ë¯¸ì§€ í¬ê¸° ê²°ì •
        if self.aspect_ratio == "9:16":
            image_size = "1024x1792"  # ì„¸ë¡œí˜• (ìˆí¼)
        else:  # 16:9 or other
            image_size = "1792x1024"  # ê°€ë¡œí˜• (ë¡±í¼)

        logger.info(f"ğŸ¨ DALL-E ì´ë¯¸ì§€ ìƒì„± í¬ê¸°: {image_size} ({self.aspect_ratio})")

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # ì¬ì‹œë„ ì‹œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
                if attempt == 0:
                    current_prompt = prompt
                elif attempt == 1:
                    # ì²« ë²ˆì§¸ ì¬ì‹œë„: ê°„ë‹¨í•˜ê³  ì•ˆì „í•œ ë²„ì „
                    current_prompt = f"A calm and peaceful scene depicting: {prompt[:100]}"
                    logger.info(f"ğŸ”„ Content filter ìš°íšŒë¥¼ ìœ„í•´ í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™” (ì‹œë„ {attempt + 1}/{max_retries})")
                else:
                    # ë‘ ë²ˆì§¸ ì¬ì‹œë„: ë§¤ìš° ì¼ë°˜ì ì¸ ì„¤ëª…
                    current_prompt = "A beautiful, peaceful landscape with soft lighting"
                    logger.info(f"ğŸ”„ ë§¤ìš° ì¼ë°˜ì ì¸ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„ (ì‹œë„ {attempt + 1}/{max_retries})")

                if attempt > 0:
                    logger.info(f"   ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸: {current_prompt}")

                # DALL-E 3 API í˜¸ì¶œ
                response = self.dalle_client.images.generate(
                    model="dall-e-3",
                    prompt=current_prompt,
                    size=image_size,
                    quality="hd",
                    n=1
                )

                # ìƒì„±ëœ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
                image_url = response.data[0].url

                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                import requests
                logger.info(f"ğŸ“¥ DALL-E ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                img_response = requests.get(image_url, timeout=30)
                img_response.raise_for_status()

                # íŒŒì¼ ì €ì¥
                save_path = save_dir / filename
                save_path.parent.mkdir(parents=True, exist_ok=True)

                with open(save_path, 'wb') as f:
                    f.write(img_response.content)

                logger.info(f"âœ… DALL-E ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path.name}")
                if attempt > 0:
                    logger.info(f"   (ì¬ì‹œë„ {attempt}íšŒ ëì— ì„±ê³µ)")
                return save_path

            except Exception as e:
                error_str = str(e)

                # Content policy violation ì²´í¬
                if 'content_policy_violation' in error_str or 'content filters' in error_str:
                    logger.warning(f"âš ï¸ Content filterì— ê±¸ë¦¼ (ì‹œë„ {attempt + 1}/{max_retries})")

                    if attempt < max_retries - 1:
                        logger.info("   â†’ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                        continue
                    else:
                        logger.error(f"âŒ {max_retries}íšŒ ì¬ì‹œë„ í›„ì—ë„ Content filter í†µê³¼ ì‹¤íŒ¨")
                        return None
                else:
                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
                    logger.error(f"âŒ DALL-E ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {error_str}")
                    return None

        return None

    def _log_dalle_cost_estimate(self, num_images: int):
        """
        DALL-E 3 ë¹„ìš© ì˜ˆì¸¡ ë¡œê·¸ ì¶œë ¥ (ê´€ë¦¬ìì—ê²Œë§Œ í‘œì‹œ)

        Args:
            num_images: ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜
        """
        # ê´€ë¦¬ìê°€ ì•„ë‹ˆë©´ ë¡œê·¸ ì¶œë ¥ ì•ˆ í•¨
        if not self.is_admin:
            return

        # DALL-E 3 pricing
        # - Standard quality (1024x1024): $0.040 per image
        # - HD quality (1024x1792 or 1792x1024): $0.080 per image

        # aspect_ratioì— ë”°ë¼ ì´ë¯¸ì§€ í¬ê¸° ê²°ì •
        # - 9:16 (ìˆí¼) -> 1024x1792 (ì„¸ë¡œí˜•)
        # - 16:9 (ë¡±í¼) -> 1792x1024 (ê°€ë¡œí˜•)
        DALLE_COST_PER_IMAGE_HD = 0.080
        DALLE_COST_PER_IMAGE_STANDARD = 0.040

        # HD quality ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        estimated_cost_hd = num_images * DALLE_COST_PER_IMAGE_HD
        estimated_cost_standard = num_images * DALLE_COST_PER_IMAGE_STANDARD

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ’° DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ë¹„ìš© ì˜ˆì¸¡ (ê´€ë¦¬ì ì „ìš©)")
        # ì´ë¯¸ì§€ í¬ê¸° í‘œì‹œ
        if self.aspect_ratio == "9:16":
            image_size_str = "1024x1792 (ì„¸ë¡œí˜• ìˆí¼)"
        else:
            image_size_str = "1792x1024 (ê°€ë¡œí˜• ë¡±í¼)"

        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š ìƒì„± ì˜ˆì • ì´ë¯¸ì§€: {num_images}ê°œ")
        logger.info(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image_size_str}")
        logger.info(f"ğŸ’µ ì˜ˆìƒ ë¹„ìš© (HD {image_size_str.split()[0]}):        ${estimated_cost_hd:.2f} (ì•½ â‚©{estimated_cost_hd * 1300:.0f})")
        logger.info(f"ğŸ’µ ì˜ˆìƒ ë¹„ìš© (Standard 1024x1024): ${estimated_cost_standard:.2f} (ì•½ â‚©{estimated_cost_standard * 1300:.0f})")
        logger.info(f"â„¹ï¸  HD quality ì‚¬ìš© ê¶Œì¥ ({self.aspect_ratio} ë¹„ìœ¨ì— ì í•©)")
        logger.info(f"{'='*60}\n")

    def _clean_script_for_tts(self, script: str) -> str:
        """TTSìš© í…ìŠ¤íŠ¸ ì •ë¦¬ (ë°±ìŠ¬ë˜ì‹œ, ì—ëŸ¬ ë©”ì‹œì§€, ìˆ«ì ë³€í™˜)"""
        import re

        cleaned = script

        # Remove all backslashes
        cleaned = cleaned.replace('\\', '')

        # Remove error messages
        cleaned = re.sub(r'\[Request interrupted by user\]', '', cleaned)
        cleaned = re.sub(r'\[.*?interrupted.*?\]', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'\[.*?error.*?\]', '', cleaned, flags=re.IGNORECASE)

        # Remove markdown
        cleaned = cleaned.replace('```', '')

        # Fix quotes
        cleaned = cleaned.replace('""', '"').replace("''", "'")

        # Convert numbers to Korean
        cleaned = self._convert_numbers_to_korean(cleaned)

        # Clean spaces
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()

        return cleaned

    def _convert_numbers_to_korean(self, text: str) -> str:
        """ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜ (3ë²ˆ -> ì„¸ ë²ˆ, 010-1234-5678 -> ê³µ ì¼ ê³µ ...)"""
        import re

        # ì „í™”ë²ˆí˜¸ íŒ¨í„´ ì²˜ë¦¬ (010-1234-5678, 02-123-4567 ë“±)
        def convert_phone_number(match):
            """ì „í™”ë²ˆí˜¸ë¥¼ í•œ ê¸€ìì”© ì½ê¸°"""
            phone = match.group(0)
            digits = re.sub(r'[^\d]', '', phone)
            digit_names = ['ê³µ', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
            result = ' '.join([digit_names[int(d)] for d in digits])
            return result

        # ì „í™”ë²ˆí˜¸ íŒ¨í„´ (010-xxxx-xxxx, 02-xxx-xxxx ë“±)
        phone_pattern = r'0\d{1,2}[-\s]?\d{3,4}[-\s]?\d{4}'
        text = re.sub(phone_pattern, convert_phone_number, text)

        # ë¹„ë°€ë²ˆí˜¸/ì½”ë“œ íŒ¨í„´ ì²˜ë¦¬
        def convert_code(match):
            """ì—°ì†ëœ ìˆ«ìë¥¼ í•œ ê¸€ìì”© ì½ê¸°"""
            prefix = match.group(1) if match.group(1) else ''
            code = match.group(2)
            digit_names = ['ê³µ', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
            result = ' '.join([digit_names[int(d)] for d in code])
            return prefix + result

        # ë¹„ë°€ë²ˆí˜¸, ì•”í˜¸, ì½”ë“œ ë“±ì˜ í‚¤ì›Œë“œ ë’¤ì— ì˜¤ëŠ” ìˆ«ì
        code_pattern = r'(ë¹„ë°€ë²ˆí˜¸ëŠ”?|ì•”í˜¸ëŠ”?|ì½”ë“œëŠ”?|ë²ˆí˜¸ëŠ”?)\s*(\d{4,})'
        text = re.sub(code_pattern, convert_code, text)

        def num_to_korean(num: int, sino: bool = True) -> str:
            if sino:
                ones = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
                tens = ['', 'ì‹­', 'ì´ì‹­', 'ì‚¼ì‹­', 'ì‚¬ì‹­', 'ì˜¤ì‹­', 'ìœ¡ì‹­', 'ì¹ ì‹­', 'íŒ”ì‹­', 'êµ¬ì‹­']

                if num == 0: return 'ì˜'
                if num < 10: return ones[num]
                elif num < 100:
                    return tens[num // 10] + (' ' + ones[num % 10] if num % 10 else '')
                elif num < 1000:
                    result = ('ë°±' if num // 100 == 1 else ones[num // 100] + 'ë°±')
                    if num % 100: result += ' ' + num_to_korean(num % 100, sino=True)
                    return result
                elif num < 10000:
                    result = ('ì²œ' if num // 1000 == 1 else ones[num // 1000] + 'ì²œ')
                    if num % 1000: result += ' ' + num_to_korean(num % 1000, sino=True)
                    return result
                elif num < 100000000:
                    result = num_to_korean(num // 10000, sino=True) + 'ë§Œ'
                    if num % 10000: result += ' ' + num_to_korean(num % 10000, sino=True)
                    return result
                else:
                    return str(num)
            else:
                native = ['', 'í•˜ë‚˜', 'ë‘˜', 'ì…‹', 'ë„·', 'ë‹¤ì„¯', 'ì—¬ì„¯', 'ì¼ê³±', 'ì—¬ëŸ', 'ì•„í™‰', 'ì—´']
                if num < 1 or num > 99: return num_to_korean(num, sino=True)
                if num <= 10: return native[num]
                elif num < 20: return 'ì—´' + (' ' + native[num - 10] if num > 10 else '')
                elif num < 100:
                    tens_native = ['', '', 'ìŠ¤ë¬´', 'ì„œë¥¸', 'ë§ˆí”', 'ì‰°', 'ì˜ˆìˆœ', 'ì¼í”', 'ì—¬ë“ ', 'ì•„í”']
                    result = tens_native[num // 10]
                    if num % 10: result += ' ' + native[num % 10]
                    return result
                else:
                    return num_to_korean(num, sino=True)

        def replace_number(match):
            num_str, unit = match.group(1), match.group(2) if match.group(2) else ''
            try:
                num = int(num_str)
                native_units = ['ë²ˆ', 'ë²ˆì§¸', 'ê°œ', 'ëª…', 'ë§ˆë¦¬', 'ì‚´', 'ì‹œ']
                use_native = any(unit.startswith(u) for u in native_units) and num <= 99
                korean_num = num_to_korean(num, sino=not use_native)

                # ë°›ì¹¨ íƒˆë½ ì²˜ë¦¬: ì…‹â†’ì„¸, ë„·â†’ë„¤, ìŠ¤ë¬¼â†’ìŠ¤ë¬´
                if unit and use_native:
                    if korean_num == 'ì…‹':
                        korean_num = 'ì„¸'
                    elif korean_num == 'ë„·':
                        korean_num = 'ë„¤'
                    elif korean_num.startswith('ì…‹ '):
                        korean_num = 'ì„¸ ' + korean_num[2:]
                    elif korean_num.startswith('ë„· '):
                        korean_num = 'ë„¤ ' + korean_num[2:]

                return korean_num + (' ' + unit if unit else '')
            except ValueError:
                return match.group(0)

        pattern = r'(\d+)(ë²ˆì§¸|ë²ˆ|ë¶„|ì´ˆ|ê°œ|ëª…|ë§ˆë¦¬|ì‚´|ì‹œ|ë“±|ìœ„|ë…„|ì›”|ì¼|íšŒ|ì°¨|ì¸µ|ëŒ€|ê¶Œ|ì¥|ê³¡|í¸|í™”|ê¸°|ì›|ë‹¬ëŸ¬|í‚¬ë¡œ|ë¯¸í„°|ì„¼í‹°|ê·¸ë¨|ë¦¬í„°)?'
        return re.sub(pattern, replace_number, text)

    def _clean_narration(self, text: str) -> str:
        """ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ ì •ë¦¬ (ëª…ë ¹ì–´ ë° ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°)"""
        # 1. TTSìš© í…ìŠ¤íŠ¸ ì •ë¦¬ (ë°±ìŠ¬ë˜ì‹œ, ì—ëŸ¬ ë©”ì‹œì§€, ìˆ«ì ë³€í™˜)
        text = self._clean_script_for_tts(text)

        # 2. ëŒ€ê´„í˜¸ ë§ˆì»¤ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜

        # [ë¬´ìŒ Nì´ˆ] â†’ ìˆ«ìë§Œí¼ ì¤„ë°”ê¿ˆ
        def replace_mute(match):
            num_str = match.group(1)
            if num_str:
                num = int(float(num_str))
                return '\n' * num
            return '\n'  # [ë¬´ìŒ] â†’ 1íšŒ
        text = re.sub(r'\[ë¬´ìŒ\s*(\d+(?:\.\d+)?)?ì´ˆ?\]', replace_mute, text)

        # [ì¹¨ë¬µ Nì´ˆ] â†’ NíšŒ ì¤„ë°”ê¿ˆ, ê¸°ë³¸ 3íšŒ
        def replace_silence(match):
            num_str = match.group(1)
            if num_str:
                num = int(float(num_str))
                return '\n' * num
            return '\n' * 3  # [ì¹¨ë¬µ] â†’ 3íšŒ
        text = re.sub(r'\[ì¹¨ë¬µ\s*(\d+(?:\.\d+)?)?ì´ˆ?\]', replace_silence, text)

        # [pause Nì´ˆ] â†’ NíšŒ ì¤„ë°”ê¿ˆ
        def replace_pause(match):
            num_str = match.group(1)
            if num_str:
                num = int(float(num_str))
                return '\n' * num
            return '\n'
        text = re.sub(r'\[pause\s*(\d+(?:\.\d+)?)?ì´ˆ?\]', replace_pause, text)

        # [íšŒìƒ] â†’ 3íšŒ ì¤„ë°”ê¿ˆ
        text = re.sub(r'\[íšŒìƒ\]', '\n\n\n', text)

        # ë‚˜ë¨¸ì§€ ëŒ€ê´„í˜¸ëŠ” ëª¨ë‘ ì œê±° (ê³µê°„, í–‰ë™, ë‚´ë©´ ë“±)
        text = re.sub(r'\[([^\]]+)\]', '', text)

        # ëŒ€í™” ë¶€ë¶„ ì œê±°ëŠ” í•˜ì§€ ì•ŠìŒ - ì„œì‚¬ì  í…ìŠ¤íŠ¸ëŠ” ëŒ€í™”ë¥¼ í¬í•¨í•¨
        # ì£¼ì„ ì²˜ë¦¬: text = re.sub(r'[ê°€-í£]+:\s*"[^"]*"', '', text)
        # ì£¼ì„ ì²˜ë¦¬: text = re.sub(r'[ê°€-í£]+:\s*[^\n/]+(?=/|$)', '', text)

        # / êµ¬ë¶„ì ì œê±°
        text = text.replace(' / ', ' ')

        # ì¤‘ë³µ ê³µë°± ì •ë¦¬ (ì¤„ë°”ê¿ˆì€ ìœ ì§€)
        text = re.sub(r' +', ' ', text)
        text = text.strip()

        return text

    def _add_natural_pauses(self, text: str) -> str:
        """êµ¬ë‘ì  ë’¤ì— ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì‰¼ íš¨ê³¼"""
        import re

        # ë¨¼ì € ì—°ì†ëœ êµ¬ë‘ì  ì¡°í•© ì²˜ë¦¬ (ì¤‘ë³µ ì¤„ë°”ê¿ˆ ë°©ì§€)
        # ." â†’ ."\n (í•œ ë²ˆë§Œ)
        text = text.replace('."', '."\n')
        # ?" â†’ ?"\n (í•œ ë²ˆë§Œ)
        text = text.replace('?"', '?"\n')
        # !" â†’ !"\n (í•œ ë²ˆë§Œ)
        text = text.replace('!"', '!"\n')

        # ... ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ê°€ì¥ ê¸´ ì‰¼)
        text = text.replace('...', '...\n')

        # ë‚¨ì€ " ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒì€ ì œì™¸)
        text = re.sub(r'"(?!\n)', '"\n', text)

        # ? ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒì€ ì œì™¸)
        text = re.sub(r'\?(?!\n)', '?\n', text)

        # ! ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒì€ ì œì™¸)
        text = re.sub(r'!(?!\n)', '!\n', text)

        # , ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ì§§ì€ ì‰¼)
        text = text.replace(',', ',\n')

        # . ë’¤ì— ì¤„ë°”ê¿ˆ ì¶”ê°€ (ë‹¨, ìˆ«ì ë’¤ë‚˜ ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒì€ ì œì™¸)
        text = re.sub(r'\.(?!\d)(?!\n)', '.\n', text)

        return text

    async def _generate_tts(self, text: str, output_path: Path) -> tuple:
        """Edge TTSë¡œ ìŒì„± ìƒì„± + ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
        logger.info(f"TTS ìƒì„± ì¤‘: {output_path.name}")

        # í…ìŠ¤íŠ¸ ì •ë¦¬
        clean_text = self._clean_narration(text)

        if not clean_text:
            logger.warning("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
            clean_text = "ë¬´ìŒ"

        # êµ¬ë‘ì ì— ì‰¼í‘œ ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ìš´ ì‰¼í‘œ íš¨ê³¼)
        tts_text = self._add_natural_pauses(clean_text)

        # Edge TTSë¡œ ìƒì„±í•˜ë©´ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ìˆ˜ì§‘
        # rate: -15%ë¡œ ì„¤ì •í•˜ì—¬ ì•½ê°„ ì²œì²œíˆ ë§í•˜ê²Œ í•¨
        communicate = edge_tts.Communicate(tts_text, self.voice, rate='-15%')

        word_timings = []
        sentence_timings = []
        audio_data = b""
        chunk_types_seen = set()

        async for chunk in communicate.stream():
            chunk_type = chunk.get("type", "unknown")
            chunk_types_seen.add(chunk_type)

            if chunk_type == "audio":
                audio_data += chunk["data"]
            elif chunk_type == "WordBoundary":
                # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥ (ì´ìƒì )
                word_timings.append({
                    "word": chunk["text"],
                    "start": chunk["offset"] / 10_000_000.0,
                    "end": (chunk["offset"] + chunk["duration"]) / 10_000_000.0
                })
            elif chunk_type == "SentenceBoundary":
                # ë¬¸ì¥ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥ (í´ë°±ìš©)
                sentence_timings.append({
                    "text": chunk.get("text", ""),
                    "start": chunk["offset"] / 10_000_000.0,
                    "end": (chunk["offset"] + chunk["duration"]) / 10_000_000.0 if "duration" in chunk else None
                })

        # WordBoundaryê°€ ì—†ìœ¼ë©´ SentenceBoundary ì‚¬ìš©
        if not word_timings and sentence_timings:
            logger.info(f"WordBoundary ì—†ìŒ, SentenceBoundary ì‚¬ìš©: {len(sentence_timings)}ê°œ ë¬¸ì¥")
            # ê° ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë¶„í• 
            for sent in sentence_timings:
                text = sent["text"].strip()
                if not text:
                    continue
                words = text.split()
                if not words:
                    continue

                # ë¬¸ì¥ ì‹œê°„ì„ ë‹¨ì–´ ê°œìˆ˜ë¡œ ê· ë“± ë¶„ë°°
                sent_duration = (sent["end"] - sent["start"]) if sent["end"] else 1.0
                time_per_word = sent_duration / len(words)

                for i, word in enumerate(words):
                    word_start = sent["start"] + (i * time_per_word)
                    word_end = word_start + time_per_word
                    word_timings.append({
                        "word": word,
                        "start": word_start,
                        "end": word_end
                    })

        if not word_timings:
            logger.warning(f"íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ! Chunk types: {chunk_types_seen}")

        # ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥
        with open(output_path, "wb") as f:
            f.write(audio_data)

        # ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
        try:
            audio_clip = AudioFileClip(str(output_path))
            duration = audio_clip.duration
            audio_clip.close()
        except Exception as e:
            logger.warning(f"ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • ì‹¤íŒ¨, ê¸°ë³¸ê°’ 1ì´ˆ ì‚¬ìš©: {e}")
            duration = 1.0

        if word_timings:
            logger.info(f"TTS ìƒì„± ì™„ë£Œ: {duration:.2f}ì´ˆ, ë‹¨ì–´ {len(word_timings)}ê°œ (íƒ€ì„ìŠ¤íƒ¬í”„ ìˆìŒ)")
        else:
            logger.warning(f"TTS ìƒì„± ì™„ë£Œ: {duration:.2f}ì´ˆ, íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ (ëŒ€ë³¸ ê¸°ë°˜ìœ¼ë¡œ í´ë°± ì˜ˆì •)")

        return duration, word_timings

    def _create_scene_video(self, scene_num: int, image_path: Path,
                           audio_path: Path, output_path: Path) -> Optional[Path]:
        """ì”¬ ë¹„ë””ì˜¤ ìƒì„± (ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤) - FFmpeg ì§ì ‘ ì‚¬ìš©"""
        try:
            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

            # FFmpeg ëª…ë ¹ì–´ë¡œ ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ ê²°í•© (ì´ˆê³ ì†)
            # -loop 1: ì´ë¯¸ì§€ ë°˜ë³µ
            # -i: ì…ë ¥ íŒŒì¼
            # -shortest: ì˜¤ë””ì˜¤ ê¸¸ì´ë§Œí¼ë§Œ
            # -c:v: ë¹„ë””ì˜¤ ì½”ë± (GPU ê°€ì†)
            # -c:a: ì˜¤ë””ì˜¤ ì½”ë±
            # -pix_fmt yuv420p: í˜¸í™˜ì„±
            # -vf scale: ë¦¬ìŠ¤ì¼€ì¼ + ë ˆí„°ë°•ìŠ¤

            cmd = [
                'ffmpeg',
                '-loop', '1',  # ì´ë¯¸ì§€ ë°˜ë³µ
                '-i', str(image_path.resolve()),  # ì…ë ¥ ì´ë¯¸ì§€ (ì ˆëŒ€ ê²½ë¡œ)
                '-i', str(audio_path.resolve()),  # ì…ë ¥ ì˜¤ë””ì˜¤ (ì ˆëŒ€ ê²½ë¡œ)
                '-vf', f"scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2:black",  # ë¦¬ìŠ¤ì¼€ì¼ + ë ˆí„°ë°•ìŠ¤
                '-c:v', self.video_codec,  # GPU ê°€ì† ì½”ë±
                '-preset', self.codec_preset,  # í”„ë¦¬ì…‹
                '-c:a', 'aac',  # ì˜¤ë””ì˜¤ ì½”ë±
                '-shortest',  # ì˜¤ë””ì˜¤ ê¸¸ì´ë§Œí¼
                '-pix_fmt', 'yuv420p',  # í˜¸í™˜ì„±
                '-y',  # ë®ì–´ì“°ê¸°
                str(output_path.resolve())  # ì¶œë ¥ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ)
            ]

            # FFmpeg ì‹¤í–‰ (UTF-8 ì¸ì½”ë”©)
            result = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding='utf-8', errors='ignore')

            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path

        except subprocess.CalledProcessError as e:
            # GPU ì¸ì½”ë” ì‹¤íŒ¨ ì‹œ CPU í´ë°±
            if 'h264_nvenc' in str(e.stderr) or 'nvenc' in str(e.stderr):
                logger.warning(f"ì”¬ {scene_num} GPU ì¸ì½”ë” ì‹¤íŒ¨, CPU ì¸ì½”ë”ë¡œ ì¬ì‹œë„...")

                # CPU ì¸ì½”ë”ë¡œ ì¬ì‹œë„
                cmd_cpu = [
                    'ffmpeg',
                    '-loop', '1',
                    '-i', str(image_path.resolve()),
                    '-i', str(audio_path.resolve()),
                    '-vf', f"scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2:black",
                    '-c:v', 'libx264',  # CPU ì¸ì½”ë”
                    '-preset', 'ultrafast',
                    '-c:a', 'aac',
                    '-shortest',
                    '-pix_fmt', 'yuv420p',
                    '-y',
                    str(output_path.resolve())
                ]

                try:
                    result = subprocess.run(cmd_cpu, check=True, capture_output=True, text=True, encoding='utf-8', errors='ignore')
                    logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ (CPU): {output_path}")
                    return output_path
                except subprocess.CalledProcessError as e2:
                    logger.error(f"ì”¬ {scene_num} CPU ì¸ì½”ë”ë„ ì‹¤íŒ¨: {e2.stderr}")
                    return None
            else:
                logger.error(f"ì”¬ {scene_num} FFmpeg ì‹¤í–‰ ì‹¤íŒ¨: {e.stderr}")
                return None
        except Exception as e:
            logger.error(f"ì”¨ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _create_scene_video_with_subtitles(self, scene_num: int, image_path: Path,
                                           audio_path: Path, output_path: Path,
                                           narration: str, audio_duration: float,
                                           word_timings: list = None) -> Optional[Path]:
        """ì”¬ ë¹„ë””ì˜¤ ìƒì„± (ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + ìë§‰ í¬í•¨) - FFmpeg ì§ì ‘ ì‚¬ìš©"""
        try:
            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ + ìë§‰ ìƒì„± ì¤‘...")

            # Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ASS ìë§‰ íŒŒì¼ ìƒì„± (ë˜ëŠ” ëŒ€ë³¸ ê¸°ë°˜ í´ë°±)
            srt_path = audio_path.with_suffix('.srt')
            ass_path = self._create_srt_with_timings(word_timings or [], srt_path, narration, audio_duration, max_chars_per_line=22)

            # FFmpeg ass í•„í„°ì—ëŠ” íŒŒì¼ëª…ë§Œ ì „ë‹¬ (ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆìŒ)
            ass_filename = ass_path.name
            logger.info(f"DEBUG ì”¬ {scene_num}: ass_filename = {ass_filename}")

            # FFmpeg ëª…ë ¹ì–´: ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + ìë§‰ì„ í•œë²ˆì— ì²˜ë¦¬ (ass í•„í„° ì‚¬ìš©)
            cmd = [
                'ffmpeg',
                '-loop', '1',
                '-i', str(image_path.resolve()),
                '-i', str(audio_path.resolve()),
                '-vf', f"scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2:black,ass={ass_filename}",
                '-c:v', self.video_codec,
                '-preset', self.codec_preset,
                '-c:a', 'aac',
                '-shortest',
                '-pix_fmt', 'yuv420p',
                '-y',
                str(output_path.resolve())
            ]

            logger.info(f"DEBUG ì”¬ {scene_num}: FFmpeg ëª…ë ¹ì–´ = {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding='utf-8', errors='ignore', cwd=str(output_path.parent))
            if result.stderr and 'error' in result.stderr.lower():
                logger.warning(f"FFmpeg ê²½ê³  (ì”¬ {scene_num}): {result.stderr[:500]}")
            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ + ìë§‰ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path

        except subprocess.CalledProcessError as e:
            # GPU ì¸ì½”ë” ì‹¤íŒ¨ ì‹œ CPU í´ë°± (stderr í™•ì¸ ë¶ˆê°€í•˜ë¯€ë¡œ íŒŒì¼ í¬ê¸°ë¡œ íŒë‹¨)
            if not output_path.exists() or output_path.stat().st_size == 0:
                logger.warning(f"ì”¬ {scene_num} GPU ì¸ì½”ë” ì‹¤íŒ¨, CPU ì¸ì½”ë”ë¡œ ì¬ì‹œë„...")

                # ASS ìë§‰ íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ ìƒì„±ë¨)
                srt_path = audio_path.with_suffix('.srt')
                ass_path = srt_path.with_suffix('.ass')
                # FFmpeg ass í•„í„°ì—ëŠ” íŒŒì¼ëª…ë§Œ ì „ë‹¬
                ass_filename = ass_path.name

                cmd_cpu = [
                    'ffmpeg',
                    '-loop', '1',
                    '-i', str(image_path.resolve()),
                    '-i', str(audio_path.resolve()),
                    '-vf', f"scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2:black,ass={ass_filename}",
                    '-c:v', 'libx264',
                    '-preset', 'ultrafast',
                    '-c:a', 'aac',
                    '-shortest',
                    '-pix_fmt', 'yuv420p',
                    '-y',
                    str(output_path.resolve())
                ]

                try:
                    result_cpu = subprocess.run(cmd_cpu, check=True, capture_output=True, text=True, encoding='utf-8', errors='ignore', cwd=str(output_path.parent))
                    if result_cpu.stderr and 'error' in result_cpu.stderr.lower():
                        logger.warning(f"FFmpeg CPU ê²½ê³  (ì”¬ {scene_num}): {result_cpu.stderr[:500]}")
                    logger.info(f"ì”¬ {scene_num} CPU ì¸ì½”ë”ë¡œ ì„±ê³µ")
                    return output_path
                except subprocess.CalledProcessError as e2:
                    logger.error(f"ì”¬ {scene_num} CPU ì¸ì½”ë”ë„ ì‹¤íŒ¨: {e2.stderr if hasattr(e2, 'stderr') else str(e2)}")
                    return None
            else:
                logger.error(f"ì”¬ {scene_num} FFmpeg ì‹¤í–‰ ì‹¤íŒ¨")
                return None
        except Exception as e:
            logger.error(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ + ìë§‰ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _create_scene_video_old_moviepy(self, scene_num: int, image_path: Path,
                           audio_path: Path, output_path: Path) -> Optional[Path]:
        """ì”¬ ë¹„ë””ì˜¤ ìƒì„± (ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤) - MoviePy ë²„ì „ (ëŠë¦¼, ë°±ì—…ìš©)"""
        try:
            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

            # ì˜¤ë””ì˜¤ í´ë¦½ ìƒì„± ë° ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
            audio_clip = AudioFileClip(str(audio_path))
            duration = audio_clip.duration

            # ì´ë¯¸ì§€ í´ë¦½ ìƒì„±
            img_clip = ImageClip(str(image_path), duration=duration)

            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
            orig_w, orig_h = img_clip.size
            logger.info(f"ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {orig_w}x{orig_h}, ëª©í‘œ í¬ê¸°: {self.width}x{self.height}")

            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í™”ë©´ì— ë§ì¶”ê¸° (í¬ë¡­ ì—†ì´, ë ˆí„°ë°•ìŠ¤ë¡œ)
            target_ratio = self.width / self.height
            img_ratio = orig_w / orig_h

            if img_ratio > target_ratio:
                # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ - ë„ˆë¹„ë¥¼ í™”ë©´ì— ë§ì¶”ê³  ìœ„ì•„ë˜ ê²€ì€ ì—¬ë°±
                img_clip = img_clip.resize(width=self.width)
            else:
                # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ - ë†’ì´ë¥¼ í™”ë©´ì— ë§ì¶”ê³  ì¢Œìš° ê²€ì€ ì—¬ë°±
                img_clip = img_clip.resize(height=self.height)

            # ì¤‘ì•™ ì •ë ¬ (ê²€ì€ ë°°ê²½ì— ì´ë¯¸ì§€ ë°°ì¹˜)
            from moviepy.editor import ColorClip, CompositeVideoClip
            bg = ColorClip(size=(self.width, self.height), color=(0, 0, 0), duration=duration)
            img_clip = CompositeVideoClip([bg, img_clip.set_position('center')], size=(self.width, self.height))

            # ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ ê²°í•©
            video = img_clip.set_audio(audio_clip)

            # ì €ì¥ (GPU ê°€ì† ì¸ì½”ë”©)
            video.write_videofile(
                str(output_path),
                fps=24,
                codec=self.video_codec,  # GPU ì¸ì½”ë” ë˜ëŠ” CPU
                audio_codec='aac',
                preset=self.codec_preset,  # ì¸ì½”ë”ì— ë§ëŠ” í”„ë¦¬ì…‹
                threads=4,  # ë©€í‹°ìŠ¤ë ˆë”© í™œì„±í™”
                logger=None
            )

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            img_clip.close()
            audio_clip.close()
            video.close()

            logger.info(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _combine_videos(self, video_paths: List[Path], output_path: Path, start_time: float) -> Optional[Path]:
        """ì—¬ëŸ¬ ì”¬ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ê²°í•© - simple_concat.py í˜¸ì¶œ"""
        import sys

        video_folder = output_path.parent

        logger.info(f"ë¹„ë””ì˜¤ ê²°í•© ì‹œì‘: {len(video_paths)}ê°œ ì”¬")

        # simple_concat.pyë¥¼ ìƒˆë¡œìš´ Python í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰
        script_path = Path(__file__).parent / "simple_concat.py"
        cmd = [
            sys.executable,  # í˜„ì¬ Python ì‹¤í–‰ íŒŒì¼
            str(script_path),
            str(video_folder),
            output_path.name
        ]

        logger.info(f"simple_concat.py ì‹¤í–‰: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')

        if result.stdout:
            logger.info(f"simple_concat.py ì¶œë ¥:\n{result.stdout}")

        if result.stderr:
            logger.warning(f"simple_concat.py ì—ëŸ¬:\n{result.stderr}")

        if result.returncode != 0:
            logger.error(f"simple_concat.py ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: {result.returncode})")
            if result.stderr:
                logger.error(f"ì—ëŸ¬ ë©”ì‹œì§€:\n{result.stderr}")
            return None

        # ì´ ìˆ˜í–‰ ì‹œê°„
        elapsed_time = time() - start_time
        minutes = int(elapsed_time // 60)
        seconds = int(elapsed_time % 60)
        logger.info(f"ë¹„ë””ì˜¤ ê²°í•© ì™„ë£Œ: {output_path}")
        logger.info(f"ì´ ìˆ˜í–‰ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")

        return output_path

    def _backup_previous_videos(self):
        """ê¸°ì¡´ generated_videos í´ë”ë¥¼ backupìœ¼ë¡œ ì´ë™ (íŒŒì¼ ì‚¬ìš© ì¤‘ì´ë©´ ê±´ë„ˆë›°ê¸°)"""
        import shutil
        from datetime import datetime

        output_folder = self.folder_path / "generated_videos"

        # generated_videos í´ë”ê°€ ìˆê³ , ë‚´ìš©ì´ ìˆìœ¼ë©´ ë°±ì—…
        if output_folder.exists() and any(output_folder.iterdir()):
            try:
                # backup í´ë” ìƒì„±
                backup_root = self.folder_path / "backup"
                backup_root.mkdir(exist_ok=True)

                # ë°±ì—… í´ë”ëª…: backup/YYYYMMDD_HHMMSS
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_folder = backup_root / timestamp

                # ì´ë™
                logger.info(f"ê¸°ì¡´ generated_videosë¥¼ ë°±ì—…í•©ë‹ˆë‹¤: {backup_folder.name}")
                shutil.move(str(output_folder), str(backup_folder))
                logger.info(f"ë°±ì—… ì™„ë£Œ: {backup_folder}")
            except PermissionError as e:
                # íŒŒì¼ì´ ì‚¬ìš© ì¤‘ì´ë©´ ë°±ì—…ì„ ê±´ë„ˆë›°ê³  ê¸°ì¡´ í´ë” ìœ ì§€
                logger.warning(f"âš ï¸  ë°±ì—… ì‹¤íŒ¨ (íŒŒì¼ ì‚¬ìš© ì¤‘)")
                logger.warning(f"   ê¸°ì¡´ generated_videos í´ë”ë¥¼ ìœ ì§€í•˜ê³  ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                logger.warning(f"   ğŸ’¡ ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ë‚˜ íƒìƒ‰ê¸°ë¥¼ ë‹«ìœ¼ë©´ ë°±ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                # í´ë”ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  ë‚´ìš©ë¬¼ë§Œ ì‚­ì œ ì‹œë„
                try:
                    for item in output_folder.iterdir():
                        try:
                            if item.is_file():
                                item.unlink()
                            elif item.is_dir():
                                shutil.rmtree(item)
                        except PermissionError:
                            logger.warning(f"   íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (ì‚¬ìš© ì¤‘): {item.name}")
                            continue
                except Exception as cleanup_error:
                    logger.warning(f"   í´ë” ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë¬´ì‹œí•˜ê³  ê³„ì†")
                    pass

    async def create_all_videos(self, combine: bool = True) -> Optional[Path]:
        """ëª¨ë“  ì”¬ì˜ ë¹„ë””ì˜¤ ìƒì„± ë° ê²°í•©"""
        start_time = time()

        # ê¸°ì¡´ generated_videos í´ë” ë°±ì—…
        self._backup_previous_videos()

        # ì´ë¯¸ì§€ ì°¾ê¸°
        images = self._find_images()

        if not images:
            logger.error("ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # scenes ê°€ì ¸ì˜¤ê¸°
        scenes = self.story_data.get("scenes", [])

        if not scenes:
            logger.error("story.jsonì— scenesê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ê¸°ì¡´ generated_videos í´ë” ë°±ì—… ê±´ë„ˆëœ€ (íŒŒì¼ ë®ì–´ì“°ê¸° í—ˆìš©)

        # ì¶œë ¥ í´ë” ìƒì„± (ë°±ì—… í›„ ìƒˆë¡œ ìƒì„±)
        output_folder = self.folder_path / "generated_videos"
        output_folder.mkdir(exist_ok=True)

        # 1ë‹¨ê³„: TTS ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
        logger.info("=" * 70)
        logger.info("1ë‹¨ê³„: TTS ìŒì„± ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)")
        logger.info("=" * 70)

        tts_tasks = []
        scene_data_list = []

        for scene in scenes:
            # scene_numberê°€ ì—†ìœ¼ë©´ scene_idì—ì„œ ì¶”ì¶œ
            scene_num = scene.get("scene_number")
            if scene_num is None:
                scene_id = scene.get("scene_id", "")
                # scene_01_main, scene_02_main ë“±ì—ì„œ ë²ˆí˜¸ ì¶”ì¶œ
                import re
                match = re.search(r'scene_(\d+)', scene_id)
                if match:
                    scene_num = int(match.group(1))
                else:
                    logger.warning(f"ì”¬ ID '{scene_id}'ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
                    continue

            narration = scene.get("narration") or scene.get("content", "")

            # scene_numì´ 0ì´ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            if scene_num == 0:
                logger.info(f"ì”¬ {scene_num} (ì¸íŠ¸ë¡œ/í­íƒ„ì”¬): ì´ë¯¸ì§€ ì—†ì´ ê±´ë„ˆëœ€.")
                continue

            if scene_num not in images:
                logger.warning(f"ì”¬ {scene_num}ì˜ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
                continue

            # ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ ì €ì¥
            narration_txt_path = output_folder / f"scene_{scene_num:02d}_narration.txt"
            clean_narration = self._clean_narration(narration)
            with open(narration_txt_path, 'w', encoding='utf-8') as f:
                f.write(clean_narration)

            # TTS íƒœìŠ¤í¬ ìƒì„±
            audio_path = output_folder / f"scene_{scene_num:02d}_audio.mp3"
            tts_tasks.append(self._generate_tts(narration, audio_path))

            scene_data_list.append({
                'scene_num': scene_num,
                'image_path': images[scene_num],
                'audio_path': audio_path,
                'clean_narration': clean_narration
            })

        # TTS ë³‘ë ¬ ìƒì„± (8ê°œì”© ì œí•œ) - íƒ€ì„ìŠ¤íƒ¬í”„ë„ í•¨ê»˜ ë°›ìŒ!
        logger.info(f"âš¡ TTS ë³‘ë ¬ ìƒì„±: ìµœëŒ€ 8ê°œì”© ë™ì‹œ ì²˜ë¦¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)")

        tts_results = []
        batch_size = 8
        for i in range(0, len(tts_tasks), batch_size):
            batch = tts_tasks[i:i+batch_size]
            batch_results = await asyncio.gather(*batch)
            tts_results.extend(batch_results)
            logger.info(f"TTS ë°°ì¹˜ ì™„ë£Œ: {i+1}~{min(i+len(batch), len(tts_tasks))}/{len(tts_tasks)}")

        logger.info(f"TTS ìƒì„± ì™„ë£Œ: {len(tts_tasks)}ê°œ")

        # ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ scene_dataì— ì €ì¥
        for i, scene_data in enumerate(scene_data_list):
            duration, word_timings = tts_results[i]
            scene_data['audio_duration'] = duration
            scene_data['word_timings'] = word_timings  # Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„!

        # 2ë‹¨ê³„: ê±´ë„ˆëœ€ (Whisper ëŒ€ì‹  ëŒ€ë³¸ ì‚¬ìš©)
        # Whisper ìŒì„± ì¸ì‹ ì—†ì´ ëŒ€ë³¸ì„ ì§ì ‘ ì‚¬ìš©í•˜ë¯€ë¡œ í›¨ì”¬ ë¹ ë¦„!

        # 3ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„± + ìë§‰ ì¶”ê°€ (ë³‘ë ¬ ì²˜ë¦¬)
        logger.info("=" * 70)
        logger.info("3ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„± ë° ìë§‰ ì¶”ê°€")
        logger.info("=" * 70)

        # ì¸ì½”ë” ì •ë³´ í‘œì‹œ
        encoder_type = "GPU ê°€ì†" if self.video_codec != 'libx264' else "CPU"
        logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì¸ì½”ë”: {self.video_codec} ({encoder_type})")
        logger.info(f"ğŸ“Š ì´ {len(scene_data_list)}ê°œ ì”¬ ì²˜ë¦¬ ì˜ˆì •")

        # ì‹œìŠ¤í…œì— ë¬´ë¦¬ ì•ˆ ê°€ë„ë¡ ì›Œì»¤ ìˆ˜ ì œí•œ (CPU ì½”ì–´ì˜ 75%, ìµœì†Œ 2, ìµœëŒ€ 4)
        cpu_count = multiprocessing.cpu_count()
        max_workers = max(2, min(4, (cpu_count * 3) // 4))
        logger.info(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬: {max_workers}ê°œ ì›Œì»¤ (CPU ì½”ì–´: {cpu_count}ê°œ)")
        logger.info("=" * 70)

        scene_videos = []
        all_narrations = []

        # ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜
        def process_scene(idx, scene_data):
            scene_num = scene_data['scene_num']
            image_path = scene_data['image_path']
            audio_path = scene_data['audio_path']
            clean_narration = scene_data['clean_narration']

            progress = f"[{idx}/{len(scene_data_list)}]"
            logger.info(f"\n{progress} ì”¬ {scene_num} ì²˜ë¦¬ ì¤‘...")

            # ë¹„ë””ì˜¤ ìƒì„± (ìë§‰ í¬í•¨)
            video_path = output_folder / f"scene_{scene_num:02d}.mp4"
            logger.info(f"{progress} ì”¬ {scene_num} ë¹„ë””ì˜¤ ìƒì„± ì¤‘... ({encoder_type})")

            # ìë§‰ ì¶”ê°€ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
            if self.add_subtitles:
                audio_duration = scene_data.get('audio_duration', 1.0)
                word_timings = scene_data.get('word_timings', [])  # Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„
                result = self._create_scene_video_with_subtitles(
                    scene_num, image_path, audio_path, video_path,
                    clean_narration, audio_duration, word_timings
                )
            else:
                result = self._create_scene_video(scene_num, image_path, audio_path, video_path)

            if result:
                logger.info(f"{progress} âœ… ì”¬ {scene_num} ì™„ë£Œ!")
                return (scene_num, result, clean_narration)
            return None

        # ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_scene, idx, scene_data): idx
                      for idx, scene_data in enumerate(scene_data_list, 1)}

            for future in as_completed(futures):
                result = future.result()
                if result:
                    scene_num, video_path, narration = result
                    scene_videos.append((scene_num, video_path))
                    all_narrations.append(narration)

        # ì”¬ ë²ˆí˜¸ ìˆœì„œë¡œ ì •ë ¬
        scene_videos.sort(key=lambda x: x[0])
        scene_videos = [path for _, path in scene_videos]

        if not scene_videos:
            logger.error("ìƒì„±ëœ ì”¬ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì „ì²´ ë‚˜ë ˆì´ì…˜ ì €ì¥
        full_narration_path = output_folder / "full_narration.txt"
        with open(full_narration_path, 'w', encoding='utf-8') as f:
            f.write('\n\n'.join(all_narrations))
        logger.info(f"ì „ì²´ ë‚˜ë ˆì´ì…˜ ì €ì¥: {full_narration_path}")

        # ê²°í•©
        if combine and len(scene_videos) > 1:
            # titleì´ ìµœìƒìœ„ì— ìˆê±°ë‚˜ metadata ì•ˆì— ìˆì„ ìˆ˜ ìˆìŒ
            title = self.story_data.get("title")
            if not title and "metadata" in self.story_data:
                title = self.story_data["metadata"].get("title")
            if not title:
                title = "video"

            # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '_', '-', '.')).strip()
            safe_title = safe_title.replace(' ', '_')
            final_path = output_folder / f"{safe_title}.mp4"
            logger.info(f"ğŸ“ ìµœì¢… ì˜ìƒ ì œëª©: {title} â†’ {safe_title}.mp4")
            return self._combine_videos(scene_videos, final_path, start_time)
        elif scene_videos:
            logger.info(f"ì”¬ ë¹„ë””ì˜¤ {len(scene_videos)}ê°œ ìƒì„± ì™„ë£Œ (ê²°í•© ì•ˆ í•¨)")
            return scene_videos[0]

        return None

    async def _generate_word_timestamps_async(self, audio_path: Path) -> list:
        """Whisperë¡œ ìŒì„± ë¶„ì„í•˜ì—¬ ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (async ë²„ì „)"""
        import concurrent.futures

        def _run_whisper(audio_path_str):
            try:
                import whisper

                logger.info(f"Whisper ë¶„ì„ ì¤‘: {Path(audio_path_str).name}")

                # Whisper ëª¨ë¸ ë¡œë“œ (base ëª¨ë¸: ë¹ ë¥´ê³  ì¶©ë¶„íˆ ì •í™•í•¨)
                model = whisper.load_model("base")

                # ìŒì„± ì¸ì‹ ì‹¤í–‰ (ì„¸ê·¸ë¨¼íŠ¸ ë‹¨ìœ„ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ)
                result = model.transcribe(
                    audio_path_str,
                    language="ko",
                    verbose=False,
                    fp16=False  # CPUì—ì„œ FP16 ê²½ê³  ë°©ì§€
                )

                # ì„¸ê·¸ë¨¼íŠ¸ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë³€í™˜
                word_segments = []
                for segment in result.get("segments", []):
                    # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ë¡œ ë¶„ë¦¬
                    text = segment.get("text", "").strip()
                    words = text.split()

                    if not words:
                        continue

                    # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ì„ ë‹¨ì–´ ê°œìˆ˜ë¡œ ë‚˜ëˆ ì„œ ê·¼ì‚¬ì¹˜ ê³„ì‚°
                    start_time = segment.get("start", 0)
                    end_time = segment.get("end", 0)
                    duration = end_time - start_time
                    time_per_word = duration / len(words) if words else 0

                    for i, word in enumerate(words):
                        word_start = start_time + (i * time_per_word)
                        word_end = start_time + ((i + 1) * time_per_word)
                        word_segments.append({
                            "word": word.strip(),
                            "start": word_start,
                            "end": word_end
                        })

                logger.info(f"Whisper ì™„ë£Œ: {Path(audio_path_str).name} - {len(word_segments)}ê°œ ë‹¨ì–´")
                return word_segments

            except Exception as e:
                logger.error(f"Whisper ë¶„ì„ ì‹¤íŒ¨ ({Path(audio_path_str).name}): {e}")
                import traceback
                logger.error(traceback.format_exc())
                # ìë§‰ ìƒì„± ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œ ì˜ìƒ ì œì‘ ì¤‘ë‹¨
                raise RuntimeError(f"ìë§‰ ìƒì„± ì‹¤íŒ¨: {Path(audio_path_str).name} - {e}")

        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            return await loop.run_in_executor(executor, _run_whisper, str(audio_path))

    def _generate_word_timestamps(self, audio_path: Path) -> list:
        """Whisperë¡œ ìŒì„± ë¶„ì„í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (ë™ê¸° ë²„ì „)"""
        try:
            import whisper

            logger.info(f"Whisperë¡œ ìŒì„± ë¶„ì„ ì¤‘: {audio_path.name}")

            # Whisper ëª¨ë¸ ë¡œë“œ (base ëª¨ë¸: ë¹ ë¥´ê³  ì¶©ë¶„íˆ ì •í™•í•¨)
            model = whisper.load_model("base")

            # ìŒì„± ì¸ì‹ ì‹¤í–‰
            result = model.transcribe(
                str(audio_path),
                language="ko",
                verbose=False,
                fp16=False  # CPUì—ì„œ FP16 ê²½ê³  ë°©ì§€
            )

            # ì„¸ê·¸ë¨¼íŠ¸ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ í›„ ë‹¨ì–´ë¡œ ë¶„í• 
            word_segments = []

            if not result or "segments" not in result:
                logger.warning("Whisperê°€ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ")
                return []

            for segment in result.get("segments", []):
                text = segment.get("text", "").strip()
                start_time = segment.get("start", 0.0)
                end_time = segment.get("end", 0.0)

                if not text:
                    continue

                # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ë¡œ ë¶„í• 
                words = text.split()
                if not words:
                    continue

                # ê° ë‹¨ì–´ì— ê· ë“±í•˜ê²Œ ì‹œê°„ ë¶„ë°°
                duration_per_word = (end_time - start_time) / len(words)

                for i, word in enumerate(words):
                    word_start = start_time + (i * duration_per_word)
                    word_end = word_start + duration_per_word

                    word_segments.append({
                        "word": word.strip(),
                        "start": word_start,
                        "end": word_end
                    })

            logger.info(f"ë‹¨ì–´ {len(word_segments)}ê°œì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì™„ë£Œ")
            return word_segments

        except Exception as e:
            logger.error(f"Whisper ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # ìë§‰ ìƒì„± ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œ ì˜ìƒ ì œì‘ ì¤‘ë‹¨
            raise RuntimeError(f"ìë§‰ ìƒì„± ì‹¤íŒ¨ (Fallback): {audio_path.name} - {e}")

    def _create_srt_with_timings(self, word_timings: list, srt_path: Path, narration: str, audio_duration: float, max_chars_per_line: int = 22):
        """Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„ ë˜ëŠ” ëŒ€ë³¸ ê¸°ë°˜ ASS ìë§‰ ìƒì„±"""
        try:
            # Edge TTSì—ì„œ ë°›ì€ ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
            word_segments = word_timings

            if not word_segments:
                logger.warning("íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë¹„ì–´ìˆìŒ â†’ ëŒ€ë³¸ ê¸°ë°˜ ìë§‰ìœ¼ë¡œ í´ë°±")
                return self._create_srt_from_script(narration, audio_duration, srt_path, max_chars_per_line)

            logger.info(f"Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ìë§‰ ìƒì„± ì¤‘... ({len(word_segments)}ê°œ ë‹¨ì–´)")

            # ë‹¨ì–´ë“¤ì„ max_chars_per_lineì— ë§ì¶° ê·¸ë£¹í™”
            subtitles = []
            current_text = ""
            current_start = None
            current_end = None

            MIN_REMAINING_CHARS = 5

            for i, word_info in enumerate(word_segments):
                word = word_info["word"]
                start = word_info["start"]
                end = word_info["end"]

                # ë¹ˆ ë‹¨ì–´ëŠ” ê±´ë„ˆë›°ê¸°
                if not word.strip():
                    continue

                # ì²« ë‹¨ì–´ë©´ ì‹œì‘ ì‹œê°„ ì„¤ì •
                if current_start is None:
                    current_start = start

                # ë‹¤ìŒ í…ìŠ¤íŠ¸ ê³„ì‚°
                next_text = current_text + (" " if current_text else "") + word

                # ë‚¨ì€ ë‹¨ì–´ë“¤ ê³„ì‚°
                remaining_words = word_segments[i+1:]
                remaining_text = " ".join([w["word"] for w in remaining_words]) if remaining_words else ""

                # ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ ë¡œì§
                if len(next_text) > max_chars_per_line and current_text:
                    # ë‚¨ì€ ê¸€ìê°€ ë„ˆë¬´ ì ìœ¼ë©´ í˜„ì¬ ë¼ì¸ì— í¬í•¨
                    if len(remaining_text) > 0 and len(remaining_text) < MIN_REMAINING_CHARS:
                        current_text = next_text + (" " + remaining_text if remaining_text else "")
                        # ë‚¨ì€ ëª¨ë“  ë‹¨ì–´ì˜ ë ì‹œê°„ ì°¾ê¸°
                        if remaining_words:
                            current_end = remaining_words[-1]["end"]
                        else:
                            current_end = end

                        subtitles.append({
                            "start": current_start,
                            "end": current_end,
                            "text": current_text.strip()
                        })
                        break  # ëª¨ë“  ë‹¨ì–´ ì²˜ë¦¬ ì™„ë£Œ
                    else:
                        # ì •ìƒì ìœ¼ë¡œ ì¤„ë°”ê¿ˆ
                        subtitles.append({
                            "start": current_start,
                            "end": end,
                            "text": current_text.strip()
                        })
                        current_text = word
                        current_start = start
                        current_end = end
                else:
                    current_text = next_text
                    current_end = end

            # ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
            if current_text:
                subtitles.append({
                    "start": current_start,
                    "end": current_end,
                    "text": current_text.strip()
                })

            # ìë§‰ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì‹œê°„ ì¡°ì •
            for i in range(len(subtitles) - 1):
                current_sub = subtitles[i]
                next_sub = subtitles[i + 1]

                # í˜„ì¬ ìë§‰ì´ ë‹¤ìŒ ìë§‰ê³¼ ê²¹ì¹˜ë©´ í˜„ì¬ ìë§‰ ì¢…ë£Œ ì‹œê°„ì„ ë‹¤ìŒ ìë§‰ ì‹œì‘ ì „ìœ¼ë¡œ ì¡°ì •
                if current_sub["end"] > next_sub["start"]:
                    # 0.05ì´ˆ ê°„ê²© ë‘ê¸°
                    current_sub["end"] = max(current_sub["start"] + 0.1, next_sub["start"] - 0.05)

            # ASS íŒŒì¼ ì‘ì„±
            ass_path = srt_path.with_suffix('.ass')

            with open(ass_path, 'w', encoding='utf-8') as f:
                # ASS í—¤ë”
                f.write("[Script Info]\n")
                f.write("ScriptType: v4.00+\n")
                f.write("PlayResX: 1920\n")
                f.write("PlayResY: 1080\n\n")

                # ìŠ¤íƒ€ì¼ ì •ì˜ - NanumGothic 96pt, ë§¨ í•˜ë‹¨
                f.write("[V4+ Styles]\n")
                f.write("Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n")
                f.write("Style: Default,NanumGothic,96,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,3,2,2,10,10,20,1\n\n")

                # ì´ë²¤íŠ¸ (ìë§‰) - audio_durationì„ ì´ˆê³¼í•˜ëŠ” ìë§‰ í•„í„°ë§
                f.write("[Events]\n")
                f.write("Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n")

                filtered_subtitles = []
                for sub in subtitles:
                    # audio_durationì„ ì´ˆê³¼í•˜ëŠ” ìë§‰ì€ ì œì™¸
                    if sub["start"] < audio_duration:
                        # ë ì‹œê°„ì´ durationì„ ì´ˆê³¼í•˜ë©´ durationìœ¼ë¡œ ì˜ë¼ëƒ„
                        end_time_adjusted = min(sub["end"], audio_duration)
                        filtered_subtitles.append({
                            "start": sub["start"],
                            "end": end_time_adjusted,
                            "text": sub["text"]
                        })

                for sub in filtered_subtitles:
                    start_time = self._format_ass_timestamp(sub["start"])
                    end_time = self._format_ass_timestamp(sub["end"])
                    text = sub["text"].replace('\n', '\\N')
                    f.write(f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\n")

            logger.info(f"Edge TTS íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ASS ìë§‰ ì™„ë£Œ: {len(filtered_subtitles)}ê°œ ë¼ì¸ (duration: {audio_duration:.2f}ì´ˆ)")
            return ass_path

        except Exception as e:
            logger.error(f"ìë§‰ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise RuntimeError(f"ìë§‰ ìƒì„± ì‹¤íŒ¨: {e}")

    def _create_srt_from_script(self, narration: str, audio_duration: float, srt_path: Path, max_chars_per_line: int = 22):
        """ëŒ€ë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ SRT ìë§‰ ìƒì„± (Whisper ì—†ì´)"""
        if not narration or not narration.strip():
            raise RuntimeError("ìë§‰ ìƒì„± ì‹¤íŒ¨: ëŒ€ë³¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # ëŒ€ë³¸ì„ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
        import re
        sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', narration)

        # ë¶„ë¦¬ëœ êµ¬ë‘ì ì„ ì• ë¬¸ì¥ì— ë¶™ì´ê¸°
        combined_sentences = []
        for i in range(0, len(sentences)-1, 2):
            if i+1 < len(sentences):
                combined_sentences.append((sentences[i] + sentences[i+1]).strip())

        # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
        if len(sentences) % 2 == 1 and sentences[-1].strip():
            combined_sentences.append(sentences[-1].strip())

        # ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ
        if not combined_sentences:
            combined_sentences = [narration.strip()]

        # ì „ì²´ ê¸€ì ìˆ˜ ê³„ì‚° (ê³µë°± í¬í•¨)
        total_text = " ".join(combined_sentences)
        total_chars = len(total_text)
        time_per_char = audio_duration / total_chars if total_chars > 0 else 0

        # ê° ë¬¸ì¥ì„ 22ì ë‹¨ìœ„ë¡œ ë¶„í•  (ê¸€ì ìˆ˜ ê¸°ë°˜ íƒ€ì´ë°)
        subtitles = []
        current_time = 0.0

        MIN_REMAINING_CHARS = 5  # ë‚¨ì€ ê¸€ìê°€ ì´ë³´ë‹¤ ì ìœ¼ë©´ í˜„ì¬ ë¼ì¸ì— í¬í•¨

        for sentence in combined_sentences:
            # ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬
            words = sentence.split()
            if not words:
                continue

            current_text = ""
            for i, word in enumerate(words):
                next_text = current_text + (" " if current_text else "") + word

                # ë‹¤ìŒ ë‹¨ì–´ê¹Œì§€ í¬í•¨í•˜ë©´ ì–¼ë§ˆë‚˜ ë‚¨ëŠ”ì§€ ê³„ì‚°
                remaining_words = words[i+1:]
                remaining_text = " ".join(remaining_words) if remaining_words else ""

                # ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ ë¡œì§
                if len(next_text) > max_chars_per_line and current_text:
                    # ë‚¨ì€ ê¸€ìê°€ ë„ˆë¬´ ì ìœ¼ë©´ (1-2ê¸€ì) í˜„ì¬ ë¼ì¸ì— í¬í•¨
                    if len(remaining_text) > 0 and len(remaining_text) < MIN_REMAINING_CHARS:
                        # í˜„ì¬ ë‹¨ì–´ë¥¼ í¬í•¨í•˜ê³  ì¤„ë°”ê¿ˆ (ë‹¤ìŒ ë‹¨ì–´ë“¤ë„ í•¨ê»˜)
                        current_text = next_text + (" " + remaining_text if remaining_text else "")
                        duration = len(current_text) * time_per_char
                        end_time = current_time + duration
                        subtitles.append({
                            "start": current_time,
                            "end": end_time,
                            "text": current_text.strip()
                        })
                        current_text = ""
                        current_time = end_time
                        break  # ì´ ë¬¸ì¥ ë
                    else:
                        # ì •ìƒì ìœ¼ë¡œ ì¤„ë°”ê¿ˆ
                        duration = len(current_text) * time_per_char
                        end_time = current_time + duration
                        subtitles.append({
                            "start": current_time,
                            "end": end_time,
                            "text": current_text.strip()
                        })
                        current_text = word
                        current_time = end_time
                else:
                    current_text = next_text

            # ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
            if current_text:
                duration = len(current_text) * time_per_char
                end_time = current_time + duration
                subtitles.append({
                    "start": current_time,
                    "end": end_time,
                    "text": current_text.strip()
                })
                current_time = end_time

        # ASS íŒŒì¼ ì‘ì„± (ìŠ¤íƒ€ì¼ í¬í•¨)
        ass_path = srt_path.with_suffix('.ass')

        with open(ass_path, 'w', encoding='utf-8') as f:
            # ASS í—¤ë”
            f.write("[Script Info]\n")
            f.write("ScriptType: v4.00+\n")
            f.write("PlayResX: 1920\n")
            f.write("PlayResY: 1080\n\n")

            # ìŠ¤íƒ€ì¼ ì •ì˜
            f.write("[V4+ Styles]\n")
            f.write("Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n")
            f.write("Style: Default,NanumGothic,96,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,3,2,2,10,10,20,1\n\n")

            # ì´ë²¤íŠ¸ (ìë§‰)
            f.write("[Events]\n")
            f.write("Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n")

            for sub in subtitles:
                start = self._format_ass_timestamp(sub["start"])
                end = self._format_ass_timestamp(sub["end"])
                text = sub['text'].replace('\n', '\\N')
                f.write(f"Dialogue: 0,{start},{end},Default,,0,0,0,,{text}\n")

        logger.info(f"ëŒ€ë³¸ ê¸°ë°˜ ASS ìƒì„± ì™„ë£Œ: {len(subtitles)}ê°œ êµ¬ê°„")

        # SRT ê²½ë¡œë¥¼ ASS ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸ (í˜¸ì¶œìê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)
        if srt_path != ass_path:
            # srt_path ë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ass_path ë°˜í™˜
            pass

        return ass_path

    def _create_srt_from_timestamps(self, word_segments: list, srt_path: Path, max_chars_per_line: int = 22):
        """ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ SRT ìë§‰ íŒŒì¼ ìƒì„± (ì ì ˆí•œ ê¸¸ì´ë¡œ ê·¸ë£¹í™”)"""
        if not word_segments:
            raise RuntimeError("ìë§‰ ìƒì„± ì‹¤íŒ¨: ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ìŠµë‹ˆë‹¤.")

        subtitles = []
        current_text = ""
        start_time = None
        min_remaining_chars = 5  # ë‚¨ì€ ê¸€ìê°€ ì´ë³´ë‹¤ ì ìœ¼ë©´ í˜„ì¬ ë¼ì¸ì— í¬í•¨

        for i, segment in enumerate(word_segments):
            word = segment["word"]

            # ì²« ë‹¨ì–´ë©´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            if not current_text:
                start_time = segment["start"]

            # ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì¶”ê°€í–ˆì„ ë•Œì˜ ê¸¸ì´ í™•ì¸ (ë„ì–´ì“°ê¸° í¬í•¨)
            next_text = current_text + (" " if current_text else "") + word
            is_last_word = (i == len(word_segments) - 1)

            # ë§ˆì§€ë§‰ ë‹¨ì–´ì´ê±°ë‚˜, ë‹¤ìŒ ë‹¨ì–´ê¹Œì§€ ì¶”ê°€í•´ë„ ì ì ˆí•œ ê¸¸ì´ë©´ ì¶”ê°€
            if is_last_word:
                current_text = next_text
                subtitles.append({
                    "start": start_time,
                    "end": segment["end"],
                    "text": current_text.strip()
                })
            elif len(next_text) >= max_chars_per_line:
                # í˜„ì¬ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ìë§‰ ìƒì„±
                if current_text:
                    subtitles.append({
                        "start": start_time,
                        "end": word_segments[i-1]["end"] if i > 0 else segment["end"],
                        "text": current_text.strip()
                    })
                    current_text = word
                    start_time = segment["start"]
                else:
                    # ë‹¨ì–´ í•˜ë‚˜ê°€ max_chars_per_lineë³´ë‹¤ ê¸´ ê²½ìš°
                    current_text = next_text
            else:
                # ë‹¤ìŒ ë‹¨ì–´ ì¶”ê°€
                current_text = next_text

                # ë‹¤ìŒë‹¤ìŒ ë‹¨ì–´ë¥¼ ë¯¸ë¦¬ í™•ì¸ (ë‚¨ì€ ê¸€ì ìˆ˜ ì˜ˆì¸¡)
                if i + 1 < len(word_segments):
                    peek_text = current_text + " " + word_segments[i + 1]["word"]
                    # ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ë©´ maxë¥¼ ë„˜ê³ , ë‚¨ì€ ê¸€ìê°€ ë„ˆë¬´ ì ì„ ê²ƒ ê°™ìœ¼ë©´ ì§€ê¸ˆ ëŠê¸°
                    if len(peek_text) > max_chars_per_line and len(peek_text) - max_chars_per_line < min_remaining_chars:
                        # ì§€ê¸ˆ ìë§‰ ìƒì„±
                        subtitles.append({
                            "start": start_time,
                            "end": segment["end"],
                            "text": current_text.strip()
                        })
                        current_text = ""

        # SRT íŒŒì¼ ì‘ì„±
        with open(srt_path, 'w', encoding='utf-8') as f:
            for i, sub in enumerate(subtitles, 1):
                start = self._format_timestamp(sub["start"])
                end = self._format_timestamp(sub["end"])
                f.write(f"{i}\n")
                f.write(f"{start} --> {end}\n")
                f.write(f"{sub['text']}\n\n")

        logger.info(f"SRT ìë§‰ ìƒì„± ì™„ë£Œ: {len(subtitles)}ê°œ êµ¬ê°„")
        return True

    def _format_timestamp(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (00:00:00,000)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def _format_ass_timestamp(self, seconds: float) -> str:
        """ì´ˆë¥¼ ASS íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0:00:00.00)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        centisecs = int((seconds % 1) * 100)
        return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"

    def _add_subtitles_with_segments(self, video_path: Path, audio_path: Path, output_path: Path, word_segments: list):
        """ë¯¸ë¦¬ ë¶„ì„ëœ Whisper íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ìë§‰ ì¶”ê°€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        import subprocess

        # ìë§‰ ìŠ¤íƒ€ì¼ (ë‚˜ëˆ”ê³ ë”•, í° ê¸€ì”¨) - _add_subtitles_from_scriptì™€ ë™ì¼í•˜ê²Œ
        subtitle_style = (
            "FontName=NanumGothic,"  # ë‚˜ëˆ”ê³ ë”•
            "Fontsize=32,"  # 20 -> 32 (ë” í¼)
            "Bold=1,"  # ë³¼ë“œ
            "PrimaryColour=&H00FFFFFF,"  # í°ìƒ‰
            "OutlineColour=&H00000000,"  # ê²€ì€ í…Œë‘ë¦¬
            "BorderStyle=1,"
            "Outline=3,"  # ë” ë‘êº¼ìš´ í…Œë‘ë¦¬
            "Shadow=2,"  # ë” ì§„í•œ ê·¸ë¦¼ì
            "MarginV=20,"  # ë§¨ í•˜ë‹¨
            "Alignment=2"  # í•˜ë‹¨ ì¤‘ì•™
        )

        # SRT íŒŒì¼ ìƒì„±
        srt_path = audio_path.with_suffix('.srt')

        # ë¯¸ë¦¬ ë¶„ì„ëœ Whisper íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì •í™•í•œ ìë§‰ ìƒì„±
        # word_segmentsê°€ ì—†ìœ¼ë©´ _create_srt_from_timestampsì—ì„œ ì˜ˆì™¸ ë°œìƒ
        self._create_srt_from_timestamps(word_segments, srt_path, max_chars_per_line=22)

        # FFmpeg ëª…ë ¹ì–´
        cmd = [
            'ffmpeg', '-i', str(video_path),
            '-vf', f"subtitles={str(srt_path)}:force_style='{subtitle_style}'",
            '-c:a', 'copy',
            '-y',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    def _add_subtitles_from_script(self, video_path: Path, audio_path: Path, output_path: Path, narration: str, audio_duration: float):
        """ëŒ€ë³¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìë§‰ ì¶”ê°€ (Whisper ì—†ì´)"""
        import subprocess

        # SRT íŒŒì¼ ê²½ë¡œ (ì‹¤ì œë¡œëŠ” ASS íŒŒì¼ì´ ìƒì„±ë¨)
        srt_path = audio_path.with_suffix('.srt')

        # ëŒ€ë³¸ ê¸°ë°˜ ASS ìë§‰ ìƒì„± (ìŠ¤íƒ€ì¼ í¬í•¨)
        ass_path = self._create_srt_from_script(narration, audio_duration, srt_path, max_chars_per_line=22)

        # FFmpeg ass í•„í„°ì—ëŠ” íŒŒì¼ëª…ë§Œ ì „ë‹¬
        ass_filename = ass_path.name

        # FFmpeg ëª…ë ¹ì–´ (ASS íŒŒì¼ì€ ì´ë¯¸ ìŠ¤íƒ€ì¼ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ force_style ë¶ˆí•„ìš”)
        cmd = [
            'ffmpeg', '-i', str(video_path),
            '-vf', f"ass={ass_filename}",
            '-c:a', 'copy',
            '-y',
            str(output_path)
        ]

        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding='utf-8', errors='ignore', cwd=str(audio_path.parent))
        except subprocess.CalledProcessError as e:
            logger.error(f"FFmpeg ìë§‰ ì¶”ê°€ ì‹¤íŒ¨: {e.stderr}")
            raise

    def _add_subtitles(self, video_path: Path, audio_path: Path, output_path: Path):
        """Whisperë¡œ ìŒì„± ë¶„ì„ í›„ ì •í™•í•œ íƒ€ì´ë°ì˜ ìë§‰ ì¶”ê°€ (ë™ê¸° ë²„ì „ - í˜¸í™˜ì„±ìš©)"""
        # Whisperë¡œ ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
        word_segments = self._generate_word_timestamps(audio_path)
        # ì¶”ì¶œëœ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ìë§‰ ì¶”ê°€
        self._add_subtitles_with_segments(video_path, audio_path, output_path, word_segments)


def main():
    # Register signal handlers for graceful shutdown
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    parser = argparse.ArgumentParser(description="story.jsonê³¼ ì´ë¯¸ì§€ë¡œ ì˜ìƒ ìƒì„±")
    parser.add_argument("--folder", "-f", required=True, help="story.jsonê³¼ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument("--voice", "-v", default="ko-KR-SoonBokNeural",
                       help="TTS ìŒì„± (ê¸°ë³¸: ko-KR-SoonBokNeural)")
    parser.add_argument("--aspect-ratio", "-a", default="9:16", choices=["9:16", "16:9"],
                       help="ë¹„ë””ì˜¤ ë¹„ìœ¨ (ê¸°ë³¸: 9:16)")
    parser.add_argument("--combine", action="store_true",
                       help="ì”¬ë³„ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ ê²°í•© (ê¸°ë³¸: ê²°í•© ì•ˆ í•¨)")
    parser.add_argument("--add-subtitles", "-s", action="store_true", default=True,
                       help="ìë§‰ ì¶”ê°€ (ê¸°ë³¸: ì¶”ê°€í•¨, --no-subtitlesë¡œ ë„ê¸°)")
    parser.add_argument("--no-subtitles", action="store_false", dest="add_subtitles",
                       help="ìë§‰ ì¶”ê°€ ì•ˆ í•¨")
    parser.add_argument("--image-source", "-i", default="none", choices=["none", "google", "dalle"],
                       help="ì´ë¯¸ì§€ ì†ŒìŠ¤ (ê¸°ë³¸: none - ìˆ˜ë™ ì—…ë¡œë“œ, google - Google Image Search, dalle - DALL-E 3)")
    parser.add_argument("--is-admin", action="store_true",
                       help="ê´€ë¦¬ì ëª¨ë“œ (ë¹„ìš© ë¡œê·¸ í‘œì‹œ)")

    args = parser.parse_args()

    # ë¡œê·¸ í´ë” ìƒì„±
    os.makedirs("logs", exist_ok=True)

    print("=" * 70)
    print("VideoFromFolder Creator")
    print("=" * 70)
    print(f"í´ë”: {args.folder}")
    print(f"ìŒì„±: {args.voice}")
    print(f"ë¹„ìœ¨: {args.aspect_ratio}")
    print(f"ìë§‰: {'ì¶”ê°€' if args.add_subtitles else 'ì¶”ê°€ ì•ˆ í•¨'}")
    print(f"ì´ë¯¸ì§€ ì†ŒìŠ¤: {args.image_source}")
    print("=" * 70)

    # í¬ë¦¬ì—ì´í„° ìƒì„±
    creator = VideoFromFolderCreator(
        folder_path=args.folder,
        voice=args.voice,
        aspect_ratio=args.aspect_ratio,
        add_subtitles=args.add_subtitles,
        image_source=args.image_source,
        is_admin=args.is_admin
    )

    # ë¹„ë””ì˜¤ ìƒì„±
    result = asyncio.run(creator.create_all_videos(combine=args.combine))

    if result:
        print("=" * 70)
        print("âœ“ ì„±ê³µ!")
        print("=" * 70)
        print(f"ì¶œë ¥: {result}")
        print("=" * 70)

        # simple_concat ë³‘í•© ë¡œì§ ì¶”ê°€
        if not args.combine:
            print("\n" + "=" * 70)
            print("ğŸ”— ì”¬ ë³‘í•© ì‹œì‘ (simple_concat)")
            print("=" * 70)

            # generated_videos í´ë” ê²½ë¡œ
            generated_videos_folder = Path(args.folder) / "generated_videos"

            if generated_videos_folder.exists():
                # story.jsonì—ì„œ ì œëª© ì¶”ì¶œ
                story_path = Path(args.folder) / "story.json"
                story_metadata_path = Path(args.folder) / "story_metadata.json"

                title = "output_video"
                if story_metadata_path.exists():
                    try:
                        with open(story_metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            title = metadata.get('title', 'output_video')
                    except Exception as e:
                        logger.warning(f"story_metadata.json ì½ê¸° ì‹¤íŒ¨: {e}")
                elif story_path.exists():
                    try:
                        with open(story_path, 'r', encoding='utf-8') as f:
                            story = json.load(f)
                            title = story.get('title', 'output_video')
                    except Exception as e:
                        logger.warning(f"story.json ì½ê¸° ì‹¤íŒ¨: {e}")

                # ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜
                safe_title = re.sub(r'[\\/:*?"<>|]', '_', title)
                output_filename = f"{safe_title}.mp4"

                print("\n" + "=" * 70)
                print("â„¹ï¸ ê°œë³„ ì”¬ íŒŒì¼ ìƒì„± ì™„ë£Œ")
                print("=" * 70)
                print(f"ğŸ“ í´ë”: {generated_videos_folder}")
                print("=" * 70)
                print(f"ğŸ“ ì˜ˆìƒ íŒŒì¼ëª…: {output_filename}")

                # simple_concat.py í˜¸ì¶œ
                try:
                    script_path = Path(__file__).parent / "simple_concat.py"
                    cmd = [
                        sys.executable,
                        str(script_path),
                        str(generated_videos_folder),
                        output_filename
                    ]

                    concat_result = subprocess.run(
                        cmd,
                        capture_output=True,
                        text=True,
                        encoding='utf-8',
                        errors='ignore',
                        timeout=600
                    )

                    if concat_result.stdout:
                        print(concat_result.stdout)

                    if concat_result.returncode == 0:
                        final_video_path = generated_videos_folder / output_filename
                        if final_video_path.exists():
                            print("\n" + "=" * 70)
                            print("âœ“ ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ!")
                            print("=" * 70)
                            print(f"ğŸ“¹ íŒŒì¼: {final_video_path}")
                            print("=" * 70)
                        else:
                            raise FileNotFoundError(f"ìƒì„±ëœ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        raise RuntimeError(f"simple_concat.py ì‹¤íŒ¨: {concat_result.stderr}")

                except Exception as e:
                    logger.error(f"âŒ ì˜ìƒ íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {e}")
                    sys.exit(1)
            else:
                logger.warning(f"generated_videos í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {generated_videos_folder}")
    else:
        print("âœ— ì‹¤íŒ¨!")
        sys.exit(1)


if __name__ == "__main__":
    main()
