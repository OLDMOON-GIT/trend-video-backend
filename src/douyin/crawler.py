"""
ë”ìš°ì¸(Douyin) íŠ¸ë Œë”© ì œí’ˆ ì˜ìƒ í¬ë¡¤ëŸ¬
Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ ë”ìš°ì¸ ì‡¼í•‘ ì„¹ì…˜ì˜ ì¸ê¸° ì˜ìƒì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
"""
import asyncio
import json
import time
import re
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict

from playwright.async_api import async_playwright, Page, Browser


@dataclass
class DouyinVideo:
    """ë”ìš°ì¸ ë¹„ë””ì˜¤ ì •ë³´"""
    video_id: str
    video_url: str
    title: str
    author: str
    author_id: str
    view_count: int
    like_count: int
    share_count: int
    product_info: Optional[str] = None
    has_text_overlay: bool = False  # ì¤‘êµ­ì–´ ìë§‰ ì—¬ë¶€
    duration_seconds: int = 0


def has_chinese_text(text: str) -> bool:
    """
    í…ìŠ¤íŠ¸ì— ì¤‘êµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

    Args:
        text: í™•ì¸í•  í…ìŠ¤íŠ¸

    Returns:
        ì¤‘êµ­ì–´ í¬í•¨ ì—¬ë¶€
    """
    # ì¤‘êµ­ì–´ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: U+4E00 ~ U+9FFF (CJK Unified Ideographs)
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
    return bool(chinese_pattern.search(text))


class DouyinCrawler:
    """ë”ìš°ì¸ í¬ë¡¤ëŸ¬"""

    def __init__(self, headless: bool = False, filter_chinese: bool = True):
        self.headless = headless
        self.filter_chinese = filter_chinese  # ì¤‘êµ­ì–´ í•„í„°ë§ ì˜µì…˜
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None

    async def start(self):
        """ë¸Œë¼ìš°ì € ì‹œì‘"""
        print("ğŸš€ Playwright ë¸Œë¼ìš°ì € ì‹œì‘...", flush=True)
        self.playwright = await async_playwright().start()

        # ë”ìš°ì¸ì€ ì¤‘êµ­ ì‚¬ì´íŠ¸ì´ë¯€ë¡œ ì¤‘êµ­ì–´ locale ì„¤ì •
        self.browser = await self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu',
                '--disable-web-security',
                '--disable-features=IsolateOrigins,site-per-process',
            ]
        )

        context = await self.browser.new_context(
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            extra_http_headers={
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            }
        )

        self.page = await context.new_page()

        # ìë™í™” ê°ì§€ ìš°íšŒ
        await self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en']
            });
        """)

        print("âœ… ë¸Œë¼ìš°ì € ì‹œì‘ ì™„ë£Œ", flush=True)

    async def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.browser:
            await self.browser.close()
            print("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")

    async def search_videos_by_keyword(
        self,
        keyword: str,
        limit: int = 20,
        use_mock_data: bool = False
    ) -> List[DouyinVideo]:
        """
        í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì¤‘êµ­ì–´)
            limit: ê°€ì ¸ì˜¬ ì˜ìƒ ê°œìˆ˜
            use_mock_data: í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ì‚¬ìš©

        Returns:
            DouyinVideo ë¦¬ìŠ¤íŠ¸
        """
        # ë”ë¯¸ ë°ì´í„° ëª¨ë“œ
        if use_mock_data:
            return await self._generate_mock_videos_for_keyword(limit, keyword)

        if not self.page:
            raise RuntimeError("ë¸Œë¼ìš°ì €ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. start()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        videos: List[DouyinVideo] = []

        # Douyin ê²€ìƒ‰ URL
        from urllib.parse import quote
        search_url = f"https://www.douyin.com/search/{quote(keyword)}"

        print(f"ğŸ” Douyin í‚¤ì›Œë“œ ê²€ìƒ‰: {keyword}", flush=True)
        print(f"   URL: {search_url}", flush=True)

        # ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ ì ‘ì† ì‹œë„ {attempt + 1}/{max_retries}...", flush=True)
                await self.page.goto(search_url, wait_until='load', timeout=60000)
                await asyncio.sleep(5)
                print(f"âœ… ê²€ìƒ‰ í˜ì´ì§€ ì ‘ì† ì„±ê³µ!", flush=True)
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ ì ‘ì† ì‹¤íŒ¨ ({attempt + 1}/{max_retries}): {e}", flush=True)
                    await asyncio.sleep(3)
                else:
                    raise Exception(f"Douyin ê²€ìƒ‰ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {e}")

        try:
            # ì˜ìƒ íƒ­ í´ë¦­ (ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì˜ìƒë§Œ í•„í„°ë§)
            try:
                video_tab = await self.page.query_selector('div[data-e2e="search-video-tab"]')
                if video_tab:
                    await video_tab.click()
                    await asyncio.sleep(2)
            except:
                pass  # ì˜ìƒ íƒ­ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì§„í–‰

            # ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ì˜ìƒ ìˆ˜ì§‘
            scroll_count = 0
            max_scrolls = limit // 5 + 2

            while len(videos) < limit and scroll_count < max_scrolls:
                # ì˜ìƒ ìš”ì†Œ ì°¾ê¸°
                video_elements = await self.page.query_selector_all('[data-e2e="search-result-video"]')

                print(f"ğŸ” ë°œê²¬ëœ ì˜ìƒ ìˆ˜: {len(video_elements)}", flush=True)

                for element in video_elements:
                    if len(videos) >= limit:
                        break

                    try:
                        # ì˜ìƒ ì •ë³´ ì¶”ì¶œ
                        video_id = await element.get_attribute('data-video-id')
                        if not video_id:
                            continue

                        # ì¤‘ë³µ ì²´í¬
                        if any(v.video_id == video_id for v in videos):
                            continue

                        # ë§í¬
                        link_element = await element.query_selector('a')
                        video_url = await link_element.get_attribute('href') if link_element else None

                        if not video_url:
                            continue

                        if video_url.startswith('/'):
                            video_url = f"https://www.douyin.com{video_url}"

                        # ì œëª©
                        title_element = await element.query_selector('[data-e2e="search-video-desc"]')
                        title = await title_element.inner_text() if title_element else "ì œëª© ì—†ìŒ"

                        # ì¤‘êµ­ì–´ í•„í„°ë§
                        if self.filter_chinese and has_chinese_text(title):
                            print(f"  â­ï¸ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ ê°ì§€ - ìŠ¤í‚µ: {title[:30]}...", flush=True)
                            continue

                        # ì‘ì„±ì
                        author_element = await element.query_selector('[data-e2e="search-video-author"]')
                        author = await author_element.inner_text() if author_element else "ì‘ì„±ì ì—†ìŒ"

                        # í†µê³„
                        view_count = await self._extract_count(element, '[data-e2e="search-video-views"]')
                        like_count = await self._extract_count(element, '[data-e2e="search-video-likes"]')

                        video = DouyinVideo(
                            video_id=video_id,
                            video_url=video_url,
                            title=title,
                            author=author,
                            author_id="",
                            view_count=view_count,
                            like_count=like_count,
                            share_count=0,
                            has_text_overlay=False,
                        )

                        videos.append(video)
                        print(f"  âœ… ì˜ìƒ ì¶”ê°€: {title[:40]}... (ì¡°íšŒ: {view_count:,})", flush=True)

                    except Exception as e:
                        print(f"  âš ï¸ ì˜ìƒ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}", flush=True)
                        continue

                # ìŠ¤í¬ë¡¤
                await self.page.evaluate('window.scrollBy(0, window.innerHeight)')
                await asyncio.sleep(2)
                scroll_count += 1

            print(f"\nâœ… ì´ {len(videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ (í‚¤ì›Œë“œ: {keyword})", flush=True)
            return videos

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}", flush=True)
            import traceback
            traceback.print_exc()
            return videos

    async def get_trending_shopping_videos(
        self,
        limit: int = 20,
        category: str = "electronics",  # electronics, fashion, beauty, home ë“±
        use_mock_data: bool = False  # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    ) -> List[DouyinVideo]:
        """
        íŠ¸ë Œë”© ì‡¼í•‘ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°

        Args:
            limit: ê°€ì ¸ì˜¬ ì˜ìƒ ê°œìˆ˜
            category: ì¹´í…Œê³ ë¦¬ (electronics, fashion, beauty, home ë“±)
            use_mock_data: í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€

        Returns:
            DouyinVideo ë¦¬ìŠ¤íŠ¸
        """
        # ë”ë¯¸ ë°ì´í„° ëª¨ë“œ
        if use_mock_data:
            return await self._generate_mock_videos(limit, category)

        if not self.page:
            raise RuntimeError("ë¸Œë¼ìš°ì €ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. start()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        videos: List[DouyinVideo] = []

        # ë”ìš°ì¸ ì‡¼í•‘ í˜ì´ì§€ URL
        # ì‹¤ì œë¡œëŠ” ë”ìš°ì¸ì˜ ì‡¼í•‘ ì„¹ì…˜ URLì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
        # ì˜ˆ: https://www.douyin.com/discover
        url = "https://www.douyin.com/discover"

        print(f"ğŸ“± ë”ìš°ì¸ íŠ¸ë Œë”© í˜ì´ì§€ ì ‘ì† ì‹œë„: {url}", flush=True)

        # ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ ì ‘ì† ì‹œë„ {attempt + 1}/{max_retries}...", flush=True)
                await self.page.goto(url, wait_until='load', timeout=60000)  # networkidle â†’ load, 60ì´ˆë¡œ ì¦ê°€
                await asyncio.sleep(5)
                print(f"âœ… í˜ì´ì§€ ì ‘ì† ì„±ê³µ!", flush=True)
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ ì ‘ì† ì‹¤íŒ¨ ({attempt + 1}/{max_retries}): {e}", flush=True)
                    await asyncio.sleep(3)
                else:
                    raise Exception(f"ë”ìš°ì¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼): {e}")

        try:
            pass  # ì•„ë˜ ê¸°ì¡´ ë¡œì§ ê³„ì†

            # í˜ì´ì§€ ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ì˜ìƒ ìˆ˜ì§‘
            scroll_count = 0
            max_scrolls = limit // 10 + 1

            while len(videos) < limit and scroll_count < max_scrolls:
                # ì˜ìƒ ìš”ì†Œ ì°¾ê¸° (ì‹¤ì œ ë”ìš°ì¸ DOM êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
                video_elements = await self.page.query_selector_all('[data-e2e="recommend-list-item"]')

                print(f"ğŸ” ë°œê²¬ëœ ì˜ìƒ ìˆ˜: {len(video_elements)}")

                for element in video_elements:
                    if len(videos) >= limit:
                        break

                    try:
                        # ì˜ìƒ ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ DOM êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
                        video_id = await element.get_attribute('data-video-id')
                        if not video_id:
                            continue

                        # ì¤‘ë³µ ì²´í¬
                        if any(v.video_id == video_id for v in videos):
                            continue

                        # ì˜ìƒ ë§í¬
                        link_element = await element.query_selector('a')
                        video_url = await link_element.get_attribute('href') if link_element else None

                        if not video_url:
                            continue

                        # ì „ì²´ URLë¡œ ë³€í™˜
                        if video_url.startswith('/'):
                            video_url = f"https://www.douyin.com{video_url}"

                        # ì œëª©
                        title_element = await element.query_selector('[data-e2e="video-title"]')
                        title = await title_element.inner_text() if title_element else "ì œëª© ì—†ìŒ"

                        # ì¤‘êµ­ì–´ í•„í„°ë§ ì²´í¬
                        if self.filter_chinese and has_chinese_text(title):
                            print(f"  â­ï¸ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ ê°ì§€ - ìŠ¤í‚µ: {title[:30]}...", flush=True)
                            continue

                        # ì‘ì„±ì
                        author_element = await element.query_selector('[data-e2e="video-author"]')
                        author = await author_element.inner_text() if author_element else "ì‘ì„±ì ì—†ìŒ"

                        # ì„¤ëª…ì—ì„œë„ ì¤‘êµ­ì–´ ì²´í¬
                        desc_element = await element.query_selector('[data-e2e="video-desc"]')
                        description = await desc_element.inner_text() if desc_element else ""

                        if self.filter_chinese and description and has_chinese_text(description):
                            print(f"  â­ï¸ ì„¤ëª…ì— ì¤‘êµ­ì–´ ê°ì§€ - ìŠ¤í‚µ: {title[:30]}...", flush=True)
                            continue

                        # í†µê³„ ì •ë³´
                        view_count = await self._extract_count(element, '[data-e2e="video-views"]')
                        like_count = await self._extract_count(element, '[data-e2e="video-likes"]')
                        share_count = await self._extract_count(element, '[data-e2e="video-shares"]')

                        video = DouyinVideo(
                            video_id=video_id,
                            video_url=video_url,
                            title=title,
                            author=author,
                            author_id="",  # í•„ìš”ì‹œ ì¶”ì¶œ
                            view_count=view_count,
                            like_count=like_count,
                            share_count=share_count,
                            has_text_overlay=False,  # ì¼ë‹¨ False, ë‹¤ìš´ë¡œë“œ í›„ ê²€ì¦
                        )

                        videos.append(video)
                        print(f"  âœ… ì˜ìƒ ì¶”ê°€ (ì¤‘êµ­ì–´ ì—†ìŒ): {title[:50]}... (ì¡°íšŒ: {view_count:,})", flush=True)

                    except Exception as e:
                        print(f"  âš ï¸ ì˜ìƒ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                        continue

                # í˜ì´ì§€ ìŠ¤í¬ë¡¤
                await self.page.evaluate('window.scrollBy(0, window.innerHeight)')
                await asyncio.sleep(2)
                scroll_count += 1

            print(f"\nâœ… ì´ {len(videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")
            return videos

        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return videos

    async def _generate_mock_videos(self, limit: int, category: str) -> List[DouyinVideo]:
        """
        í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì˜ìƒ ë°ì´í„° ìƒì„± (ì¤‘êµ­ì–´ ì—†ëŠ” ì˜ë¬¸ ì œëª©)

        Args:
            limit: ìƒì„±í•  ì˜ìƒ ê°œìˆ˜
            category: ì¹´í…Œê³ ë¦¬

        Returns:
            DouyinVideo ë¦¬ìŠ¤íŠ¸
        """
        import random

        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {limit}ê°œ ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...", flush=True)
        await asyncio.sleep(0.5)  # ë¹„ë™ê¸° ì‘ì—… ì‹œë®¬ë ˆì´ì…˜

        mock_titles = {
            "electronics": [
                "Amazing Wireless Earbuds Review",
                "Smart Watch Unboxing 2024",
                "Gaming Keyboard Test",
                "Portable Charger Comparison",
                "4K Webcam Setup Guide",
            ],
            "fashion": [
                "Summer Fashion Trends",
                "Sneaker Collection Showcase",
                "Minimal Wardrobe Essentials",
                "Designer Bag Review",
                "Outfit Ideas for Spring",
            ],
            "beauty": [
                "Skincare Routine Morning",
                "Makeup Tutorial Natural Look",
                "Hair Care Tips 2024",
                "Best Lip Gloss Swatches",
                "Anti-Aging Serum Review",
            ],
        }

        titles = mock_titles.get(category, mock_titles["electronics"])
        videos = []

        for i in range(limit):
            title = random.choice(titles) + f" #{i+1}"
            video_id = f"mock_{category}_{int(time.time())}_{i}"

            video = DouyinVideo(
                video_id=video_id,
                video_url=f"https://www.douyin.com/video/{video_id}",
                title=title,
                author=f"TestUser{random.randint(1, 100)}",
                author_id=f"user_{random.randint(1000, 9999)}",
                view_count=random.randint(10000, 1000000),
                like_count=random.randint(1000, 100000),
                share_count=random.randint(100, 10000),
                has_text_overlay=False,
                duration_seconds=random.randint(15, 60),
            )

            videos.append(video)
            print(f"  âœ… ë”ë¯¸ ì˜ìƒ ìƒì„±: {title} (ì¡°íšŒ: {video.view_count:,})", flush=True)

        print(f"âœ… {len(videos)}ê°œ ë”ë¯¸ ì˜ìƒ ìƒì„± ì™„ë£Œ", flush=True)
        return videos

    async def _generate_mock_videos_for_keyword(self, limit: int, keyword: str) -> List[DouyinVideo]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë”ë¯¸ ì˜ìƒ ìƒì„±"""
        import random

        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {keyword} í‚¤ì›Œë“œë¡œ {limit}ê°œ ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...", flush=True)
        await asyncio.sleep(0.5)

        videos = []
        for i in range(limit):
            title = f"{keyword} Product Review #{i+1}"
            video_id = f"mock_{keyword}_{int(time.time())}_{i}"

            video = DouyinVideo(
                video_id=video_id,
                video_url=f"https://www.douyin.com/video/{video_id}",
                title=title,
                author=f"TestUser{random.randint(1, 100)}",
                author_id=f"user_{random.randint(1000, 9999)}",
                view_count=random.randint(10000, 1000000),
                like_count=random.randint(1000, 100000),
                share_count=random.randint(100, 10000),
                has_text_overlay=False,
                duration_seconds=random.randint(15, 60),
            )

            videos.append(video)
            print(f"  âœ… ë”ë¯¸ ì˜ìƒ ìƒì„±: {title} (ì¡°íšŒ: {video.view_count:,})", flush=True)

        print(f"âœ… {len(videos)}ê°œ ë”ë¯¸ ì˜ìƒ ìƒì„± ì™„ë£Œ (í‚¤ì›Œë“œ: {keyword})", flush=True)
        return videos

    async def _extract_count(self, element, selector: str) -> int:
        """ìˆ«ì ì¹´ìš´íŠ¸ ì¶”ì¶œ"""
        try:
            count_element = await element.query_selector(selector)
            if count_element:
                text = await count_element.inner_text()
                # "1.2w" ê°™ì€ í˜•ì‹ì„ ìˆ«ìë¡œ ë³€í™˜
                text = text.lower().replace('w', '0000').replace('k', '000')
                # ìˆ«ìë§Œ ì¶”ì¶œ
                numbers = re.findall(r'\d+', text)
                if numbers:
                    return int(numbers[0])
        except:
            pass
        return 0

    async def check_text_overlay(self, video_url: str) -> bool:
        """
        ì˜ìƒì— í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´(ìë§‰)ê°€ ìˆëŠ”ì§€ í™•ì¸

        Args:
            video_url: ì˜ìƒ URL

        Returns:
            True if í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ê°€ ìˆìŒ, False otherwise
        """
        # TODO: OCR ë˜ëŠ” ì˜ìƒ ë¶„ì„ì„ í†µí•´ ì¤‘êµ­ì–´ ìë§‰ ê°ì§€
        # ì§€ê¸ˆì€ ê°„ë‹¨íˆ False ë°˜í™˜
        return False

    def save_videos_to_json(self, videos: List[DouyinVideo], output_path: Path):
        """ì˜ìƒ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        data = [asdict(video) for video in videos]

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ì˜ìƒ ì •ë³´ ì €ì¥: {output_path}")


async def main():
    """í…ŒìŠ¤íŠ¸ ì½”ë“œ"""
    crawler = DouyinCrawler(headless=False)

    try:
        await crawler.start()

        # íŠ¸ë Œë”© ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
        videos = await crawler.get_trending_shopping_videos(limit=10)

        # JSONìœ¼ë¡œ ì €ì¥
        output_path = Path("douyin_videos.json")
        crawler.save_videos_to_json(videos, output_path)

        print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
        for i, video in enumerate(videos, 1):
            print(f"{i}. {video.title}")
            print(f"   ì¡°íšŒ: {video.view_count:,}, ì¢‹ì•„ìš”: {video.like_count:,}")
            print(f"   URL: {video.video_url}")
            print()

    finally:
        await crawler.close()


if __name__ == "__main__":
    asyncio.run(main())
